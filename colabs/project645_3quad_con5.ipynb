{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setting up data and env"],"metadata":{"id":"nBuehlq35L4x"}},{"cell_type":"markdown","source":["## Upload Your Project"],"metadata":{"id":"zK_iE6Rb219f"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":128},"id":"GWfv5Zzc2eZv","outputId":"b9444293-d0b5-47dd-833f-77ffea31539f","executionInfo":{"status":"ok","timestamp":1747795355430,"user_tz":-180,"elapsed":439619,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Upload your project645.zip file...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5c47f1fa-8928-451d-bdee-712d9d5e77d0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5c47f1fa-8928-451d-bdee-712d9d5e77d0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving project645.zip to project645.zip\n","User uploaded file \"project645.zip\" with length 24112955 bytes\n"]}],"source":["from google.colab import files\n","print(\"Upload your project645.zip file...\")\n","uploaded = files.upload()\n","\n","# Verify upload\n","for fn in uploaded.keys():\n","  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"]},{"cell_type":"markdown","source":["## Unzip the project"],"metadata":{"id":"wKZyBp5y3dhD"}},{"cell_type":"code","source":["!unzip -q project645.zip -d /content/\n","# Verify unzip by listing contents\n","!ls /content/project645/\n","!ls /content/project645/code/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CaZYeN_63YNo","executionInfo":{"status":"ok","timestamp":1747795358084,"user_tz":-180,"elapsed":1034,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"f0e6cc0b-0666-40e4-c506-9d9e02af70e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["code  LICENSE  mai645.yml  README.md  train_data_bvh\n","fix_feet.py\t\t\t read_bvh.py\n","generate_training_euler_data.py  read_bvh.pyc\n","generate_training_pos_data.py\t rotation2xyz.py\n","generate_training_quad_data.py\t rotation2xyz.pyc\n","__pycache__\t\t\t rotation_conversions.py\n","pytorch_train_euler_aclstm.py\t synthesize_euler_motion.py\n","pytorch_train_pos_aclstm.py\t synthesize_pos_motion_original_colab.py\n","pytorch_train_quad_aclstm.py\t synthesize_pos_motion.py\n","read_bvh_hierarchy.py\t\t synthesize_quad_motion.py\n","read_bvh_hierarchy.pyc\t\t test_encodings.py\n"]}]},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"F7XrtRYE3lSl"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSBSPgkp3nqG","executionInfo":{"status":"ok","timestamp":1747795384330,"user_tz":-180,"elapsed":24692,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"20f010d8-2ff1-44ad-abae-0465ecbc9100"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Create Output Folder"],"metadata":{"id":"HGWxCQaAfKCC"}},{"cell_type":"markdown","source":["*   **Create an Output Folder in Google Drive:** It's highly recommended to create a dedicated folder in your Google Drive to store the outputs (trained models, generated data/BVH files). For example, you could create a folder named `mai645_project_outputs` directly in your \"My Drive\".\n","*   Define a variable in Colab pointing to this Drive folder. **Make sure the path matches the folder you created.**"],"metadata":{"id":"bcZi7xIM33-g"}},{"cell_type":"code","source":["# IMPORTANT: Adjust this path if you named your Drive folder differently!\n","# uncomment according to which experiment you are running\n","GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs_con5\"\n","# GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs_con30\"\n","# GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs_con45\"\n","# Create the directory in Drive if it doesn't exist (optional, Colab can create it)\n","import os\n","os.makedirs(GDRIVE_OUTPUT_DIR, exist_ok=True)\n","print(f\"Outputs will be saved to: {GDRIVE_OUTPUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbv-wNTk34sD","executionInfo":{"status":"ok","timestamp":1747796692816,"user_tz":-180,"elapsed":21,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"02c8f526-1d3e-40d5-e810-b710f5f2acdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Outputs will be saved to: /content/drive/MyDrive/mai645_project_outputs_con30\n"]}]},{"cell_type":"markdown","source":["## Install Dependencies"],"metadata":{"id":"K6fxAysh4Aza"}},{"cell_type":"code","source":["# Install the latest compatible PyTorch, torchvision, torchaudio for this Colab environment\n","!pip install -q torch torchvision torchaudio\n","\n","# Install other libraries, specifically targeting numpy in the 2.0.x range.\n","# This aims to satisfy thinc (>=2.0.0) AND tensorflow/numba (<2.1.0).\n","!pip install -q contourpy==1.3.1 cycler==0.12.1 fonttools==4.56.0 kiwisolver==1.4.8 matplotlib==3.10.1 \"numpy>=2.0.0,<2.1.0\" opencv-python==4.11.0.86 packaging==24.2 pyparsing==3.2.3 python-dateutil==2.9.0.post0 six==1.17.0 transforms3d==0.4.2\n","\n","# Verify installation\n","!pip show torch torchvision torchaudio transforms3d numpy opencv-python tensorflow numba"],"metadata":{"id":"iiDk6zZ34Ch8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Change the current working directory to where your Python scripts are located"],"metadata":{"id":"lUWhlJaS5DJy"}},{"cell_type":"code","source":["cd /content/project645/code/"],"metadata":{"id":"-PoyGBYI5C88","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747795629976,"user_tz":-180,"elapsed":25,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"0137106c-207f-4567-bf74-ea2979b2ce6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/project645/code\n"]}]},{"cell_type":"markdown","source":["# Quaternion Preprocess"],"metadata":{"id":"GEHg6mh_7Rco"}},{"cell_type":"code","source":["# Define path for cached preprocessed data archive on Google Drive\n","PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH = os.path.join(GDRIVE_OUTPUT_DIR, \"preprocessed_quad_data.tar.gz\")\n","# Define a path to a key file that indicates preprocessing was successful and data is present\n","# This file is expected to be created by generate_training_quad_data.py\n","PREPROCESSED_QUAD_DONE_FLAG_PATH = \"/content/project645/train_data_quad/salsa/metadata_quad.json\"\n","\n","# Variable to track if actual preprocessing is needed or if cached data can be used\n","preprocessing_needed = True"],"metadata":{"id":"_ujTUHdUto1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load Cached Preprocessed Quaternion Data (if available)\n","\n","if os.path.exists(PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH):\n","  print(f\"Found cached preprocessed data archive at {PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH}.\")\n","  print(\"Attempting to load...\")\n","  # Ensure the base target directory for extraction exists\n","  !mkdir -p /content/project645\n","  # Copy from Drive to local Colab environment\n","  !cp \"{PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH}\" /tmp/preprocessed_quad_data.tar.gz\n","  # Extract the archive into /content/project645/\n","  # The archive was created with paths relative to /content/project645\n","  print(\"Extracting data...\")\n","  !tar -xzf /tmp/preprocessed_quad_data.tar.gz -C /content/project645/\n","\n","  # Verify if a key file (flag path) now exists after extraction\n","  if os.path.exists(PREPROCESSED_QUAD_DONE_FLAG_PATH):\n","    print(\"Successfully loaded and verified cached preprocessed data.\")\n","    preprocessing_needed = False\n","  else:\n","    print(f\"Cached data archive found and extracted, but key file {PREPROCESSED_QUAD_DONE_FLAG_PATH} is missing.\")\n","    print(\"This might indicate an issue with the cache or the extraction process. Will re-preprocess.\")\n","    # Attempt to clean up potentially incomplete/corrupted extraction to avoid issues\n","    !rm -rf /content/project645/train_data_quad\n","    !rm -rf /content/project645/reconstructed_bvh_data_quad\n","    preprocessing_needed = True # Ensure it's true if verification fails\n","else:\n","  print(f\"No cached preprocessed data archive found at {PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH}.\")\n","  print(\"Proceeding with fresh preprocessing.\")\n","  preprocessing_needed = True # Explicitly set, though it's the default\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDCfzNjqtt-F","executionInfo":{"status":"ok","timestamp":1747795635802,"user_tz":-180,"elapsed":3144,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"f450bdea-4c2f-40d6-b6a8-e9dc71f89e94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found cached preprocessed data archive at /content/drive/MyDrive/mai645_project_outputs_v2t1/preprocessed_quad_data.tar.gz.\n","Attempting to load...\n","Extracting data...\n","Successfully loaded and verified cached preprocessed data.\n"]}]},{"cell_type":"code","source":["if preprocessing_needed:\n","  print(\"Running Quaternion preprocessing script as cached data was not used...\")\n","  # Preprocess Quaternion data\n","  !python generate_training_quad_data.py\n","\n","  # Verify that preprocessing script created the expected outputs and the flag file\n","  if os.path.exists(PREPROCESSED_QUAD_DONE_FLAG_PATH):\n","    print(\"Preprocessing script completed. Expected output flag file found.\")\n","    print(\"Checking output directories:\")\n","    !ls /content/project645/train_data_quad/\n","    !ls /content/project645/train_data_quad/salsa/\n","    !ls /content/project645/reconstructed_bvh_data_quad/salsa/\n","\n","    # After successful preprocessing, save the results to Google Drive\n","    print(\"\\nPreprocessing finished. Saving data to Google Drive for future runs...\")\n","    # Create the archive.\n","    # -C /content/project645 makes paths in archive relative (e.g., train_data_quad, reconstructed_bvh_data_quad)\n","    # The directories to archive are /content/project645/train_data_quad and /content/project645/reconstructed_bvh_data_quad\n","    !tar -czf /tmp/preprocessed_quad_data.tar.gz -C /content/project645 train_data_quad reconstructed_bvh_data_quad\n","    !cp /tmp/preprocessed_quad_data.tar.gz \"{PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH}\"\n","    print(f\"Preprocessed data successfully saved to {PREPROCESSED_QUAD_ARCHIVE_GDRIVE_PATH}\")\n","  else:\n","    print(f\"Preprocessing script ran, but the key output flag file ({PREPROCESSED_QUAD_DONE_FLAG_PATH}) was not found.\")\n","    print(\"Data will not be cached. Please check the preprocessing script and its outputs.\")\n","    print(\"Listing contents of relevant directories for debugging (if they exist):\")\n","    !ls -ld /content/project645/train_data_quad/ # Use -ld to show directory info or error\n","    !ls -ld /content/project645/train_data_quad/salsa/\n","    !ls -ld /content/project645/reconstructed_bvh_data_quad/\n","    !ls -ld /content/project645/reconstructed_bvh_data_quad/salsa/\n","\n","else:\n","  print(\"Skipping Quaternion preprocessing as cached data was successfully loaded.\")\n","  print(\"Verifying existence of loaded data directories:\")\n","  # Confirm the directories expected from cache are present\n","  !ls /content/project645/train_data_quad/\n","  !ls /content/project645/train_data_quad/salsa/\n","  !ls /content/project645/reconstructed_bvh_data_quad/salsa/\n"],"metadata":{"id":"qMihsAXa7RjS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747795637799,"user_tz":-180,"elapsed":353,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"ddc08466-8a2a-4642-f013-29624e1d9327"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping Quaternion preprocessing as cached data was successfully loaded.\n","Verifying existence of loaded data directories:\n","salsa\n","01.npy\t05.npy\t09.npy\t13.npy\t17.npy\t21.npy\t25.npy\t29.npy\n","02.npy\t06.npy\t10.npy\t14.npy\t18.npy\t22.npy\t26.npy\t30.npy\n","03.npy\t07.npy\t11.npy\t15.npy\t19.npy\t23.npy\t27.npy\tmetadata_quad.json\n","04.npy\t08.npy\t12.npy\t16.npy\t20.npy\t24.npy\t28.npy\n","01.bvh\t04.bvh\t07.bvh\t10.bvh\t13.bvh\t16.bvh\t19.bvh\t22.bvh\t25.bvh\t28.bvh\n","02.bvh\t05.bvh\t08.bvh\t11.bvh\t14.bvh\t17.bvh\t20.bvh\t23.bvh\t26.bvh\t29.bvh\n","03.bvh\t06.bvh\t09.bvh\t12.bvh\t15.bvh\t18.bvh\t21.bvh\t24.bvh\t27.bvh\t30.bvh\n"]}]},{"cell_type":"markdown","source":["# Quaternion training"],"metadata":{"id":"NqgwoHHmDcyi"}},{"cell_type":"code","source":["\n","# Define paths for training outputs\n","QUAD_DATA_DIR = \"/content/project645/train_data_quad/salsa/\" # Created by preprocessing script\n","METADATA_QUAD_PATH = os.path.join(QUAD_DATA_DIR, \"metadata_quad.json\")\n","QUAD_WEIGHTS_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"weights_quad\")\n","QUAD_TRAIN_BVH_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"train_output_bvh_quad\")\n","os.makedirs(QUAD_WEIGHTS_DIR, exist_ok=True)\n","os.makedirs(QUAD_TRAIN_BVH_DIR, exist_ok=True)\n","\n","# Training command for pytorch_train_quad_aclstm.py\n","# The --in_frame and --out_frame arguments are now determined by metadata inside the script.\n","# Standard BVH path is relative to the /code directory.\n","# Set total_iterations to a reasonable number for demonstration/testing.\n","# For full training, use a higher value like 50000 as per instructions.\n","TOTAL_ITERATIONS_QUAD = 50000 # Adjust as needed\n","BATCH_SIZE_QUAD = 32\n","\n","!python pytorch_train_quad_aclstm.py \\\n","    --dances_folder \"{QUAD_DATA_DIR}\" \\\n","    --metadata_path \"{METADATA_QUAD_PATH}\" \\\n","    --write_weight_folder \"{QUAD_WEIGHTS_DIR}/\" \\\n","    --write_bvh_motion_folder \"{QUAD_TRAIN_BVH_DIR}/\" \\\n","    --standard_bvh_file \"../train_data_bvh/standard.bvh\" \\\n","    --batch_size {BATCH_SIZE_QUAD} \\\n","    --seq_len 100 \\\n","    --total_iterations {TOTAL_ITERATIONS_QUAD} \\\n","    --print_loss_iter 100 \\\n","    --save_model_iter 1000 \\\n","    --save_bvh_iter 1000 \\\n","    # --read_weight_path \"{QUAD_WEIGHTS_DIR}/0015000.weight\" # Optional: to resume training\n","\n","\n","print(f\"\\n--- Training for Quaternion script finished. Check {QUAD_WEIGHTS_DIR} for models. ---\")"],"metadata":{"id":"hQ1tTDfqDk67","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a44e0f2-47d7-4e3d-9141-f8b3e876661b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 42 non-end-site bones from hierarchy.\n","Loaded metadata from /content/project645/train_data_quad/salsa/metadata_quad.json\n","Loading motion files from /content/project645/train_data_quad/salsa/...\n","30 motion files loaded.\n","Training on: cuda\n","########### iter 0000000 ######################\n","loss: 2.463281\n","########### iter 0000100 ######################\n","loss: 0.191560\n","########### iter 0000200 ######################\n","loss: 0.158475\n","########### iter 0000300 ######################\n","loss: 0.146552\n","########### iter 0000400 ######################\n","loss: 0.139894\n","########### iter 0000500 ######################\n","loss: 0.127827\n","########### iter 0000600 ######################\n","loss: 0.120742\n","########### iter 0000700 ######################\n","loss: 0.112335\n","########### iter 0000800 ######################\n","loss: 0.104727\n","########### iter 0000900 ######################\n","loss: 0.094029\n","########### iter 0001000 ######################\n","loss: 0.091160\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0001000.weight\n","########### iter 0001100 ######################\n","loss: 0.085525\n","########### iter 0001200 ######################\n","loss: 0.086783\n","########### iter 0001300 ######################\n","loss: 0.078993\n","########### iter 0001400 ######################\n","loss: 0.081333\n","########### iter 0001500 ######################\n","loss: 0.076547\n","########### iter 0001600 ######################\n","loss: 0.071333\n","########### iter 0001700 ######################\n","loss: 0.072074\n","########### iter 0001800 ######################\n","loss: 0.071824\n","########### iter 0001900 ######################\n","loss: 0.071288\n","########### iter 0002000 ######################\n","loss: 0.071024\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0002000.weight\n","########### iter 0002100 ######################\n","loss: 0.068176\n","########### iter 0002200 ######################\n","loss: 0.069087\n","########### iter 0002300 ######################\n","loss: 0.063223\n","########### iter 0002400 ######################\n","loss: 0.067580\n","########### iter 0002500 ######################\n","loss: 0.059980\n","########### iter 0002600 ######################\n","loss: 0.062073\n","########### iter 0002700 ######################\n","loss: 0.060143\n","########### iter 0002800 ######################\n","loss: 0.060027\n","########### iter 0002900 ######################\n","loss: 0.061544\n","########### iter 0003000 ######################\n","loss: 0.063072\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0003000.weight\n","########### iter 0003100 ######################\n","loss: 0.055580\n","########### iter 0003200 ######################\n","loss: 0.055959\n","########### iter 0003300 ######################\n","loss: 0.056065\n","########### iter 0003400 ######################\n","loss: 0.056428\n","########### iter 0003500 ######################\n","loss: 0.053945\n","########### iter 0003600 ######################\n","loss: 0.055573\n","########### iter 0003700 ######################\n","loss: 0.053482\n","########### iter 0003800 ######################\n","loss: 0.056164\n","########### iter 0003900 ######################\n","loss: 0.055246\n","########### iter 0004000 ######################\n","loss: 0.054637\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0004000.weight\n","########### iter 0004100 ######################\n","loss: 0.054947\n","########### iter 0004200 ######################\n","loss: 0.054774\n","########### iter 0004300 ######################\n","loss: 0.052659\n","########### iter 0004400 ######################\n","loss: 0.053630\n","########### iter 0004500 ######################\n","loss: 0.051595\n","########### iter 0004600 ######################\n","loss: 0.050557\n","########### iter 0004700 ######################\n","loss: 0.052100\n","########### iter 0004800 ######################\n","loss: 0.051019\n","########### iter 0004900 ######################\n","loss: 0.052396\n","########### iter 0005000 ######################\n","loss: 0.050925\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0005000.weight\n","########### iter 0005100 ######################\n","loss: 0.049711\n","########### iter 0005200 ######################\n","loss: 0.049560\n","########### iter 0005300 ######################\n","loss: 0.051280\n","########### iter 0005400 ######################\n","loss: 0.046733\n","########### iter 0005500 ######################\n","loss: 0.049383\n","########### iter 0005600 ######################\n","loss: 0.047609\n","########### iter 0005700 ######################\n","loss: 0.045704\n","########### iter 0005800 ######################\n","loss: 0.046947\n","########### iter 0005900 ######################\n","loss: 0.048115\n","########### iter 0006000 ######################\n","loss: 0.046565\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0006000.weight\n","########### iter 0006100 ######################\n","loss: 0.045988\n","########### iter 0006200 ######################\n","loss: 0.047491\n","########### iter 0006300 ######################\n","loss: 0.045035\n","########### iter 0006400 ######################\n","loss: 0.045316\n","########### iter 0006500 ######################\n","loss: 0.044488\n","########### iter 0006600 ######################\n","loss: 0.046588\n","########### iter 0006700 ######################\n","loss: 0.045059\n","########### iter 0006800 ######################\n","loss: 0.044427\n","########### iter 0006900 ######################\n","loss: 0.043841\n","########### iter 0007000 ######################\n","loss: 0.043562\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0007000.weight\n","########### iter 0007100 ######################\n","loss: 0.043122\n","########### iter 0007200 ######################\n","loss: 0.042112\n","########### iter 0007300 ######################\n","loss: 0.044665\n","########### iter 0007400 ######################\n","loss: 0.042169\n","########### iter 0007500 ######################\n","loss: 0.042865\n","########### iter 0007600 ######################\n","loss: 0.040782\n","########### iter 0007700 ######################\n","loss: 0.043833\n","########### iter 0007800 ######################\n","loss: 0.043123\n","########### iter 0007900 ######################\n","loss: 0.040204\n","########### iter 0008000 ######################\n","loss: 0.041378\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0008000.weight\n","########### iter 0008100 ######################\n","loss: 0.041949\n","########### iter 0008200 ######################\n","loss: 0.041331\n","########### iter 0008300 ######################\n","loss: 0.041026\n","########### iter 0008400 ######################\n","loss: 0.040308\n","########### iter 0008500 ######################\n","loss: 0.040960\n","########### iter 0008600 ######################\n","loss: 0.039776\n","########### iter 0008700 ######################\n","loss: 0.040049\n","########### iter 0008800 ######################\n","loss: 0.040741\n","########### iter 0008900 ######################\n","loss: 0.039771\n","########### iter 0009000 ######################\n","loss: 0.040924\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0009000.weight\n","########### iter 0009100 ######################\n","loss: 0.040834\n","########### iter 0009200 ######################\n","loss: 0.040164\n","########### iter 0009300 ######################\n","loss: 0.037891\n","########### iter 0009400 ######################\n","loss: 0.037655\n","########### iter 0009500 ######################\n","loss: 0.037626\n","########### iter 0009600 ######################\n","loss: 0.036781\n","########### iter 0009700 ######################\n","loss: 0.037657\n","########### iter 0009800 ######################\n","loss: 0.037863\n","########### iter 0009900 ######################\n","loss: 0.038361\n","########### iter 0010000 ######################\n","loss: 0.037347\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0010000.weight\n","########### iter 0010100 ######################\n","loss: 0.036634\n","########### iter 0010200 ######################\n","loss: 0.035663\n","########### iter 0010300 ######################\n","loss: 0.035600\n","########### iter 0010400 ######################\n","loss: 0.035957\n","########### iter 0010500 ######################\n","loss: 0.035394\n","########### iter 0010600 ######################\n","loss: 0.034555\n","########### iter 0010700 ######################\n","loss: 0.034852\n","########### iter 0010800 ######################\n","loss: 0.034081\n","########### iter 0010900 ######################\n","loss: 0.032861\n","########### iter 0011000 ######################\n","loss: 0.035351\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0011000.weight\n","########### iter 0011100 ######################\n","loss: 0.033639\n","########### iter 0011200 ######################\n","loss: 0.033458\n","########### iter 0011300 ######################\n","loss: 0.034512\n","########### iter 0011400 ######################\n","loss: 0.034082\n","########### iter 0011500 ######################\n","loss: 0.031845\n","########### iter 0011600 ######################\n","loss: 0.033258\n","########### iter 0011700 ######################\n","loss: 0.031862\n","########### iter 0011800 ######################\n","loss: 0.030522\n","########### iter 0011900 ######################\n","loss: 0.031125\n","########### iter 0012000 ######################\n","loss: 0.030785\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0012000.weight\n","########### iter 0012100 ######################\n","loss: 0.030771\n","########### iter 0012200 ######################\n","loss: 0.030451\n","########### iter 0012300 ######################\n","loss: 0.030006\n","########### iter 0012400 ######################\n","loss: 0.029044\n","########### iter 0012500 ######################\n","loss: 0.029793\n","########### iter 0012600 ######################\n","loss: 0.030564\n","########### iter 0012700 ######################\n","loss: 0.029601\n","########### iter 0012800 ######################\n","loss: 0.028012\n","########### iter 0012900 ######################\n","loss: 0.028620\n","########### iter 0013000 ######################\n","loss: 0.027542\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0013000.weight\n","########### iter 0013100 ######################\n","loss: 0.028012\n","########### iter 0013200 ######################\n","loss: 0.027461\n","########### iter 0013300 ######################\n","loss: 0.027714\n","########### iter 0013400 ######################\n","loss: 0.027388\n","########### iter 0013500 ######################\n","loss: 0.026664\n","########### iter 0013600 ######################\n","loss: 0.025633\n","########### iter 0013700 ######################\n","loss: 0.026869\n","########### iter 0013800 ######################\n","loss: 0.025258\n","########### iter 0013900 ######################\n","loss: 0.027082\n","########### iter 0014000 ######################\n","loss: 0.025702\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0014000.weight\n","########### iter 0014100 ######################\n","loss: 0.025676\n","########### iter 0014200 ######################\n","loss: 0.024323\n","########### iter 0014300 ######################\n","loss: 0.024648\n","########### iter 0014400 ######################\n","loss: 0.023953\n","########### iter 0014500 ######################\n","loss: 0.023391\n","########### iter 0014600 ######################\n","loss: 0.023762\n","########### iter 0014700 ######################\n","loss: 0.023878\n","########### iter 0014800 ######################\n","loss: 0.023524\n","########### iter 0014900 ######################\n","loss: 0.023470\n","########### iter 0015000 ######################\n","loss: 0.023019\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0015000.weight\n","########### iter 0015100 ######################\n","loss: 0.022121\n","########### iter 0015200 ######################\n","loss: 0.022053\n","########### iter 0015300 ######################\n","loss: 0.022465\n","########### iter 0015400 ######################\n","loss: 0.021428\n","########### iter 0015500 ######################\n","loss: 0.021523\n","########### iter 0015600 ######################\n","loss: 0.021714\n","########### iter 0015700 ######################\n","loss: 0.020332\n","########### iter 0015800 ######################\n","loss: 0.020769\n","########### iter 0015900 ######################\n","loss: 0.021687\n","########### iter 0016000 ######################\n","loss: 0.021011\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0016000.weight\n","########### iter 0016100 ######################\n","loss: 0.021120\n","########### iter 0016200 ######################\n","loss: 0.020480\n","########### iter 0016300 ######################\n","loss: 0.019716\n","########### iter 0016400 ######################\n","loss: 0.020652\n","########### iter 0016500 ######################\n","loss: 0.020289\n","########### iter 0016600 ######################\n","loss: 0.019554\n","########### iter 0016700 ######################\n","loss: 0.018633\n","########### iter 0016800 ######################\n","loss: 0.019777\n","########### iter 0016900 ######################\n","loss: 0.019620\n","########### iter 0017000 ######################\n","loss: 0.018872\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0017000.weight\n","########### iter 0017100 ######################\n","loss: 0.019905\n","########### iter 0017200 ######################\n","loss: 0.018453\n","########### iter 0017300 ######################\n","loss: 0.018389\n","########### iter 0017400 ######################\n","loss: 0.019065\n","########### iter 0017500 ######################\n","loss: 0.018439\n","########### iter 0017600 ######################\n","loss: 0.018602\n","########### iter 0017700 ######################\n","loss: 0.018501\n","########### iter 0017800 ######################\n","loss: 0.017842\n","########### iter 0017900 ######################\n","loss: 0.016621\n","########### iter 0018000 ######################\n","loss: 0.017439\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0018000.weight\n","########### iter 0018100 ######################\n","loss: 0.018048\n","########### iter 0018200 ######################\n","loss: 0.017262\n","########### iter 0018300 ######################\n","loss: 0.016878\n","########### iter 0018400 ######################\n","loss: 0.017166\n","########### iter 0018500 ######################\n","loss: 0.016654\n","########### iter 0018600 ######################\n","loss: 0.016886\n","########### iter 0018700 ######################\n","loss: 0.016973\n","########### iter 0018800 ######################\n","loss: 0.016981\n","########### iter 0018900 ######################\n","loss: 0.016613\n","########### iter 0019000 ######################\n","loss: 0.016700\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0019000.weight\n","########### iter 0019100 ######################\n","loss: 0.017590\n","########### iter 0019200 ######################\n","loss: 0.016806\n","########### iter 0019300 ######################\n","loss: 0.016312\n","########### iter 0019400 ######################\n","loss: 0.015909\n","########### iter 0019500 ######################\n","loss: 0.016947\n","########### iter 0019600 ######################\n","loss: 0.015875\n","########### iter 0019700 ######################\n","loss: 0.016230\n","########### iter 0019800 ######################\n","loss: 0.015533\n","########### iter 0019900 ######################\n","loss: 0.016446\n","########### iter 0020000 ######################\n","loss: 0.015827\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0020000.weight\n","########### iter 0020100 ######################\n","loss: 0.015131\n","########### iter 0020200 ######################\n","loss: 0.015257\n","########### iter 0020300 ######################\n","loss: 0.014996\n","########### iter 0020400 ######################\n","loss: 0.015081\n","########### iter 0020500 ######################\n","loss: 0.014273\n","########### iter 0020600 ######################\n","loss: 0.014579\n","########### iter 0020700 ######################\n","loss: 0.014264\n","########### iter 0020800 ######################\n","loss: 0.014917\n","########### iter 0020900 ######################\n","loss: 0.014784\n","########### iter 0021000 ######################\n","loss: 0.014815\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0021000.weight\n","########### iter 0021100 ######################\n","loss: 0.014041\n","########### iter 0021200 ######################\n","loss: 0.015142\n","########### iter 0021300 ######################\n","loss: 0.015232\n","########### iter 0021400 ######################\n","loss: 0.014604\n","########### iter 0021500 ######################\n","loss: 0.014052\n","########### iter 0021600 ######################\n","loss: 0.013863\n","########### iter 0021700 ######################\n","loss: 0.013958\n","########### iter 0021800 ######################\n","loss: 0.014189\n","########### iter 0021900 ######################\n","loss: 0.013260\n","########### iter 0022000 ######################\n","loss: 0.013857\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0022000.weight\n","########### iter 0022100 ######################\n","loss: 0.013807\n","########### iter 0022200 ######################\n","loss: 0.013497\n","########### iter 0022300 ######################\n","loss: 0.013920\n","########### iter 0022400 ######################\n","loss: 0.013683\n","########### iter 0022500 ######################\n","loss: 0.013682\n","########### iter 0022600 ######################\n","loss: 0.013443\n","########### iter 0022700 ######################\n","loss: 0.013884\n","########### iter 0022800 ######################\n","loss: 0.013328\n","########### iter 0022900 ######################\n","loss: 0.013258\n","########### iter 0023000 ######################\n","loss: 0.013034\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0023000.weight\n","########### iter 0023100 ######################\n","loss: 0.012769\n","########### iter 0023200 ######################\n","loss: 0.013228\n","########### iter 0023300 ######################\n","loss: 0.012424\n","########### iter 0023400 ######################\n","loss: 0.013059\n","########### iter 0023500 ######################\n","loss: 0.012891\n","########### iter 0023600 ######################\n","loss: 0.013121\n","########### iter 0023700 ######################\n","loss: 0.012884\n","########### iter 0023800 ######################\n","loss: 0.012547\n","########### iter 0023900 ######################\n","loss: 0.012270\n","########### iter 0024000 ######################\n","loss: 0.012155\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0024000.weight\n","########### iter 0024100 ######################\n","loss: 0.012532\n","########### iter 0024200 ######################\n","loss: 0.013101\n","########### iter 0024300 ######################\n","loss: 0.012034\n","########### iter 0024400 ######################\n","loss: 0.012687\n","########### iter 0024500 ######################\n","loss: 0.011803\n","########### iter 0024600 ######################\n","loss: 0.011808\n","########### iter 0024700 ######################\n","loss: 0.012107\n","########### iter 0024800 ######################\n","loss: 0.012464\n","########### iter 0024900 ######################\n","loss: 0.012041\n","########### iter 0025000 ######################\n","loss: 0.011944\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0025000.weight\n","########### iter 0025100 ######################\n","loss: 0.012120\n","########### iter 0025200 ######################\n","loss: 0.011639\n","########### iter 0025300 ######################\n","loss: 0.012051\n","########### iter 0025400 ######################\n","loss: 0.012032\n","########### iter 0025500 ######################\n","loss: 0.011490\n","########### iter 0025600 ######################\n","loss: 0.011538\n","########### iter 0025700 ######################\n","loss: 0.011320\n","########### iter 0025800 ######################\n","loss: 0.011688\n","########### iter 0025900 ######################\n","loss: 0.011335\n","########### iter 0026000 ######################\n","loss: 0.011390\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0026000.weight\n","########### iter 0026100 ######################\n","loss: 0.011437\n","########### iter 0026200 ######################\n","loss: 0.011241\n","########### iter 0026300 ######################\n","loss: 0.011355\n","########### iter 0026400 ######################\n","loss: 0.010815\n","########### iter 0026500 ######################\n","loss: 0.011747\n","########### iter 0026600 ######################\n","loss: 0.011114\n","########### iter 0026700 ######################\n","loss: 0.011093\n","########### iter 0026800 ######################\n","loss: 0.011294\n","########### iter 0026900 ######################\n","loss: 0.010936\n","########### iter 0027000 ######################\n","loss: 0.010578\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0027000.weight\n","########### iter 0027100 ######################\n","loss: 0.011110\n","########### iter 0027200 ######################\n","loss: 0.010995\n","########### iter 0027300 ######################\n","loss: 0.011098\n","########### iter 0027400 ######################\n","loss: 0.011738\n","########### iter 0027500 ######################\n","loss: 0.010557\n","########### iter 0027600 ######################\n","loss: 0.010661\n","########### iter 0027700 ######################\n","loss: 0.010728\n","########### iter 0027800 ######################\n","loss: 0.010237\n","########### iter 0027900 ######################\n","loss: 0.010466\n","########### iter 0028000 ######################\n","loss: 0.010926\n"]}]},{"cell_type":"markdown","source":["# Synthesis"],"metadata":{"id":"PHzsDI2kjb_Y"}},{"cell_type":"code","source":["# Define paths for training outputs\n","QUAD_DATA_DIR = \"/content/project645/train_data_quad/salsa/\" # Created by preprocessing script\n","METADATA_QUAD_PATH = os.path.join(QUAD_DATA_DIR, \"metadata_quad.json\")\n","QUAD_WEIGHTS_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"weights_quad\")\n","QUAD_TRAIN_BVH_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"train_output_bvh_quad\")\n","os.makedirs(QUAD_WEIGHTS_DIR, exist_ok=True)\n","os.makedirs(QUAD_TRAIN_BVH_DIR, exist_ok=True)\n","\n","# Define paths and parameters for synthesis\n","QUAD_SYNTH_BVH_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"synthesis_output_bvh_quad\")\n","os.makedirs(QUAD_SYNTH_BVH_DIR, exist_ok=True)\n","\n","# Determine the latest weight file based on TOTAL_ITERATIONS_QUAD\n","# Assuming weight files are saved with leading zeros, e.g., 0050000.weight\n","LATEST_QUAD_WEIGHT_FILE_NAME = f\"{22000:07d}.weight\"\n","LATEST_QUAD_WEIGHT_PATH = os.path.join(QUAD_WEIGHTS_DIR, LATEST_QUAD_WEIGHT_FILE_NAME)\n","\n","# Standard BVH path is relative to the /code directory.\n","STANDARD_BVH_PATH_SYNTH = \"../train_data_bvh/standard.bvh\"\n","\n","# Synthesis script parameters\n","SYNTH_BATCH_SIZE = 1\n","SYNTH_INITIAL_SEQ_LEN = 300\n","SYNTH_GENERATE_FRAMES = 400\n","SYNTH_HIDDEN_SIZE = 1024 # Should match the trained model's hidden size\n","SYNTH_QUANT_COMPARE_LEN = 20 # For quantitative evaluation if seed data allows\n","\n","# Check if the specific weight file exists, otherwise, it might cause an error.\n","print(f\"Attempting to use weight file: {LATEST_QUAD_WEIGHT_PATH}\")\n","if not os.path.exists(LATEST_QUAD_WEIGHT_PATH):\n","    print(f\"WARNING: Weight file {LATEST_QUAD_WEIGHT_PATH} not found. Synthesis might fail or use an uninitialized model if the script handles this.\")\n","    print(f\"Please check the QUAD_WEIGHTS_DIR ({QUAD_WEIGHTS_DIR}) for available .weight files.\")\n","    print(\"You might need to adjust LATEST_QUAD_WEIGHT_FILE_NAME or ensure training completed successfully and saved the model.\")\n","\n","!python synthesize_quad_motion.py \\\n","    --read_weight_path \"{LATEST_QUAD_WEIGHT_PATH}\" \\\n","    --dances_folder \"{QUAD_DATA_DIR}\" \\\n","    --metadata_path \"{METADATA_QUAD_PATH}\" \\\n","    --write_bvh_motion_folder \"{QUAD_SYNTH_BVH_DIR}/\" \\\n","    --standard_bvh_file \"{STANDARD_BVH_PATH_SYNTH}\" \\\n","    --batch_size {SYNTH_BATCH_SIZE} \\\n","    --initial_seq_len {SYNTH_INITIAL_SEQ_LEN} \\\n","    --generate_frames_number {SYNTH_GENERATE_FRAMES} \\\n","    --hidden_size {SYNTH_HIDDEN_SIZE} \\\n","    --quantitative_comparison_len {SYNTH_QUANT_COMPARE_LEN}\n","\n","print(f\"\\n--- Quaternion synthesis finished. Check {QUAD_SYNTH_BVH_DIR} for generated BVH files. ---\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4I1ju6cjdsv","executionInfo":{"status":"ok","timestamp":1747796077463,"user_tz":-180,"elapsed":15347,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"4839fc8b-316d-437f-f2a2-873a5b2fdaf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attempting to use weight file: /content/drive/MyDrive/mai645_project_outputs_v2t1/weights_quad/0022000.weight\n","Using device: cuda\n","Loaded metadata from /content/project645/train_data_quad/salsa/metadata_quad.json\n","Loading motion files from /content/project645/train_data_quad/salsa/...\n","Loaded 01.npy, frames: 2243\n","Loaded 02.npy, frames: 2102\n","Loaded 03.npy, frames: 1831\n","Loaded 04.npy, frames: 1872\n","Loaded 05.npy, frames: 1679\n","Loaded 06.npy, frames: 1773\n","Loaded 07.npy, frames: 2072\n","Loaded 08.npy, frames: 3422\n","Loaded 09.npy, frames: 2576\n","Loaded 10.npy, frames: 1198\n","Loaded 11.npy, frames: 2109\n","Loaded 12.npy, frames: 1691\n","Loaded 13.npy, frames: 2272\n","Loaded 14.npy, frames: 1950\n","Loaded 15.npy, frames: 2141\n","Loaded 16.npy, frames: 2243\n","Loaded 17.npy, frames: 2102\n","Loaded 18.npy, frames: 1831\n","Loaded 19.npy, frames: 1872\n","Loaded 20.npy, frames: 1679\n","Loaded 21.npy, frames: 1773\n","Loaded 22.npy, frames: 2072\n","Loaded 23.npy, frames: 3422\n","Loaded 24.npy, frames: 2576\n","Loaded 25.npy, frames: 1198\n","Loaded 26.npy, frames: 2109\n","Loaded 27.npy, frames: 1691\n","Loaded 28.npy, frames: 2272\n","Loaded 29.npy, frames: 1950\n","Loaded 30.npy, frames: 2141\n","30 motion files loaded.\n","Batch 0: Dance 22 (len 3422), start source frame 592\n","DEBUG: Frame for starting generation (hip_x_diff, hip_y_abs, hip_z_diff): 0.0281, 0.8275, 0.0425\n","DEBUG: Gen step 0 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0281, 0.8275, 0.0425\n","DEBUG: Gen step 0 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0404, 0.8420, 0.0356\n","DEBUG: Gen step 1 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0404, 0.8420, 0.0356\n","DEBUG: Gen step 1 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0583, 0.8337, 0.0225\n","DEBUG: Gen step 2 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0583, 0.8337, 0.0225\n","DEBUG: Gen step 2 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0667, 0.8138, 0.0016\n","DEBUG: Gen step 3 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0667, 0.8138, 0.0016\n","DEBUG: Gen step 3 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0781, 0.7949, -0.0259\n","DEBUG: Gen step 4 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0781, 0.7949, -0.0259\n","DEBUG: Gen step 4 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0874, 0.7798, -0.0397\n","DEBUG: Gen step 5 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0874, 0.7798, -0.0397\n","DEBUG: Gen step 5 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0920, 0.7683, -0.0315\n","DEBUG: Gen step 6 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0920, 0.7683, -0.0315\n","DEBUG: Gen step 6 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0966, 0.7660, -0.0151\n","DEBUG: Gen step 7 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0966, 0.7660, -0.0151\n","DEBUG: Gen step 7 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0991, 0.7739, -0.0054\n","DEBUG: Gen step 8 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0991, 0.7739, -0.0054\n","DEBUG: Gen step 8 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0926, 0.7837, -0.0011\n","DEBUG: Gen step 9 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0926, 0.7837, -0.0011\n","DEBUG: Gen step 9 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0793, 0.7886, 0.0017\n","DEBUG: Gen step 10 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0793, 0.7886, 0.0017\n","DEBUG: Gen step 10 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0659, 0.7901, 0.0040\n","DEBUG: Gen step 11 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0659, 0.7901, 0.0040\n","DEBUG: Gen step 11 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0550, 0.7898, 0.0049\n","DEBUG: Gen step 12 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0550, 0.7898, 0.0049\n","DEBUG: Gen step 12 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0451, 0.7866, 0.0041\n","DEBUG: Gen step 13 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0451, 0.7866, 0.0041\n","DEBUG: Gen step 13 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0362, 0.7813, 0.0024\n","DEBUG: Gen step 14 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0362, 0.7813, 0.0024\n","DEBUG: Gen step 14 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0297, 0.7747, 0.0007\n","DEBUG: Gen step 15 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0297, 0.7747, 0.0007\n","DEBUG: Gen step 15 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0254, 0.7672, -0.0016\n","DEBUG: Gen step 16 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0254, 0.7672, -0.0016\n","DEBUG: Gen step 16 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0219, 0.7590, -0.0045\n","DEBUG: Gen step 17 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0219, 0.7590, -0.0045\n","DEBUG: Gen step 17 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0188, 0.7507, -0.0076\n","DEBUG: Gen step 18 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0188, 0.7507, -0.0076\n","DEBUG: Gen step 18 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0159, 0.7430, -0.0099\n","DEBUG: Gen step 19 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0159, 0.7430, -0.0099\n","DEBUG: Gen step 19 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0137, 0.7366, -0.0109\n","DEBUG: Gen step 20 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0137, 0.7366, -0.0109\n","DEBUG: Gen step 20 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0121, 0.7322, -0.0108\n","DEBUG: Gen step 21 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0121, 0.7322, -0.0108\n","DEBUG: Gen step 21 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0108, 0.7299, -0.0098\n","DEBUG: Gen step 22 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0108, 0.7299, -0.0098\n","DEBUG: Gen step 22 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0098, 0.7295, -0.0084\n","DEBUG: Gen step 23 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0098, 0.7295, -0.0084\n","DEBUG: Gen step 23 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0089, 0.7306, -0.0070\n","DEBUG: Gen step 24 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0089, 0.7306, -0.0070\n","DEBUG: Gen step 24 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0081, 0.7326, -0.0057\n","DEBUG: Gen step 25 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0081, 0.7326, -0.0057\n","DEBUG: Gen step 25 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0075, 0.7350, -0.0046\n","DEBUG: Gen step 26 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0075, 0.7350, -0.0046\n","DEBUG: Gen step 26 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0070, 0.7374, -0.0037\n","DEBUG: Gen step 27 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0070, 0.7374, -0.0037\n","DEBUG: Gen step 27 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0067, 0.7394, -0.0031\n","DEBUG: Gen step 28 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0067, 0.7394, -0.0031\n","DEBUG: Gen step 28 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0065, 0.7409, -0.0025\n","DEBUG: Gen step 29 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0065, 0.7409, -0.0025\n","DEBUG: Gen step 29 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0063, 0.7418, -0.0021\n","DEBUG: Gen step 40 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0052, 0.7420, -0.0002\n","DEBUG: Gen step 40 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0052, 0.7422, -0.0002\n","DEBUG: Gen step 60 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0048, 0.7429, 0.0001\n","DEBUG: Gen step 60 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0048, 0.7429, 0.0001\n","DEBUG: Gen step 80 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0001\n","DEBUG: Gen step 80 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0001\n","DEBUG: Gen step 100 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0001\n","DEBUG: Gen step 100 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0001\n","DEBUG: Gen step 120 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 120 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 140 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 140 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 160 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 160 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 180 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 180 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 200 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 200 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 220 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 220 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 240 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 240 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 260 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 260 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 280 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 280 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 300 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 300 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 320 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 320 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 340 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 340 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 360 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 360 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 380 - Input to LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","DEBUG: Gen step 380 - Output from LSTM (hip_x_diff, hip_y_abs, hip_z_diff): 0.0047, 0.7431, 0.0002\n","Batch 0: Quant Eval (first 20 frames) - Total Loss: 0.0850, Hip MSE: 0.0012, Rot Quat Loss: 0.0837\n","Quaternion motion synthesis complete. BVH files saved to: /content/drive/MyDrive/mai645_project_outputs_v2t1/synthesis_output_bvh_quad/\n","\n","--- Quaternion synthesis finished. Check /content/drive/MyDrive/mai645_project_outputs_v2t1/synthesis_output_bvh_quad for generated BVH files. ---\n"]}]}]}