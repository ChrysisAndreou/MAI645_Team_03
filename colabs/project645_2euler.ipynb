{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setting up data and env"],"metadata":{"id":"nBuehlq35L4x"}},{"cell_type":"markdown","source":["## Upload Your Project"],"metadata":{"id":"zK_iE6Rb219f"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":128},"id":"GWfv5Zzc2eZv","executionInfo":{"status":"ok","timestamp":1747900310813,"user_tz":-180,"elapsed":137162,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"d9587ab3-8c35-4898-d1a6-b2886dce5694"},"outputs":[{"output_type":"stream","name":"stdout","text":["Upload your project645.zip file...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6ca3f0b3-5bf1-4f96-89c5-e67987d60692\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6ca3f0b3-5bf1-4f96-89c5-e67987d60692\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving project645.zip to project645.zip\n","User uploaded file \"project645.zip\" with length 24134759 bytes\n"]}],"source":["from google.colab import files\n","print(\"Upload your project645.zip file...\")\n","uploaded = files.upload()\n","\n","# Verify upload\n","for fn in uploaded.keys():\n","  print(f'User uploaded file \"{fn}\" with length {len(uploaded[fn])} bytes')"]},{"cell_type":"markdown","source":["## Unzip the project"],"metadata":{"id":"wKZyBp5y3dhD"}},{"cell_type":"code","source":["!unzip -q project645.zip -d /content/\n","# Verify unzip by listing contents\n","!ls /content/project645/\n","!ls /content/project645/code/"],"metadata":{"id":"CaZYeN_63YNo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747900393357,"user_tz":-180,"elapsed":1024,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"f3824cbe-0b8b-4467-e485-a3d2eba2d8f4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["code  LICENSE  mai645.yml  README.md  train_data_bvh\n","analysis.py\n","fix_feet.py\n","generate_training_euler_data.py\n","generate_training_pos_data.py\n","generate_training_quad_data.py\n","plot_euler_loss.py\n","plot_loss.py\n","__pycache__\n","pytorch_train_euler_aclstm_for_calculating_loss_to_device.py\n","pytorch_train_euler_aclstm.py\n","pytorch_train_pos_aclstm_for_calculating_loss_to_device.py\n","pytorch_train_pos_aclstm.py\n","pytorch_train_quad_aclstm.py\n","read_bvh_hierarchy.py\n","read_bvh_hierarchy.pyc\n","read_bvh.py\n","read_bvh.pyc\n","rotation2xyz.py\n","rotation2xyz.pyc\n","rotation_conversions.py\n","synthesize_euler_motion.py\n","synthesize_pos_motion_original_colab.py\n","synthesize_pos_motion.py\n","synthesize_quad_motion.py\n","test_encodings.py\n"]}]},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"F7XrtRYE3lSl"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSBSPgkp3nqG","executionInfo":{"status":"ok","timestamp":1747900414132,"user_tz":-180,"elapsed":19213,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"e55aef7f-26ad-424f-e1e2-39cec56d66a9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Create Output Folder"],"metadata":{"id":"HGWxCQaAfKCC"}},{"cell_type":"markdown","source":["*   **Create an Output Folder in Google Drive:** It's highly recommended to create a dedicated folder in your Google Drive to store the outputs (trained models, generated data/BVH files). For example, you could create a folder named `mai645_project_outputs` directly in your \"My Drive\".\n","*   Define a variable in Colab pointing to this Drive folder. **Make sure the path matches the folder you created.**"],"metadata":{"id":"bcZi7xIM33-g"}},{"cell_type":"code","source":["# IMPORTANT: Adjust this path if you named your Drive folder differently!\n","GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs\"\n","# Create the directory in Drive if it doesn't exist (optional, Colab can create it)\n","import os\n","os.makedirs(GDRIVE_OUTPUT_DIR, exist_ok=True)\n","print(f\"Outputs will be saved to: {GDRIVE_OUTPUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbv-wNTk34sD","executionInfo":{"status":"ok","timestamp":1747900416421,"user_tz":-180,"elapsed":487,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"07aeca30-be67-4fb7-c905-e99b528961e0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Outputs will be saved to: /content/drive/MyDrive/mai645_project_outputs\n"]}]},{"cell_type":"markdown","source":["## Install Dependencies"],"metadata":{"id":"K6fxAysh4Aza"}},{"cell_type":"code","source":["# Install the latest compatible PyTorch, torchvision, torchaudio for this Colab environment\n","!pip install -q torch torchvision torchaudio\n","\n","# Install other libraries, specifically targeting numpy in the 2.0.x range.\n","# This aims to satisfy thinc (>=2.0.0) AND tensorflow/numba (<2.1.0).\n","!pip install -q contourpy==1.3.1 cycler==0.12.1 fonttools==4.56.0 kiwisolver==1.4.8 matplotlib==3.10.1 \"numpy>=2.0.0,<2.1.0\" opencv-python==4.11.0.86 packaging==24.2 pyparsing==3.2.3 python-dateutil==2.9.0.post0 six==1.17.0 transforms3d==0.4.2\n","\n","# Verify installation\n","!pip show torch torchvision torchaudio transforms3d numpy opencv-python tensorflow numba"],"metadata":{"id":"iiDk6zZ34Ch8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747900533120,"user_tz":-180,"elapsed":115077,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"630676af-5ea6-4a30-9c60-0dd5c3dbf3e3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hName: torch\n","Version: 2.6.0+cu124\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3-Clause\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n","Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchvision\n","---\n","Name: torchvision\n","Version: 0.21.0+cu124\n","Summary: image and video datasets and models for torch deep learning\n","Home-page: https://github.com/pytorch/vision\n","Author: PyTorch Core Team\n","Author-email: soumith@pytorch.org\n","License: BSD\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: numpy, pillow, torch\n","Required-by: fastai, timm\n","---\n","Name: torchaudio\n","Version: 2.6.0+cu124\n","Summary: An audio package for PyTorch\n","Home-page: https://github.com/pytorch/audio\n","Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n","Author-email: soumith@pytorch.org\n","License: \n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: torch\n","Required-by: \n","---\n","Name: transforms3d\n","Version: 0.4.2\n","Summary: Functions for 3D coordinate transformations\n","Home-page: http://github.com/matthew-brett/transforms3d\n","Author: \n","Author-email: Matthew Brett <matthew.brett@gmail.com>\n","License: BSD license\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: numpy\n","Required-by: \n","---\n","Name: numpy\n","Version: 2.0.2\n","Summary: Fundamental package for array computing in Python\n","Home-page: https://numpy.org\n","Author: Travis E. Oliphant et al.\n","Author-email: \n","License: Copyright (c) 2005-2024, NumPy Developers.\n","All rights reserved.\n","\n","Redistribution and use in source and binary forms, with or without\n","modification, are permitted provided that the following conditions are\n","met:\n","\n","    * Redistributions of source code must retain the above copyright\n","       notice, this list of conditions and the following disclaimer.\n","\n","    * Redistributions in binary form must reproduce the above\n","       copyright notice, this list of conditions and the following\n","       disclaimer in the documentation and/or other materials provided\n","       with the distribution.\n","\n","    * Neither the name of the NumPy Developers nor the names of any\n","       contributors may be used to endorse or promote products derived\n","       from this software without specific prior written permission.\n","\n","THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n","\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n","LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n","A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n","OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n","SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n","LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n","DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n","THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n","(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n","OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n","\n","----\n","\n","The NumPy repository and source distributions bundle several libraries that are\n","compatibly licensed.  We list these here.\n","\n","Name: lapack-lite\n","Files: numpy/linalg/lapack_lite/*\n","License: BSD-3-Clause\n","  For details, see numpy/linalg/lapack_lite/LICENSE.txt\n","\n","Name: dragon4\n","Files: numpy/_core/src/multiarray/dragon4.c\n","License: MIT\n","  For license text, see numpy/_core/src/multiarray/dragon4.c\n","\n","Name: libdivide\n","Files: numpy/_core/include/numpy/libdivide/*\n","License: Zlib\n","  For license text, see numpy/_core/include/numpy/libdivide/LICENSE.txt\n","\n","\n","Note that the following files are vendored in the repository and sdist but not\n","installed in built numpy packages:\n","\n","Name: Meson\n","Files: vendored-meson/meson/*\n","License: Apache 2.0\n","  For license text, see vendored-meson/meson/COPYING\n","\n","Name: spin\n","Files: .spin/cmds.py\n","License: BSD-3\n","  For license text, see .spin/LICENSE\n","\n","----\n","\n","This binary distribution of NumPy also bundles the following software:\n","\n","\n","Name: OpenBLAS\n","Files: numpy.libs/libscipy_openblas*.so\n","Description: bundled as a dynamically linked library\n","Availability: https://github.com/OpenMathLib/OpenBLAS/\n","License: BSD-3-Clause\n","  Copyright (c) 2011-2014, The OpenBLAS Project\n","  All rights reserved.\n","\n","  Redistribution and use in source and binary forms, with or without\n","  modification, are permitted provided that the following conditions are\n","  met:\n","\n","     1. Redistributions of source code must retain the above copyright\n","        notice, this list of conditions and the following disclaimer.\n","\n","     2. Redistributions in binary form must reproduce the above copyright\n","        notice, this list of conditions and the following disclaimer in\n","        the documentation and/or other materials provided with the\n","        distribution.\n","     3. Neither the name of the OpenBLAS project nor the names of\n","        its contributors may be used to endorse or promote products\n","        derived from this software without specific prior written\n","        permission.\n","\n","  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n","  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n","  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n","  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE\n","  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n","  DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n","  SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n","  CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n","  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n","  USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n","\n","\n","Name: LAPACK\n","Files: numpy.libs/libscipy_openblas*.so\n","Description: bundled in OpenBLAS\n","Availability: https://github.com/OpenMathLib/OpenBLAS/\n","License: BSD-3-Clause-Attribution\n","  Copyright (c) 1992-2013 The University of Tennessee and The University\n","                          of Tennessee Research Foundation.  All rights\n","                          reserved.\n","  Copyright (c) 2000-2013 The University of California Berkeley. All\n","                          rights reserved.\n","  Copyright (c) 2006-2013 The University of Colorado Denver.  All rights\n","                          reserved.\n","\n","  $COPYRIGHT$\n","\n","  Additional copyrights may follow\n","\n","  $HEADER$\n","\n","  Redistribution and use in source and binary forms, with or without\n","  modification, are permitted provided that the following conditions are\n","  met:\n","\n","  - Redistributions of source code must retain the above copyright\n","    notice, this list of conditions and the following disclaimer.\n","\n","  - Redistributions in binary form must reproduce the above copyright\n","    notice, this list of conditions and the following disclaimer listed\n","    in this license in the documentation and/or other materials\n","    provided with the distribution.\n","\n","  - Neither the name of the copyright holders nor the names of its\n","    contributors may be used to endorse or promote products derived from\n","    this software without specific prior written permission.\n","\n","  The copyright holders provide no reassurances that the source code\n","  provided does not infringe any patent, copyright, or any other\n","  intellectual property rights of third parties.  The copyright holders\n","  disclaim any liability to any recipient for claims brought against\n","  recipient by any third party for infringement of that parties\n","  intellectual property rights.\n","\n","  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n","  \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n","  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n","  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n","  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n","  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n","  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n","  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n","  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n","  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n","  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n","\n","\n","Name: GCC runtime library\n","Files: numpy.libs/libgfortran*.so\n","Description: dynamically linked to files compiled with gcc\n","Availability: https://gcc.gnu.org/git/?p=gcc.git;a=tree;f=libgfortran\n","License: GPL-3.0-with-GCC-exception\n","  Copyright (C) 2002-2017 Free Software Foundation, Inc.\n","\n","  Libgfortran is free software; you can redistribute it and/or modify\n","  it under the terms of the GNU General Public License as published by\n","  the Free Software Foundation; either version 3, or (at your option)\n","  any later version.\n","\n","  Libgfortran is distributed in the hope that it will be useful,\n","  but WITHOUT ANY WARRANTY; without even the implied warranty of\n","  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","  GNU General Public License for more details.\n","\n","  Under Section 7 of GPL version 3, you are granted additional\n","  permissions described in the GCC Runtime Library Exception, version\n","  3.1, as published by the Free Software Foundation.\n","\n","  You should have received a copy of the GNU General Public License and\n","  a copy of the GCC Runtime Library Exception along with this program;\n","  see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see\n","  <http://www.gnu.org/licenses/>.\n","\n","----\n","\n","Full text of license texts referred to above follows (that they are\n","listed below does not necessarily imply the conditions apply to the\n","present binary release):\n","\n","----\n","\n","GCC RUNTIME LIBRARY EXCEPTION\n","\n","Version 3.1, 31 March 2009\n","\n","Copyright (C) 2009 Free Software Foundation, Inc. <http://fsf.org/>\n","\n","Everyone is permitted to copy and distribute verbatim copies of this\n","license document, but changing it is not allowed.\n","\n","This GCC Runtime Library Exception (\"Exception\") is an additional\n","permission under section 7 of the GNU General Public License, version\n","3 (\"GPLv3\"). It applies to a given file (the \"Runtime Library\") that\n","bears a notice placed by the copyright holder of the file stating that\n","the file is governed by GPLv3 along with this Exception.\n","\n","When you use GCC to compile a program, GCC may combine portions of\n","certain GCC header files and runtime libraries with the compiled\n","program. The purpose of this Exception is to allow compilation of\n","non-GPL (including proprietary) programs to use, in this way, the\n","header files and runtime libraries covered by this Exception.\n","\n","0. Definitions.\n","\n","A file is an \"Independent Module\" if it either requires the Runtime\n","Library for execution after a Compilation Process, or makes use of an\n","interface provided by the Runtime Library, but is not otherwise based\n","on the Runtime Library.\n","\n","\"GCC\" means a version of the GNU Compiler Collection, with or without\n","modifications, governed by version 3 (or a specified later version) of\n","the GNU General Public License (GPL) with the option of using any\n","subsequent versions published by the FSF.\n","\n","\"GPL-compatible Software\" is software whose conditions of propagation,\n","modification and use would permit combination with GCC in accord with\n","the license of GCC.\n","\n","\"Target Code\" refers to output from any compiler for a real or virtual\n","target processor architecture, in executable form or suitable for\n","input to an assembler, loader, linker and/or execution\n","phase. Notwithstanding that, Target Code does not include data in any\n","format that is used as a compiler intermediate representation, or used\n","for producing a compiler intermediate representation.\n","\n","The \"Compilation Process\" transforms code entirely represented in\n","non-intermediate languages designed for human-written code, and/or in\n","Java Virtual Machine byte code, into Target Code. Thus, for example,\n","use of source code generators and preprocessors need not be considered\n","part of the Compilation Process, since the Compilation Process can be\n","understood as starting with the output of the generators or\n","preprocessors.\n","\n","A Compilation Process is \"Eligible\" if it is done using GCC, alone or\n","with other GPL-compatible software, or if it is done without using any\n","work based on GCC. For example, using non-GPL-compatible Software to\n","optimize any GCC intermediate representations would not qualify as an\n","Eligible Compilation Process.\n","\n","1. Grant of Additional Permission.\n","\n","You have permission to propagate a work of Target Code formed by\n","combining the Runtime Library with Independent Modules, even if such\n","propagation would otherwise violate the terms of GPLv3, provided that\n","all Target Code was generated by Eligible Compilation Processes. You\n","may then convey such a combination under terms of your choice,\n","consistent with the licensing of the Independent Modules.\n","\n","2. No Weakening of GCC Copyleft.\n","\n","The availability of this Exception does not imply any general\n","presumption that third-party software is unaffected by the copyleft\n","requirements of the license of GCC.\n","\n","----\n","\n","                    GNU GENERAL PUBLIC LICENSE\n","                       Version 3, 29 June 2007\n","\n"," Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>\n"," Everyone is permitted to copy and distribute verbatim copies\n"," of this license document, but changing it is not allowed.\n","\n","                            Preamble\n","\n","  The GNU General Public License is a free, copyleft license for\n","software and other kinds of works.\n","\n","  The licenses for most software and other practical works are designed\n","to take away your freedom to share and change the works.  By contrast,\n","the GNU General Public License is intended to guarantee your freedom to\n","share and change all versions of a program--to make sure it remains free\n","software for all its users.  We, the Free Software Foundation, use the\n","GNU General Public License for most of our software; it applies also to\n","any other work released this way by its authors.  You can apply it to\n","your programs, too.\n","\n","  When we speak of free software, we are referring to freedom, not\n","price.  Our General Public Licenses are designed to make sure that you\n","have the freedom to distribute copies of free software (and charge for\n","them if you wish), that you receive source code or can get it if you\n","want it, that you can change the software or use pieces of it in new\n","free programs, and that you know you can do these things.\n","\n","  To protect your rights, we need to prevent others from denying you\n","these rights or asking you to surrender the rights.  Therefore, you have\n","certain responsibilities if you distribute copies of the software, or if\n","you modify it: responsibilities to respect the freedom of others.\n","\n","  For example, if you distribute copies of such a program, whether\n","gratis or for a fee, you must pass on to the recipients the same\n","freedoms that you received.  You must make sure that they, too, receive\n","or can get the source code.  And you must show them these terms so they\n","know their rights.\n","\n","  Developers that use the GNU GPL protect your rights with two steps:\n","(1) assert copyright on the software, and (2) offer you this License\n","giving you legal permission to copy, distribute and/or modify it.\n","\n","  For the developers' and authors' protection, the GPL clearly explains\n","that there is no warranty for this free software.  For both users' and\n","authors' sake, the GPL requires that modified versions be marked as\n","changed, so that their problems will not be attributed erroneously to\n","authors of previous versions.\n","\n","  Some devices are designed to deny users access to install or run\n","modified versions of the software inside them, although the manufacturer\n","can do so.  This is fundamentally incompatible with the aim of\n","protecting users' freedom to change the software.  The systematic\n","pattern of such abuse occurs in the area of products for individuals to\n","use, which is precisely where it is most unacceptable.  Therefore, we\n","have designed this version of the GPL to prohibit the practice for those\n","products.  If such problems arise substantially in other domains, we\n","stand ready to extend this provision to those domains in future versions\n","of the GPL, as needed to protect the freedom of users.\n","\n","  Finally, every program is threatened constantly by software patents.\n","States should not allow patents to restrict development and use of\n","software on general-purpose computers, but in those that do, we wish to\n","avoid the special danger that patents applied to a free program could\n","make it effectively proprietary.  To prevent this, the GPL assures that\n","patents cannot be used to render the program non-free.\n","\n","  The precise terms and conditions for copying, distribution and\n","modification follow.\n","\n","                       TERMS AND CONDITIONS\n","\n","  0. Definitions.\n","\n","  \"This License\" refers to version 3 of the GNU General Public License.\n","\n","  \"Copyright\" also means copyright-like laws that apply to other kinds of\n","works, such as semiconductor masks.\n","\n","  \"The Program\" refers to any copyrightable work licensed under this\n","License.  Each licensee is addressed as \"you\".  \"Licensees\" and\n","\"recipients\" may be individuals or organizations.\n","\n","  To \"modify\" a work means to copy from or adapt all or part of the work\n","in a fashion requiring copyright permission, other than the making of an\n","exact copy.  The resulting work is called a \"modified version\" of the\n","earlier work or a work \"based on\" the earlier work.\n","\n","  A \"covered work\" means either the unmodified Program or a work based\n","on the Program.\n","\n","  To \"propagate\" a work means to do anything with it that, without\n","permission, would make you directly or secondarily liable for\n","infringement under applicable copyright law, except executing it on a\n","computer or modifying a private copy.  Propagation includes copying,\n","distribution (with or without modification), making available to the\n","public, and in some countries other activities as well.\n","\n","  To \"convey\" a work means any kind of propagation that enables other\n","parties to make or receive copies.  Mere interaction with a user through\n","a computer network, with no transfer of a copy, is not conveying.\n","\n","  An interactive user interface displays \"Appropriate Legal Notices\"\n","to the extent that it includes a convenient and prominently visible\n","feature that (1) displays an appropriate copyright notice, and (2)\n","tells the user that there is no warranty for the work (except to the\n","extent that warranties are provided), that licensees may convey the\n","work under this License, and how to view a copy of this License.  If\n","the interface presents a list of user commands or options, such as a\n","menu, a prominent item in the list meets this criterion.\n","\n","  1. Source Code.\n","\n","  The \"source code\" for a work means the preferred form of the work\n","for making modifications to it.  \"Object code\" means any non-source\n","form of a work.\n","\n","  A \"Standard Interface\" means an interface that either is an official\n","standard defined by a recognized standards body, or, in the case of\n","interfaces specified for a particular programming language, one that\n","is widely used among developers working in that language.\n","\n","  The \"System Libraries\" of an executable work include anything, other\n","than the work as a whole, that (a) is included in the normal form of\n","packaging a Major Component, but which is not part of that Major\n","Component, and (b) serves only to enable use of the work with that\n","Major Component, or to implement a Standard Interface for which an\n","implementation is available to the public in source code form.  A\n","\"Major Component\", in this context, means a major essential component\n","(kernel, window system, and so on) of the specific operating system\n","(if any) on which the executable work runs, or a compiler used to\n","produce the work, or an object code interpreter used to run it.\n","\n","  The \"Corresponding Source\" for a work in object code form means all\n","the source code needed to generate, install, and (for an executable\n","work) run the object code and to modify the work, including scripts to\n","control those activities.  However, it does not include the work's\n","System Libraries, or general-purpose tools or generally available free\n","programs which are used unmodified in performing those activities but\n","which are not part of the work.  For example, Corresponding Source\n","includes interface definition files associated with source files for\n","the work, and the source code for shared libraries and dynamically\n","linked subprograms that the work is specifically designed to require,\n","such as by intimate data communication or control flow between those\n","subprograms and other parts of the work.\n","\n","  The Corresponding Source need not include anything that users\n","can regenerate automatically from other parts of the Corresponding\n","Source.\n","\n","  The Corresponding Source for a work in source code form is that\n","same work.\n","\n","  2. Basic Permissions.\n","\n","  All rights granted under this License are granted for the term of\n","copyright on the Program, and are irrevocable provided the stated\n","conditions are met.  This License explicitly affirms your unlimited\n","permission to run the unmodified Program.  The output from running a\n","covered work is covered by this License only if the output, given its\n","content, constitutes a covered work.  This License acknowledges your\n","rights of fair use or other equivalent, as provided by copyright law.\n","\n","  You may make, run and propagate covered works that you do not\n","convey, without conditions so long as your license otherwise remains\n","in force.  You may convey covered works to others for the sole purpose\n","of having them make modifications exclusively for you, or provide you\n","with facilities for running those works, provided that you comply with\n","the terms of this License in conveying all material for which you do\n","not control copyright.  Those thus making or running the covered works\n","for you must do so exclusively on your behalf, under your direction\n","and control, on terms that prohibit them from making any copies of\n","your copyrighted material outside their relationship with you.\n","\n","  Conveying under any other circumstances is permitted solely under\n","the conditions stated below.  Sublicensing is not allowed; section 10\n","makes it unnecessary.\n","\n","  3. Protecting Users' Legal Rights From Anti-Circumvention Law.\n","\n","  No covered work shall be deemed part of an effective technological\n","measure under any applicable law fulfilling obligations under article\n","11 of the WIPO copyright treaty adopted on 20 December 1996, or\n","similar laws prohibiting or restricting circumvention of such\n","measures.\n","\n","  When you convey a covered work, you waive any legal power to forbid\n","circumvention of technological measures to the extent such circumvention\n","is effected by exercising rights under this License with respect to\n","the covered work, and you disclaim any intention to limit operation or\n","modification of the work as a means of enforcing, against the work's\n","users, your or third parties' legal rights to forbid circumvention of\n","technological measures.\n","\n","  4. Conveying Verbatim Copies.\n","\n","  You may convey verbatim copies of the Program's source code as you\n","receive it, in any medium, provided that you conspicuously and\n","appropriately publish on each copy an appropriate copyright notice;\n","keep intact all notices stating that this License and any\n","non-permissive terms added in accord with section 7 apply to the code;\n","keep intact all notices of the absence of any warranty; and give all\n","recipients a copy of this License along with the Program.\n","\n","  You may charge any price or no price for each copy that you convey,\n","and you may offer support or warranty protection for a fee.\n","\n","  5. Conveying Modified Source Versions.\n","\n","  You may convey a work based on the Program, or the modifications to\n","produce it from the Program, in the form of source code under the\n","terms of section 4, provided that you also meet all of these conditions:\n","\n","    a) The work must carry prominent notices stating that you modified\n","    it, and giving a relevant date.\n","\n","    b) The work must carry prominent notices stating that it is\n","    released under this License and any conditions added under section\n","    7.  This requirement modifies the requirement in section 4 to\n","    \"keep intact all notices\".\n","\n","    c) You must license the entire work, as a whole, under this\n","    License to anyone who comes into possession of a copy.  This\n","    License will therefore apply, along with any applicable section 7\n","    additional terms, to the whole of the work, and all its parts,\n","    regardless of how they are packaged.  This License gives no\n","    permission to license the work in any other way, but it does not\n","    invalidate such permission if you have separately received it.\n","\n","    d) If the work has interactive user interfaces, each must display\n","    Appropriate Legal Notices; however, if the Program has interactive\n","    interfaces that do not display Appropriate Legal Notices, your\n","    work need not make them do so.\n","\n","  A compilation of a covered work with other separate and independent\n","works, which are not by their nature extensions of the covered work,\n","and which are not combined with it such as to form a larger program,\n","in or on a volume of a storage or distribution medium, is called an\n","\"aggregate\" if the compilation and its resulting copyright are not\n","used to limit the access or legal rights of the compilation's users\n","beyond what the individual works permit.  Inclusion of a covered work\n","in an aggregate does not cause this License to apply to the other\n","parts of the aggregate.\n","\n","  6. Conveying Non-Source Forms.\n","\n","  You may convey a covered work in object code form under the terms\n","of sections 4 and 5, provided that you also convey the\n","machine-readable Corresponding Source under the terms of this License,\n","in one of these ways:\n","\n","    a) Convey the object code in, or embodied in, a physical product\n","    (including a physical distribution medium), accompanied by the\n","    Corresponding Source fixed on a durable physical medium\n","    customarily used for software interchange.\n","\n","    b) Convey the object code in, or embodied in, a physical product\n","    (including a physical distribution medium), accompanied by a\n","    written offer, valid for at least three years and valid for as\n","    long as you offer spare parts or customer support for that product\n","    model, to give anyone who possesses the object code either (1) a\n","    copy of the Corresponding Source for all the software in the\n","    product that is covered by this License, on a durable physical\n","    medium customarily used for software interchange, for a price no\n","    more than your reasonable cost of physically performing this\n","    conveying of source, or (2) access to copy the\n","    Corresponding Source from a network server at no charge.\n","\n","    c) Convey individual copies of the object code with a copy of the\n","    written offer to provide the Corresponding Source.  This\n","    alternative is allowed only occasionally and noncommercially, and\n","    only if you received the object code with such an offer, in accord\n","    with subsection 6b.\n","\n","    d) Convey the object code by offering access from a designated\n","    place (gratis or for a charge), and offer equivalent access to the\n","    Corresponding Source in the same way through the same place at no\n","    further charge.  You need not require recipients to copy the\n","    Corresponding Source along with the object code.  If the place to\n","    copy the object code is a network server, the Corresponding Source\n","    may be on a different server (operated by you or a third party)\n","    that supports equivalent copying facilities, provided you maintain\n","    clear directions next to the object code saying where to find the\n","    Corresponding Source.  Regardless of what server hosts the\n","    Corresponding Source, you remain obligated to ensure that it is\n","    available for as long as needed to satisfy these requirements.\n","\n","    e) Convey the object code using peer-to-peer transmission, provided\n","    you inform other peers where the object code and Corresponding\n","    Source of the work are being offered to the general public at no\n","    charge under subsection 6d.\n","\n","  A separable portion of the object code, whose source code is excluded\n","from the Corresponding Source as a System Library, need not be\n","included in conveying the object code work.\n","\n","  A \"User Product\" is either (1) a \"consumer product\", which means any\n","tangible personal property which is normally used for personal, family,\n","or household purposes, or (2) anything designed or sold for incorporation\n","into a dwelling.  In determining whether a product is a consumer product,\n","doubtful cases shall be resolved in favor of coverage.  For a particular\n","product received by a particular user, \"normally used\" refers to a\n","typical or common use of that class of product, regardless of the status\n","of the particular user or of the way in which the particular user\n","actually uses, or expects or is expected to use, the product.  A product\n","is a consumer product regardless of whether the product has substantial\n","commercial, industrial or non-consumer uses, unless such uses represent\n","the only significant mode of use of the product.\n","\n","  \"Installation Information\" for a User Product means any methods,\n","procedures, authorization keys, or other information required to install\n","and execute modified versions of a covered work in that User Product from\n","a modified version of its Corresponding Source.  The information must\n","suffice to ensure that the continued functioning of the modified object\n","code is in no case prevented or interfered with solely because\n","modification has been made.\n","\n","  If you convey an object code work under this section in, or with, or\n","specifically for use in, a User Product, and the conveying occurs as\n","part of a transaction in which the right of possession and use of the\n","User Product is transferred to the recipient in perpetuity or for a\n","fixed term (regardless of how the transaction is characterized), the\n","Corresponding Source conveyed under this section must be accompanied\n","by the Installation Information.  But this requirement does not apply\n","if neither you nor any third party retains the ability to install\n","modified object code on the User Product (for example, the work has\n","been installed in ROM).\n","\n","  The requirement to provide Installation Information does not include a\n","requirement to continue to provide support service, warranty, or updates\n","for a work that has been modified or installed by the recipient, or for\n","the User Product in which it has been modified or installed.  Access to a\n","network may be denied when the modification itself materially and\n","adversely affects the operation of the network or violates the rules and\n","protocols for communication across the network.\n","\n","  Corresponding Source conveyed, and Installation Information provided,\n","in accord with this section must be in a format that is publicly\n","documented (and with an implementation available to the public in\n","source code form), and must require no special password or key for\n","unpacking, reading or copying.\n","\n","  7. Additional Terms.\n","\n","  \"Additional permissions\" are terms that supplement the terms of this\n","License by making exceptions from one or more of its conditions.\n","Additional permissions that are applicable to the entire Program shall\n","be treated as though they were included in this License, to the extent\n","that they are valid under applicable law.  If additional permissions\n","apply only to part of the Program, that part may be used separately\n","under those permissions, but the entire Program remains governed by\n","this License without regard to the additional permissions.\n","\n","  When you convey a copy of a covered work, you may at your option\n","remove any additional permissions from that copy, or from any part of\n","it.  (Additional permissions may be written to require their own\n","removal in certain cases when you modify the work.)  You may place\n","additional permissions on material, added by you to a covered work,\n","for which you have or can give appropriate copyright permission.\n","\n","  Notwithstanding any other provision of this License, for material you\n","add to a covered work, you may (if authorized by the copyright holders of\n","that material) supplement the terms of this License with terms:\n","\n","    a) Disclaiming warranty or limiting liability differently from the\n","    terms of sections 15 and 16 of this License; or\n","\n","    b) Requiring preservation of specified reasonable legal notices or\n","    author attributions in that material or in the Appropriate Legal\n","    Notices displayed by works containing it; or\n","\n","    c) Prohibiting misrepresentation of the origin of that material, or\n","    requiring that modified versions of such material be marked in\n","    reasonable ways as different from the original version; or\n","\n","    d) Limiting the use for publicity purposes of names of licensors or\n","    authors of the material; or\n","\n","    e) Declining to grant rights under trademark law for use of some\n","    trade names, trademarks, or service marks; or\n","\n","    f) Requiring indemnification of licensors and authors of that\n","    material by anyone who conveys the material (or modified versions of\n","    it) with contractual assumptions of liability to the recipient, for\n","    any liability that these contractual assumptions directly impose on\n","    those licensors and authors.\n","\n","  All other non-permissive additional terms are considered \"further\n","restrictions\" within the meaning of section 10.  If the Program as you\n","received it, or any part of it, contains a notice stating that it is\n","governed by this License along with a term that is a further\n","restriction, you may remove that term.  If a license document contains\n","a further restriction but permits relicensing or conveying under this\n","License, you may add to a covered work material governed by the terms\n","of that license document, provided that the further restriction does\n","not survive such relicensing or conveying.\n","\n","  If you add terms to a covered work in accord with this section, you\n","must place, in the relevant source files, a statement of the\n","additional terms that apply to those files, or a notice indicating\n","where to find the applicable terms.\n","\n","  Additional terms, permissive or non-permissive, may be stated in the\n","form of a separately written license, or stated as exceptions;\n","the above requirements apply either way.\n","\n","  8. Termination.\n","\n","  You may not propagate or modify a covered work except as expressly\n","provided under this License.  Any attempt otherwise to propagate or\n","modify it is void, and will automatically terminate your rights under\n","this License (including any patent licenses granted under the third\n","paragraph of section 11).\n","\n","  However, if you cease all violation of this License, then your\n","license from a particular copyright holder is reinstated (a)\n","provisionally, unless and until the copyright holder explicitly and\n","finally terminates your license, and (b) permanently, if the copyright\n","holder fails to notify you of the violation by some reasonable means\n","prior to 60 days after the cessation.\n","\n","  Moreover, your license from a particular copyright holder is\n","reinstated permanently if the copyright holder notifies you of the\n","violation by some reasonable means, this is the first time you have\n","received notice of violation of this License (for any work) from that\n","copyright holder, and you cure the violation prior to 30 days after\n","your receipt of the notice.\n","\n","  Termination of your rights under this section does not terminate the\n","licenses of parties who have received copies or rights from you under\n","this License.  If your rights have been terminated and not permanently\n","reinstated, you do not qualify to receive new licenses for the same\n","material under section 10.\n","\n","  9. Acceptance Not Required for Having Copies.\n","\n","  You are not required to accept this License in order to receive or\n","run a copy of the Program.  Ancillary propagation of a covered work\n","occurring solely as a consequence of using peer-to-peer transmission\n","to receive a copy likewise does not require acceptance.  However,\n","nothing other than this License grants you permission to propagate or\n","modify any covered work.  These actions infringe copyright if you do\n","not accept this License.  Therefore, by modifying or propagating a\n","covered work, you indicate your acceptance of this License to do so.\n","\n","  10. Automatic Licensing of Downstream Recipients.\n","\n","  Each time you convey a covered work, the recipient automatically\n","receives a license from the original licensors, to run, modify and\n","propagate that work, subject to this License.  You are not responsible\n","for enforcing compliance by third parties with this License.\n","\n","  An \"entity transaction\" is a transaction transferring control of an\n","organization, or substantially all assets of one, or subdividing an\n","organization, or merging organizations.  If propagation of a covered\n","work results from an entity transaction, each party to that\n","transaction who receives a copy of the work also receives whatever\n","licenses to the work the party's predecessor in interest had or could\n","give under the previous paragraph, plus a right to possession of the\n","Corresponding Source of the work from the predecessor in interest, if\n","the predecessor has it or can get it with reasonable efforts.\n","\n","  You may not impose any further restrictions on the exercise of the\n","rights granted or affirmed under this License.  For example, you may\n","not impose a license fee, royalty, or other charge for exercise of\n","rights granted under this License, and you may not initiate litigation\n","(including a cross-claim or counterclaim in a lawsuit) alleging that\n","any patent claim is infringed by making, using, selling, offering for\n","sale, or importing the Program or any portion of it.\n","\n","  11. Patents.\n","\n","  A \"contributor\" is a copyright holder who authorizes use under this\n","License of the Program or a work on which the Program is based.  The\n","work thus licensed is called the contributor's \"contributor version\".\n","\n","  A contributor's \"essential patent claims\" are all patent claims\n","owned or controlled by the contributor, whether already acquired or\n","hereafter acquired, that would be infringed by some manner, permitted\n","by this License, of making, using, or selling its contributor version,\n","but do not include claims that would be infringed only as a\n","consequence of further modification of the contributor version.  For\n","purposes of this definition, \"control\" includes the right to grant\n","patent sublicenses in a manner consistent with the requirements of\n","this License.\n","\n","  Each contributor grants you a non-exclusive, worldwide, royalty-free\n","patent license under the contributor's essential patent claims, to\n","make, use, sell, offer for sale, import and otherwise run, modify and\n","propagate the contents of its contributor version.\n","\n","  In the following three paragraphs, a \"patent license\" is any express\n","agreement or commitment, however denominated, not to enforce a patent\n","(such as an express permission to practice a patent or covenant not to\n","sue for patent infringement).  To \"grant\" such a patent license to a\n","party means to make such an agreement or commitment not to enforce a\n","patent against the party.\n","\n","  If you convey a covered work, knowingly relying on a patent license,\n","and the Corresponding Source of the work is not available for anyone\n","to copy, free of charge and under the terms of this License, through a\n","publicly available network server or other readily accessible means,\n","then you must either (1) cause the Corresponding Source to be so\n","available, or (2) arrange to deprive yourself of the benefit of the\n","patent license for this particular work, or (3) arrange, in a manner\n","consistent with the requirements of this License, to extend the patent\n","license to downstream recipients.  \"Knowingly relying\" means you have\n","actual knowledge that, but for the patent license, your conveying the\n","covered work in a country, or your recipient's use of the covered work\n","in a country, would infringe one or more identifiable patents in that\n","country that you have reason to believe are valid.\n","\n","  If, pursuant to or in connection with a single transaction or\n","arrangement, you convey, or propagate by procuring conveyance of, a\n","covered work, and grant a patent license to some of the parties\n","receiving the covered work authorizing them to use, propagate, modify\n","or convey a specific copy of the covered work, then the patent license\n","you grant is automatically extended to all recipients of the covered\n","work and works based on it.\n","\n","  A patent license is \"discriminatory\" if it does not include within\n","the scope of its coverage, prohibits the exercise of, or is\n","conditioned on the non-exercise of one or more of the rights that are\n","specifically granted under this License.  You may not convey a covered\n","work if you are a party to an arrangement with a third party that is\n","in the business of distributing software, under which you make payment\n","to the third party based on the extent of your activity of conveying\n","the work, and under which the third party grants, to any of the\n","parties who would receive the covered work from you, a discriminatory\n","patent license (a) in connection with copies of the covered work\n","conveyed by you (or copies made from those copies), or (b) primarily\n","for and in connection with specific products or compilations that\n","contain the covered work, unless you entered into that arrangement,\n","or that patent license was granted, prior to 28 March 2007.\n","\n","  Nothing in this License shall be construed as excluding or limiting\n","any implied license or other defenses to infringement that may\n","otherwise be available to you under applicable patent law.\n","\n","  12. No Surrender of Others' Freedom.\n","\n","  If conditions are imposed on you (whether by court order, agreement or\n","otherwise) that contradict the conditions of this License, they do not\n","excuse you from the conditions of this License.  If you cannot convey a\n","covered work so as to satisfy simultaneously your obligations under this\n","License and any other pertinent obligations, then as a consequence you may\n","not convey it at all.  For example, if you agree to terms that obligate you\n","to collect a royalty for further conveying from those to whom you convey\n","the Program, the only way you could satisfy both those terms and this\n","License would be to refrain entirely from conveying the Program.\n","\n","  13. Use with the GNU Affero General Public License.\n","\n","  Notwithstanding any other provision of this License, you have\n","permission to link or combine any covered work with a work licensed\n","under version 3 of the GNU Affero General Public License into a single\n","combined work, and to convey the resulting work.  The terms of this\n","License will continue to apply to the part which is the covered work,\n","but the special requirements of the GNU Affero General Public License,\n","section 13, concerning interaction through a network will apply to the\n","combination as such.\n","\n","  14. Revised Versions of this License.\n","\n","  The Free Software Foundation may publish revised and/or new versions of\n","the GNU General Public License from time to time.  Such new versions will\n","be similar in spirit to the present version, but may differ in detail to\n","address new problems or concerns.\n","\n","  Each version is given a distinguishing version number.  If the\n","Program specifies that a certain numbered version of the GNU General\n","Public License \"or any later version\" applies to it, you have the\n","option of following the terms and conditions either of that numbered\n","version or of any later version published by the Free Software\n","Foundation.  If the Program does not specify a version number of the\n","GNU General Public License, you may choose any version ever published\n","by the Free Software Foundation.\n","\n","  If the Program specifies that a proxy can decide which future\n","versions of the GNU General Public License can be used, that proxy's\n","public statement of acceptance of a version permanently authorizes you\n","to choose that version for the Program.\n","\n","  Later license versions may give you additional or different\n","permissions.  However, no additional obligations are imposed on any\n","author or copyright holder as a result of your choosing to follow a\n","later version.\n","\n","  15. Disclaimer of Warranty.\n","\n","  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY\n","APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT\n","HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY\n","OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,\n","THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n","PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM\n","IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF\n","ALL NECESSARY SERVICING, REPAIR OR CORRECTION.\n","\n","  16. Limitation of Liability.\n","\n","  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\n","WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS\n","THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY\n","GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE\n","USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF\n","DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD\n","PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),\n","EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF\n","SUCH DAMAGES.\n","\n","  17. Interpretation of Sections 15 and 16.\n","\n","  If the disclaimer of warranty and limitation of liability provided\n","above cannot be given local legal effect according to their terms,\n","reviewing courts shall apply local law that most closely approximates\n","an absolute waiver of all civil liability in connection with the\n","Program, unless a warranty or assumption of liability accompanies a\n","copy of the Program in return for a fee.\n","\n","                     END OF TERMS AND CONDITIONS\n","\n","            How to Apply These Terms to Your New Programs\n","\n","  If you develop a new program, and you want it to be of the greatest\n","possible use to the public, the best way to achieve this is to make it\n","free software which everyone can redistribute and change under these terms.\n","\n","  To do so, attach the following notices to the program.  It is safest\n","to attach them to the start of each source file to most effectively\n","state the exclusion of warranty; and each file should have at least\n","the \"copyright\" line and a pointer to where the full notice is found.\n","\n","    <one line to give the program's name and a brief idea of what it does.>\n","    Copyright (C) <year>  <name of author>\n","\n","    This program is free software: you can redistribute it and/or modify\n","    it under the terms of the GNU General Public License as published by\n","    the Free Software Foundation, either version 3 of the License, or\n","    (at your option) any later version.\n","\n","    This program is distributed in the hope that it will be useful,\n","    but WITHOUT ANY WARRANTY; without even the implied warranty of\n","    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","    GNU General Public License for more details.\n","\n","    You should have received a copy of the GNU General Public License\n","    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n","\n","Also add information on how to contact you by electronic and paper mail.\n","\n","  If the program does terminal interaction, make it output a short\n","notice like this when it starts in an interactive mode:\n","\n","    <program>  Copyright (C) <year>  <name of author>\n","    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\n","    This is free software, and you are welcome to redistribute it\n","    under certain conditions; type `show c' for details.\n","\n","The hypothetical commands `show w' and `show c' should show the appropriate\n","parts of the General Public License.  Of course, your program's commands\n","might be different; for a GUI interface, you would use an \"about box\".\n","\n","  You should also get your employer (if you work as a programmer) or school,\n","if any, to sign a \"copyright disclaimer\" for the program, if necessary.\n","For more information on this, and how to apply and follow the GNU GPL, see\n","<http://www.gnu.org/licenses/>.\n","\n","  The GNU General Public License does not permit incorporating your program\n","into proprietary programs.  If your program is a subroutine library, you\n","may consider it more useful to permit linking proprietary applications with\n","the library.  If this is what you want to do, use the GNU Lesser General\n","Public License instead of this License.  But first, please read\n","<http://www.gnu.org/philosophy/why-not-lgpl.html>.\n","\n","Name: libquadmath\n","Files: numpy.libs/libquadmath*.so\n","Description: dynamically linked to files compiled with gcc\n","Availability: https://gcc.gnu.org/git/?p=gcc.git;a=tree;f=libquadmath\n","License: LGPL-2.1-or-later\n","\n","    GCC Quad-Precision Math Library\n","    Copyright (C) 2010-2019 Free Software Foundation, Inc.\n","    Written by Francois-Xavier Coudert  <fxcoudert@gcc.gnu.org>\n","\n","    This file is part of the libquadmath library.\n","    Libquadmath is free software; you can redistribute it and/or\n","    modify it under the terms of the GNU Library General Public\n","    License as published by the Free Software Foundation; either\n","    version 2.1 of the License, or (at your option) any later version.\n","\n","    Libquadmath is distributed in the hope that it will be useful,\n","    but WITHOUT ANY WARRANTY; without even the implied warranty of\n","    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n","    Lesser General Public License for more details.\n","    https://www.gnu.org/licenses/old-licenses/lgpl-2.1.html\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: \n","Required-by: accelerate, albucore, albumentations, ale-py, arviz, astropy, autograd, bigframes, blis, blosc2, bokeh, Bottleneck, bqplot, chex, clarabel, cmdstanpy, contourpy, cudf-cu12, cufflinks, cuml-cu12, cupy-cuda12x, cuvs-cu12, cvxpy, cyipopt, dask-cuda, dask-cudf-cu12, datascience, datasets, db-dtypes, diffusers, dm-tree, dopamine_rl, flax, folium, geemap, geopandas, gym, gymnasium, h5py, hdbscan, highspy, holoviews, hyperopt, imageio, imbalanced-learn, jax, jaxlib, keras, keras-hub, libpysal, librosa, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, nx-cugraph-cu12, opencv-contrib-python, opencv-python, opencv-python-headless, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, pandas-stubs, patsy, peft, plotnine, prophet, pycocotools, pyerfa, pylibcugraph-cu12, pylibraft-cu12, pymc, pyogrio, pytensor, python-louvain, PyWavelets, rmm-cu12, scikit-image, scikit-learn, scipy, scs, seaborn, shap, shapely, sklearn-pandas, soundfile, soxr, spacy, spanner-graph-notebook, stanio, statsmodels, stumpy, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorflow_decision_forests, tensorstore, thinc, tifffile, torchtune, torchvision, transformers, transforms3d, treelite, treescope, tsfresh, ucx-py-cu12, ucxx-cu12, umap-learn, wordcloud, xarray, xarray-einstats, xgboost, ydf, yellowbrick, yfinance\n","---\n","Name: opencv-python\n","Version: 4.11.0.86\n","Summary: Wrapper package for OpenCV python bindings.\n","Home-page: https://github.com/opencv/opencv-python\n","Author: \n","Author-email: \n","License: Apache 2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: numpy\n","Required-by: dopamine_rl\n","---\n","Name: tensorflow\n","Version: 2.18.0\n","Summary: TensorFlow is an open source machine learning framework for everyone.\n","Home-page: https://www.tensorflow.org/\n","Author: Google Inc.\n","Author-email: packages@tensorflow.org\n","License: Apache 2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n","Required-by: dopamine_rl, tensorflow-text, tensorflow_decision_forests, tf_keras\n","---\n","Name: numba\n","Version: 0.60.0\n","Summary: compiling Python code using LLVM\n","Home-page: https://numba.pydata.org\n","Author: \n","Author-email: \n","License: BSD\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: llvmlite, numpy\n","Required-by: cudf-cu12, cuml-cu12, dask-cuda, distributed-ucxx-cu12, librosa, numba-cuda, pynndescent, shap, stumpy, umap-learn\n"]}]},{"cell_type":"markdown","source":["## Change the current working directory to where your Python scripts are located"],"metadata":{"id":"lUWhlJaS5DJy"}},{"cell_type":"code","source":["cd /content/project645/code/"],"metadata":{"id":"-PoyGBYI5C88","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747901067952,"user_tz":-180,"elapsed":43,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"4c8f5ca0-14a2-411d-a041-30851933c5a0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/project645/code\n"]}]},{"cell_type":"markdown","source":["# Euler Preprocessing"],"metadata":{"id":"Zcj2a5Jh7RCa"}},{"cell_type":"code","source":["# Preprocess Euler data\n","!python generate_training_euler_data.py\n","# Check if output folders were created\n","!ls /content/project645/train_data_euler/\n","!ls /content/project645/train_data_euler/salsa/\n","!ls /content/project645/reconstructed_bvh_data_euler/salsa/"],"metadata":{"id":"cgr-cC_57QtN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747901081226,"user_tz":-180,"elapsed":10783,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"2bf00b3e-bc1b-47ed-cdd6-f8c5d309c974"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Euler Data Generation (with Hip Position Normalization) ---\n","Source BVH: ../train_data_bvh/salsa\n","Target .npy (Normalized Euler): ../train_data_euler/salsa/\n","Target reconstructed BVH: ../reconstructed_bvh_data_euler/salsa/\n","Standard BVH for reconstruction: ../train_data_bvh/standard.bvh\n","Hip Position Scale Factor: 0.01\n","\n","Step 1: Converting BVH files to Normalized Euler representation (.npy)...\n","Created directory: ../train_data_euler/salsa/\n","Found 30 BVH files in ../train_data_bvh/salsa\n","Processing (encode): ../train_data_bvh/salsa/09.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/09.npy with shape (2576, 132)\n","Processing (encode): ../train_data_bvh/salsa/27.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/27.npy with shape (1691, 132)\n","Processing (encode): ../train_data_bvh/salsa/16.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/16.npy with shape (2243, 132)\n","Processing (encode): ../train_data_bvh/salsa/24.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/24.npy with shape (2576, 132)\n","Processing (encode): ../train_data_bvh/salsa/23.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/23.npy with shape (3422, 132)\n","Processing (encode): ../train_data_bvh/salsa/20.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/20.npy with shape (1679, 132)\n","Processing (encode): ../train_data_bvh/salsa/01.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/01.npy with shape (2243, 132)\n","Processing (encode): ../train_data_bvh/salsa/05.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/05.npy with shape (1679, 132)\n","Processing (encode): ../train_data_bvh/salsa/21.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/21.npy with shape (1773, 132)\n","Processing (encode): ../train_data_bvh/salsa/26.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/26.npy with shape (2109, 132)\n","Processing (encode): ../train_data_bvh/salsa/03.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/03.npy with shape (1831, 132)\n","Processing (encode): ../train_data_bvh/salsa/30.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/30.npy with shape (2141, 132)\n","Processing (encode): ../train_data_bvh/salsa/28.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/28.npy with shape (2272, 132)\n","Processing (encode): ../train_data_bvh/salsa/19.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/19.npy with shape (1872, 132)\n","Processing (encode): ../train_data_bvh/salsa/14.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/14.npy with shape (1950, 132)\n","Processing (encode): ../train_data_bvh/salsa/10.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/10.npy with shape (1198, 132)\n","Processing (encode): ../train_data_bvh/salsa/22.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/22.npy with shape (2072, 132)\n","Processing (encode): ../train_data_bvh/salsa/13.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/13.npy with shape (2272, 132)\n","Processing (encode): ../train_data_bvh/salsa/04.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/04.npy with shape (1872, 132)\n","Processing (encode): ../train_data_bvh/salsa/08.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/08.npy with shape (3422, 132)\n","Processing (encode): ../train_data_bvh/salsa/07.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/07.npy with shape (2072, 132)\n","Processing (encode): ../train_data_bvh/salsa/15.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/15.npy with shape (2141, 132)\n","Processing (encode): ../train_data_bvh/salsa/18.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/18.npy with shape (1831, 132)\n","Processing (encode): ../train_data_bvh/salsa/06.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/06.npy with shape (1773, 132)\n","Processing (encode): ../train_data_bvh/salsa/29.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/29.npy with shape (1950, 132)\n","Processing (encode): ../train_data_bvh/salsa/17.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/17.npy with shape (2102, 132)\n","Processing (encode): ../train_data_bvh/salsa/25.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/25.npy with shape (1198, 132)\n","Processing (encode): ../train_data_bvh/salsa/11.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/11.npy with shape (2109, 132)\n","Processing (encode): ../train_data_bvh/salsa/02.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/02.npy with shape (2102, 132)\n","Processing (encode): ../train_data_bvh/salsa/12.bvh\n","Saved normalized Euler data to ../train_data_euler/salsa/12.npy with shape (1691, 132)\n","\n","Step 2: Converting Normalized Euler .npy data back to BVH for verification (hip inverse-scaled)...\n","Created directory: ../reconstructed_bvh_data_euler/salsa/\n","Found 30 NPY files in ../train_data_euler/salsa/\n","Processing (decode): ../train_data_euler/salsa/08.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/08.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/06.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/06.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/28.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/28.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/16.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/16.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/29.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/29.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/26.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/26.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/11.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/11.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/25.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/25.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/23.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/23.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/01.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/01.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/21.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/21.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/17.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/17.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/27.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/27.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/03.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/03.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/22.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/22.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/12.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/12.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/10.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/10.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/20.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/20.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/14.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/14.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/05.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/05.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/18.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/18.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/15.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/15.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/09.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/09.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/19.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/19.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/02.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/02.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/07.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/07.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/13.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/13.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/04.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/04.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/30.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/30.bvh (hip positions inverse-scaled only)\n","Processing (decode): ../train_data_euler/salsa/24.npy\n","Saved reconstructed BVH file to ../reconstructed_bvh_data_euler/salsa/24.bvh (hip positions inverse-scaled only)\n","\n","Normalized Euler data processing completed.\n","salsa\n","01.npy\t04.npy\t07.npy\t10.npy\t13.npy\t16.npy\t19.npy\t22.npy\t25.npy\t28.npy\n","02.npy\t05.npy\t08.npy\t11.npy\t14.npy\t17.npy\t20.npy\t23.npy\t26.npy\t29.npy\n","03.npy\t06.npy\t09.npy\t12.npy\t15.npy\t18.npy\t21.npy\t24.npy\t27.npy\t30.npy\n","01.bvh\t04.bvh\t07.bvh\t10.bvh\t13.bvh\t16.bvh\t19.bvh\t22.bvh\t25.bvh\t28.bvh\n","02.bvh\t05.bvh\t08.bvh\t11.bvh\t14.bvh\t17.bvh\t20.bvh\t23.bvh\t26.bvh\t29.bvh\n","03.bvh\t06.bvh\t09.bvh\t12.bvh\t15.bvh\t18.bvh\t21.bvh\t24.bvh\t27.bvh\t30.bvh\n"]}]},{"cell_type":"markdown","source":["# Euler training"],"metadata":{"id":"atUjDOBGDEG7"}},{"cell_type":"code","source":["GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs\" # Redefine if needed, ensure this matches your setup\n","EULER_DATA_DIR = \"/content/project645/train_data_euler/salsa/\" # Assumes data is preprocessed in Colab\n","EULER_WEIGHTS_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"weights_euler\")\n","EULER_TRAIN_BVH_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"train_output_bvh_euler\")\n","STANDARD_BVH_REF_PATH = \"/content/project645/train_data_bvh/standard.bvh\" # Path to your standard.bvh\n","\n","os.makedirs(EULER_WEIGHTS_DIR, exist_ok=True)\n","os.makedirs(EULER_TRAIN_BVH_DIR, exist_ok=True)\n","\n","# Check if the standard_bvh_reference file exists\n","if not os.path.exists(STANDARD_BVH_REF_PATH):\n","    print(f\"ERROR: Standard BVH reference file not found at {STANDARD_BVH_REF_PATH}\")\n","    print(\"Please ensure the 'standard.bvh' file is in the '/content/project645/train_data_bvh/' directory.\")\n","else:\n","    print(f\"Using standard BVH reference: {STANDARD_BVH_REF_PATH}\")\n","    euler_frame_channels = 132\n","\n","    # Before running, ensure EULER_DATA_DIR has the .npy files from generate_training_euler_data.py\n","    if not os.path.exists(EULER_DATA_DIR) or not os.listdir(EULER_DATA_DIR):\n","        print(f\"ERROR: Euler training data not found or directory is empty: {EULER_DATA_DIR}\")\n","        print(\"Please run the 'Preprocess Euler data' cell first to generate the .npy files.\")\n","    else:\n","        print(f\"Found Euler training data in: {EULER_DATA_DIR}\")\n","        get_ipython().system(f\"\"\"python pytorch_train_euler_aclstm.py \\\\\n","            --dances_folder \"{EULER_DATA_DIR}\" \\\\\n","            --write_weight_folder \"{EULER_WEIGHTS_DIR}/\" \\\\\n","            --write_bvh_motion_folder \"{EULER_TRAIN_BVH_DIR}/\" \\\\\n","            --standard_bvh_reference \"{STANDARD_BVH_REF_PATH}\" \\\\\n","            --dance_frame_rate 60 \\\\\n","            --batch_size 32 \\\\\n","            --in_frame {euler_frame_channels} \\\\\n","            --out_frame {euler_frame_channels} \\\\\n","            --hidden_size 1024 \\\\\n","            --seq_len 100 \\\\\n","            --total_iterations 100000\"\"\")\n","            # --read_weight_path \"{EULER_WEIGHTS_DIR}/XXXXXXX.weight\" # Optional: to resume training\n"],"metadata":{"id":"OkDR7IjzoHfW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746874768001,"user_tz":-180,"elapsed":6082152,"user":{"displayName":"Chrysis Andreou","userId":"12086803060101170547"}},"outputId":"31630dec-5392-49d2-f34c-b1a1f2002fa1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","########### iter 0001600 ######################\n","loss: 0.0182\n","########### iter 0001620 ######################\n","loss: 0.0165\n","########### iter 0001640 ######################\n","loss: 0.0192\n","########### iter 0001660 ######################\n","loss: 0.0195\n","########### iter 0001680 ######################\n","loss: 0.0163\n","########### iter 0001700 ######################\n","loss: 0.0155\n","########### iter 0001720 ######################\n","loss: 0.0159\n","########### iter 0001740 ######################\n","loss: 0.0133\n","########### iter 0001760 ######################\n","loss: 0.0163\n","########### iter 0001780 ######################\n","loss: 0.0143\n","########### iter 0001800 ######################\n","loss: 0.0141\n","########### iter 0001820 ######################\n","loss: 0.0183\n","########### iter 0001840 ######################\n","loss: 0.0142\n","########### iter 0001860 ######################\n","loss: 0.0147\n","########### iter 0001880 ######################\n","loss: 0.0135\n","########### iter 0001900 ######################\n","loss: 0.0162\n","########### iter 0001920 ######################\n","loss: 0.0139\n","########### iter 0001940 ######################\n","loss: 0.0156\n","########### iter 0001960 ######################\n","loss: 0.0160\n","########### iter 0001980 ######################\n","loss: 0.0138\n","########### iter 0002000 ######################\n","loss: 0.0126\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0002000.weight\n","########### iter 0002020 ######################\n","loss: 0.0133\n","########### iter 0002040 ######################\n","loss: 0.0144\n","########### iter 0002060 ######################\n","loss: 0.0137\n","########### iter 0002080 ######################\n","loss: 0.0139\n","########### iter 0002100 ######################\n","loss: 0.0138\n","########### iter 0002120 ######################\n","loss: 0.0131\n","########### iter 0002140 ######################\n","loss: 0.0133\n","########### iter 0002160 ######################\n","loss: 0.0110\n","########### iter 0002180 ######################\n","loss: 0.0114\n","########### iter 0002200 ######################\n","loss: 0.0121\n","########### iter 0002220 ######################\n","loss: 0.0111\n","########### iter 0002240 ######################\n","loss: 0.0103\n","########### iter 0002260 ######################\n","loss: 0.0118\n","########### iter 0002280 ######################\n","loss: 0.0105\n","########### iter 0002300 ######################\n","loss: 0.0119\n","########### iter 0002320 ######################\n","loss: 0.0108\n","########### iter 0002340 ######################\n","loss: 0.0117\n","########### iter 0002360 ######################\n","loss: 0.0112\n","########### iter 0002380 ######################\n","loss: 0.0104\n","########### iter 0002400 ######################\n","loss: 0.0099\n","########### iter 0002420 ######################\n","loss: 0.0091\n","########### iter 0002440 ######################\n","loss: 0.0102\n","########### iter 0002460 ######################\n","loss: 0.0098\n","########### iter 0002480 ######################\n","loss: 0.0110\n","########### iter 0002500 ######################\n","loss: 0.0095\n","########### iter 0002520 ######################\n","loss: 0.0094\n","########### iter 0002540 ######################\n","loss: 0.0095\n","########### iter 0002560 ######################\n","loss: 0.0106\n","########### iter 0002580 ######################\n","loss: 0.0092\n","########### iter 0002600 ######################\n","loss: 0.0085\n","########### iter 0002620 ######################\n","loss: 0.0101\n","########### iter 0002640 ######################\n","loss: 0.0087\n","########### iter 0002660 ######################\n","loss: 0.0092\n","########### iter 0002680 ######################\n","loss: 0.0087\n","########### iter 0002700 ######################\n","loss: 0.0081\n","########### iter 0002720 ######################\n","loss: 0.0074\n","########### iter 0002740 ######################\n","loss: 0.0101\n","########### iter 0002760 ######################\n","loss: 0.0087\n","########### iter 0002780 ######################\n","loss: 0.0091\n","########### iter 0002800 ######################\n","loss: 0.0080\n","########### iter 0002820 ######################\n","loss: 0.0115\n","########### iter 0002840 ######################\n","loss: 0.0109\n","########### iter 0002860 ######################\n","loss: 0.0084\n","########### iter 0002880 ######################\n","loss: 0.0090\n","########### iter 0002900 ######################\n","loss: 0.0091\n","########### iter 0002920 ######################\n","loss: 0.0076\n","########### iter 0002940 ######################\n","loss: 0.0073\n","########### iter 0002960 ######################\n","loss: 0.0076\n","########### iter 0002980 ######################\n","loss: 0.0084\n","########### iter 0003000 ######################\n","loss: 0.0088\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0003000.weight\n","########### iter 0003020 ######################\n","loss: 0.0086\n","########### iter 0003040 ######################\n","loss: 0.0073\n","########### iter 0003060 ######################\n","loss: 0.0069\n","########### iter 0003080 ######################\n","loss: 0.0075\n","########### iter 0003100 ######################\n","loss: 0.0064\n","########### iter 0003120 ######################\n","loss: 0.0071\n","########### iter 0003140 ######################\n","loss: 0.0067\n","########### iter 0003160 ######################\n","loss: 0.0067\n","########### iter 0003180 ######################\n","loss: 0.0058\n","########### iter 0003200 ######################\n","loss: 0.0068\n","########### iter 0003220 ######################\n","loss: 0.0076\n","########### iter 0003240 ######################\n","loss: 0.0068\n","########### iter 0003260 ######################\n","loss: 0.0068\n","########### iter 0003280 ######################\n","loss: 0.0065\n","########### iter 0003300 ######################\n","loss: 0.0066\n","########### iter 0003320 ######################\n","loss: 0.0072\n","########### iter 0003340 ######################\n","loss: 0.0057\n","########### iter 0003360 ######################\n","loss: 0.0056\n","########### iter 0003380 ######################\n","loss: 0.0061\n","########### iter 0003400 ######################\n","loss: 0.0061\n","########### iter 0003420 ######################\n","loss: 0.0064\n","########### iter 0003440 ######################\n","loss: 0.0058\n","########### iter 0003460 ######################\n","loss: 0.0058\n","########### iter 0003480 ######################\n","loss: 0.0061\n","########### iter 0003500 ######################\n","loss: 0.0057\n","########### iter 0003520 ######################\n","loss: 0.0060\n","########### iter 0003540 ######################\n","loss: 0.0070\n","########### iter 0003560 ######################\n","loss: 0.0056\n","########### iter 0003580 ######################\n","loss: 0.0065\n","########### iter 0003600 ######################\n","loss: 0.0056\n","########### iter 0003620 ######################\n","loss: 0.0053\n","########### iter 0003640 ######################\n","loss: 0.0052\n","########### iter 0003660 ######################\n","loss: 0.0061\n","########### iter 0003680 ######################\n","loss: 0.0053\n","########### iter 0003700 ######################\n","loss: 0.0057\n","########### iter 0003720 ######################\n","loss: 0.0054\n","########### iter 0003740 ######################\n","loss: 0.0044\n","########### iter 0003760 ######################\n","loss: 0.0053\n","########### iter 0003780 ######################\n","loss: 0.0051\n","########### iter 0003800 ######################\n","loss: 0.0055\n","########### iter 0003820 ######################\n","loss: 0.0048\n","########### iter 0003840 ######################\n","loss: 0.0053\n","########### iter 0003860 ######################\n","loss: 0.0047\n","########### iter 0003880 ######################\n","loss: 0.0046\n","########### iter 0003900 ######################\n","loss: 0.0049\n","########### iter 0003920 ######################\n","loss: 0.0054\n","########### iter 0003940 ######################\n","loss: 0.0056\n","########### iter 0003960 ######################\n","loss: 0.0046\n","########### iter 0003980 ######################\n","loss: 0.0048\n","########### iter 0004000 ######################\n","loss: 0.0047\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0004000.weight\n","########### iter 0004020 ######################\n","loss: 0.0051\n","########### iter 0004040 ######################\n","loss: 0.0048\n","########### iter 0004060 ######################\n","loss: 0.0052\n","########### iter 0004080 ######################\n","loss: 0.0044\n","########### iter 0004100 ######################\n","loss: 0.0042\n","########### iter 0004120 ######################\n","loss: 0.0052\n","########### iter 0004140 ######################\n","loss: 0.0047\n","########### iter 0004160 ######################\n","loss: 0.0047\n","########### iter 0004180 ######################\n","loss: 0.0049\n","########### iter 0004200 ######################\n","loss: 0.0049\n","########### iter 0004220 ######################\n","loss: 0.0048\n","########### iter 0004240 ######################\n","loss: 0.0043\n","########### iter 0004260 ######################\n","loss: 0.0045\n","########### iter 0004280 ######################\n","loss: 0.0044\n","########### iter 0004300 ######################\n","loss: 0.0044\n","########### iter 0004320 ######################\n","loss: 0.0046\n","########### iter 0004340 ######################\n","loss: 0.0042\n","########### iter 0004360 ######################\n","loss: 0.0040\n","########### iter 0004380 ######################\n","loss: 0.0040\n","########### iter 0004400 ######################\n","loss: 0.0041\n","########### iter 0004420 ######################\n","loss: 0.0046\n","########### iter 0004440 ######################\n","loss: 0.0042\n","########### iter 0004460 ######################\n","loss: 0.0044\n","########### iter 0004480 ######################\n","loss: 0.0037\n","########### iter 0004500 ######################\n","loss: 0.0045\n","########### iter 0004520 ######################\n","loss: 0.0039\n","########### iter 0004540 ######################\n","loss: 0.0038\n","########### iter 0004560 ######################\n","loss: 0.0038\n","########### iter 0004580 ######################\n","loss: 0.0042\n","########### iter 0004600 ######################\n","loss: 0.0041\n","########### iter 0004620 ######################\n","loss: 0.0044\n","########### iter 0004640 ######################\n","loss: 0.0039\n","########### iter 0004660 ######################\n","loss: 0.0039\n","########### iter 0004680 ######################\n","loss: 0.0041\n","########### iter 0004700 ######################\n","loss: 0.0037\n","########### iter 0004720 ######################\n","loss: 0.0042\n","########### iter 0004740 ######################\n","loss: 0.0039\n","########### iter 0004760 ######################\n","loss: 0.0030\n","########### iter 0004780 ######################\n","loss: 0.0038\n","########### iter 0004800 ######################\n","loss: 0.0039\n","########### iter 0004820 ######################\n","loss: 0.0039\n","########### iter 0004840 ######################\n","loss: 0.0035\n","########### iter 0004860 ######################\n","loss: 0.0039\n","########### iter 0004880 ######################\n","loss: 0.0034\n","########### iter 0004900 ######################\n","loss: 0.0037\n","########### iter 0004920 ######################\n","loss: 0.0034\n","########### iter 0004940 ######################\n","loss: 0.0037\n","########### iter 0004960 ######################\n","loss: 0.0032\n","########### iter 0004980 ######################\n","loss: 0.0030\n","########### iter 0005000 ######################\n","loss: 0.0034\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0005000.weight\n","########### iter 0005020 ######################\n","loss: 0.0033\n","########### iter 0005040 ######################\n","loss: 0.0033\n","########### iter 0005060 ######################\n","loss: 0.0037\n","########### iter 0005080 ######################\n","loss: 0.0036\n","########### iter 0005100 ######################\n","loss: 0.0030\n","########### iter 0005120 ######################\n","loss: 0.0041\n","########### iter 0005140 ######################\n","loss: 0.0033\n","########### iter 0005160 ######################\n","loss: 0.0031\n","########### iter 0005180 ######################\n","loss: 0.0033\n","########### iter 0005200 ######################\n","loss: 0.0032\n","########### iter 0005220 ######################\n","loss: 0.0033\n","########### iter 0005240 ######################\n","loss: 0.0033\n","########### iter 0005260 ######################\n","loss: 0.0035\n","########### iter 0005280 ######################\n","loss: 0.0036\n","########### iter 0005300 ######################\n","loss: 0.0034\n","########### iter 0005320 ######################\n","loss: 0.0034\n","########### iter 0005340 ######################\n","loss: 0.0033\n","########### iter 0005360 ######################\n","loss: 0.0034\n","########### iter 0005380 ######################\n","loss: 0.0031\n","########### iter 0005400 ######################\n","loss: 0.0034\n","########### iter 0005420 ######################\n","loss: 0.0031\n","########### iter 0005440 ######################\n","loss: 0.0029\n","########### iter 0005460 ######################\n","loss: 0.0031\n","########### iter 0005480 ######################\n","loss: 0.0028\n","########### iter 0005500 ######################\n","loss: 0.0034\n","########### iter 0005520 ######################\n","loss: 0.0034\n","########### iter 0005540 ######################\n","loss: 0.0037\n","########### iter 0005560 ######################\n","loss: 0.0032\n","########### iter 0005580 ######################\n","loss: 0.0030\n","########### iter 0005600 ######################\n","loss: 0.0028\n","########### iter 0005620 ######################\n","loss: 0.0034\n","########### iter 0005640 ######################\n","loss: 0.0033\n","########### iter 0005660 ######################\n","loss: 0.0035\n","########### iter 0005680 ######################\n","loss: 0.0032\n","########### iter 0005700 ######################\n","loss: 0.0032\n","########### iter 0005720 ######################\n","loss: 0.0034\n","########### iter 0005740 ######################\n","loss: 0.0033\n","########### iter 0005760 ######################\n","loss: 0.0029\n","########### iter 0005780 ######################\n","loss: 0.0031\n","########### iter 0005800 ######################\n","loss: 0.0030\n","########### iter 0005820 ######################\n","loss: 0.0028\n","########### iter 0005840 ######################\n","loss: 0.0027\n","########### iter 0005860 ######################\n","loss: 0.0030\n","########### iter 0005880 ######################\n","loss: 0.0028\n","########### iter 0005900 ######################\n","loss: 0.0030\n","########### iter 0005920 ######################\n","loss: 0.0029\n","########### iter 0005940 ######################\n","loss: 0.0030\n","########### iter 0005960 ######################\n","loss: 0.0030\n","########### iter 0005980 ######################\n","loss: 0.0026\n","########### iter 0006000 ######################\n","loss: 0.0030\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0006000.weight\n","########### iter 0006020 ######################\n","loss: 0.0028\n","########### iter 0006040 ######################\n","loss: 0.0028\n","########### iter 0006060 ######################\n","loss: 0.0029\n","########### iter 0006080 ######################\n","loss: 0.0027\n","########### iter 0006100 ######################\n","loss: 0.0024\n","########### iter 0006120 ######################\n","loss: 0.0028\n","########### iter 0006140 ######################\n","loss: 0.0026\n","########### iter 0006160 ######################\n","loss: 0.0028\n","########### iter 0006180 ######################\n","loss: 0.0028\n","########### iter 0006200 ######################\n","loss: 0.0024\n","########### iter 0006220 ######################\n","loss: 0.0029\n","########### iter 0006240 ######################\n","loss: 0.0026\n","########### iter 0006260 ######################\n","loss: 0.0029\n","########### iter 0006280 ######################\n","loss: 0.0024\n","########### iter 0006300 ######################\n","loss: 0.0028\n","########### iter 0006320 ######################\n","loss: 0.0026\n","########### iter 0006340 ######################\n","loss: 0.0022\n","########### iter 0006360 ######################\n","loss: 0.0030\n","########### iter 0006380 ######################\n","loss: 0.0028\n","########### iter 0006400 ######################\n","loss: 0.0026\n","########### iter 0006420 ######################\n","loss: 0.0023\n","########### iter 0006440 ######################\n","loss: 0.0029\n","########### iter 0006460 ######################\n","loss: 0.0023\n","########### iter 0006480 ######################\n","loss: 0.0026\n","########### iter 0006500 ######################\n","loss: 0.0027\n","########### iter 0006520 ######################\n","loss: 0.0020\n","########### iter 0006540 ######################\n","loss: 0.0024\n","########### iter 0006560 ######################\n","loss: 0.0022\n","########### iter 0006580 ######################\n","loss: 0.0026\n","########### iter 0006600 ######################\n","loss: 0.0028\n","########### iter 0006620 ######################\n","loss: 0.0023\n","########### iter 0006640 ######################\n","loss: 0.0022\n","########### iter 0006660 ######################\n","loss: 0.0027\n","########### iter 0006680 ######################\n","loss: 0.0023\n","########### iter 0006700 ######################\n","loss: 0.0021\n","########### iter 0006720 ######################\n","loss: 0.0025\n","########### iter 0006740 ######################\n","loss: 0.0025\n","########### iter 0006760 ######################\n","loss: 0.0024\n","########### iter 0006780 ######################\n","loss: 0.0024\n","########### iter 0006800 ######################\n","loss: 0.0024\n","########### iter 0006820 ######################\n","loss: 0.0022\n","########### iter 0006840 ######################\n","loss: 0.0022\n","########### iter 0006860 ######################\n","loss: 0.0022\n","########### iter 0006880 ######################\n","loss: 0.0023\n","########### iter 0006900 ######################\n","loss: 0.0022\n","########### iter 0006920 ######################\n","loss: 0.0024\n","########### iter 0006940 ######################\n","loss: 0.0021\n","########### iter 0006960 ######################\n","loss: 0.0023\n","########### iter 0006980 ######################\n","loss: 0.0023\n","########### iter 0007000 ######################\n","loss: 0.0023\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0007000.weight\n","########### iter 0007020 ######################\n","loss: 0.0022\n","########### iter 0007040 ######################\n","loss: 0.0021\n","########### iter 0007060 ######################\n","loss: 0.0024\n","########### iter 0007080 ######################\n","loss: 0.0026\n","########### iter 0007100 ######################\n","loss: 0.0023\n","########### iter 0007120 ######################\n","loss: 0.0021\n","########### iter 0007140 ######################\n","loss: 0.0024\n","########### iter 0007160 ######################\n","loss: 0.0023\n","########### iter 0007180 ######################\n","loss: 0.0023\n","########### iter 0007200 ######################\n","loss: 0.0021\n","########### iter 0007220 ######################\n","loss: 0.0019\n","########### iter 0007240 ######################\n","loss: 0.0021\n","########### iter 0007260 ######################\n","loss: 0.0021\n","########### iter 0007280 ######################\n","loss: 0.0024\n","########### iter 0007300 ######################\n","loss: 0.0022\n","########### iter 0007320 ######################\n","loss: 0.0020\n","########### iter 0007340 ######################\n","loss: 0.0020\n","########### iter 0007360 ######################\n","loss: 0.0021\n","########### iter 0007380 ######################\n","loss: 0.0022\n","########### iter 0007400 ######################\n","loss: 0.0022\n","########### iter 0007420 ######################\n","loss: 0.0021\n","########### iter 0007440 ######################\n","loss: 0.0022\n","########### iter 0007460 ######################\n","loss: 0.0023\n","########### iter 0007480 ######################\n","loss: 0.0020\n","########### iter 0007500 ######################\n","loss: 0.0030\n","########### iter 0007520 ######################\n","loss: 0.0029\n","########### iter 0007540 ######################\n","loss: 0.0024\n","########### iter 0007560 ######################\n","loss: 0.0028\n","########### iter 0007580 ######################\n","loss: 0.0022\n","########### iter 0007600 ######################\n","loss: 0.0024\n","########### iter 0007620 ######################\n","loss: 0.0020\n","########### iter 0007640 ######################\n","loss: 0.0024\n","########### iter 0007660 ######################\n","loss: 0.0019\n","########### iter 0007680 ######################\n","loss: 0.0024\n","########### iter 0007700 ######################\n","loss: 0.0031\n","########### iter 0007720 ######################\n","loss: 0.0030\n","########### iter 0007740 ######################\n","loss: 0.0027\n","########### iter 0007760 ######################\n","loss: 0.0039\n","########### iter 0007780 ######################\n","loss: 0.0026\n","########### iter 0007800 ######################\n","loss: 0.0026\n","########### iter 0007820 ######################\n","loss: 0.0025\n","########### iter 0007840 ######################\n","loss: 0.0024\n","########### iter 0007860 ######################\n","loss: 0.0025\n","########### iter 0007880 ######################\n","loss: 0.0020\n","########### iter 0007900 ######################\n","loss: 0.0024\n","########### iter 0007920 ######################\n","loss: 0.0025\n","########### iter 0007940 ######################\n","loss: 0.0027\n","########### iter 0007960 ######################\n","loss: 0.0030\n","########### iter 0007980 ######################\n","loss: 0.0028\n","########### iter 0008000 ######################\n","loss: 0.0027\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0008000.weight\n","########### iter 0008020 ######################\n","loss: 0.0019\n","########### iter 0008040 ######################\n","loss: 0.0020\n","########### iter 0008060 ######################\n","loss: 0.0024\n","########### iter 0008080 ######################\n","loss: 0.0020\n","########### iter 0008100 ######################\n","loss: 0.0020\n","########### iter 0008120 ######################\n","loss: 0.0018\n","########### iter 0008140 ######################\n","loss: 0.0020\n","########### iter 0008160 ######################\n","loss: 0.0020\n","########### iter 0008180 ######################\n","loss: 0.0017\n","########### iter 0008200 ######################\n","loss: 0.0020\n","########### iter 0008220 ######################\n","loss: 0.0021\n","########### iter 0008240 ######################\n","loss: 0.0018\n","########### iter 0008260 ######################\n","loss: 0.0018\n","########### iter 0008280 ######################\n","loss: 0.0018\n","########### iter 0008300 ######################\n","loss: 0.0018\n","########### iter 0008320 ######################\n","loss: 0.0021\n","########### iter 0008340 ######################\n","loss: 0.0022\n","########### iter 0008360 ######################\n","loss: 0.0021\n","########### iter 0008380 ######################\n","loss: 0.0021\n","########### iter 0008400 ######################\n","loss: 0.0021\n","########### iter 0008420 ######################\n","loss: 0.0021\n","########### iter 0008440 ######################\n","loss: 0.0017\n","########### iter 0008460 ######################\n","loss: 0.0019\n","########### iter 0008480 ######################\n","loss: 0.0018\n","########### iter 0008500 ######################\n","loss: 0.0016\n","########### iter 0008520 ######################\n","loss: 0.0016\n","########### iter 0008540 ######################\n","loss: 0.0017\n","########### iter 0008560 ######################\n","loss: 0.0015\n","########### iter 0008580 ######################\n","loss: 0.0019\n","########### iter 0008600 ######################\n","loss: 0.0016\n","########### iter 0008620 ######################\n","loss: 0.0017\n","########### iter 0008640 ######################\n","loss: 0.0017\n","########### iter 0008660 ######################\n","loss: 0.0017\n","########### iter 0008680 ######################\n","loss: 0.0016\n","########### iter 0008700 ######################\n","loss: 0.0018\n","########### iter 0008720 ######################\n","loss: 0.0019\n","########### iter 0008740 ######################\n","loss: 0.0018\n","########### iter 0008760 ######################\n","loss: 0.0016\n","########### iter 0008780 ######################\n","loss: 0.0022\n","########### iter 0008800 ######################\n","loss: 0.0015\n","########### iter 0008820 ######################\n","loss: 0.0016\n","########### iter 0008840 ######################\n","loss: 0.0016\n","########### iter 0008860 ######################\n","loss: 0.0015\n","########### iter 0008880 ######################\n","loss: 0.0017\n","########### iter 0008900 ######################\n","loss: 0.0018\n","########### iter 0008920 ######################\n","loss: 0.0021\n","########### iter 0008940 ######################\n","loss: 0.0013\n","########### iter 0008960 ######################\n","loss: 0.0016\n","########### iter 0008980 ######################\n","loss: 0.0018\n","########### iter 0009000 ######################\n","loss: 0.0016\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0009000.weight\n","########### iter 0009020 ######################\n","loss: 0.0015\n","########### iter 0009040 ######################\n","loss: 0.0016\n","########### iter 0009060 ######################\n","loss: 0.0017\n","########### iter 0009080 ######################\n","loss: 0.0019\n","########### iter 0009100 ######################\n","loss: 0.0018\n","########### iter 0009120 ######################\n","loss: 0.0018\n","########### iter 0009140 ######################\n","loss: 0.0016\n","########### iter 0009160 ######################\n","loss: 0.0017\n","########### iter 0009180 ######################\n","loss: 0.0018\n","########### iter 0009200 ######################\n","loss: 0.0016\n","########### iter 0009220 ######################\n","loss: 0.0015\n","########### iter 0009240 ######################\n","loss: 0.0014\n","########### iter 0009260 ######################\n","loss: 0.0018\n","########### iter 0009280 ######################\n","loss: 0.0016\n","########### iter 0009300 ######################\n","loss: 0.0016\n","########### iter 0009320 ######################\n","loss: 0.0015\n","########### iter 0009340 ######################\n","loss: 0.0018\n","########### iter 0009360 ######################\n","loss: 0.0015\n","########### iter 0009380 ######################\n","loss: 0.0017\n","########### iter 0009400 ######################\n","loss: 0.0020\n","########### iter 0009420 ######################\n","loss: 0.0033\n","########### iter 0009440 ######################\n","loss: 0.0019\n","########### iter 0009460 ######################\n","loss: 0.0015\n","########### iter 0009480 ######################\n","loss: 0.0015\n","########### iter 0009500 ######################\n","loss: 0.0019\n","########### iter 0009520 ######################\n","loss: 0.0014\n","########### iter 0009540 ######################\n","loss: 0.0017\n","########### iter 0009560 ######################\n","loss: 0.0015\n","########### iter 0009580 ######################\n","loss: 0.0016\n","########### iter 0009600 ######################\n","loss: 0.0015\n","########### iter 0009620 ######################\n","loss: 0.0015\n","########### iter 0009640 ######################\n","loss: 0.0015\n","########### iter 0009660 ######################\n","loss: 0.0016\n","########### iter 0009680 ######################\n","loss: 0.0017\n","########### iter 0009700 ######################\n","loss: 0.0015\n","########### iter 0009720 ######################\n","loss: 0.0015\n","########### iter 0009740 ######################\n","loss: 0.0014\n","########### iter 0009760 ######################\n","loss: 0.0016\n","########### iter 0009780 ######################\n","loss: 0.0015\n","########### iter 0009800 ######################\n","loss: 0.0015\n","########### iter 0009820 ######################\n","loss: 0.0019\n","########### iter 0009840 ######################\n","loss: 0.0016\n","########### iter 0009860 ######################\n","loss: 0.0016\n","########### iter 0009880 ######################\n","loss: 0.0015\n","########### iter 0009900 ######################\n","loss: 0.0015\n","########### iter 0009920 ######################\n","loss: 0.0020\n","########### iter 0009940 ######################\n","loss: 0.0016\n","########### iter 0009960 ######################\n","loss: 0.0013\n","########### iter 0009980 ######################\n","loss: 0.0015\n","########### iter 0010000 ######################\n","loss: 0.0015\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0010000.weight\n","########### iter 0010020 ######################\n","loss: 0.0014\n","########### iter 0010040 ######################\n","loss: 0.0016\n","########### iter 0010060 ######################\n","loss: 0.0017\n","########### iter 0010080 ######################\n","loss: 0.0015\n","########### iter 0010100 ######################\n","loss: 0.0015\n","########### iter 0010120 ######################\n","loss: 0.0015\n","########### iter 0010140 ######################\n","loss: 0.0014\n","########### iter 0010160 ######################\n","loss: 0.0015\n","########### iter 0010180 ######################\n","loss: 0.0013\n","########### iter 0010200 ######################\n","loss: 0.0015\n","########### iter 0010220 ######################\n","loss: 0.0019\n","########### iter 0010240 ######################\n","loss: 0.0014\n","########### iter 0010260 ######################\n","loss: 0.0015\n","########### iter 0010280 ######################\n","loss: 0.0016\n","########### iter 0010300 ######################\n","loss: 0.0016\n","########### iter 0010320 ######################\n","loss: 0.0016\n","########### iter 0010340 ######################\n","loss: 0.0014\n","########### iter 0010360 ######################\n","loss: 0.0014\n","########### iter 0010380 ######################\n","loss: 0.0015\n","########### iter 0010400 ######################\n","loss: 0.0016\n","########### iter 0010420 ######################\n","loss: 0.0014\n","########### iter 0010440 ######################\n","loss: 0.0013\n","########### iter 0010460 ######################\n","loss: 0.0015\n","########### iter 0010480 ######################\n","loss: 0.0018\n","########### iter 0010500 ######################\n","loss: 0.0015\n","########### iter 0010520 ######################\n","loss: 0.0014\n","########### iter 0010540 ######################\n","loss: 0.0013\n","########### iter 0010560 ######################\n","loss: 0.0014\n","########### iter 0010580 ######################\n","loss: 0.0014\n","########### iter 0010600 ######################\n","loss: 0.0014\n","########### iter 0010620 ######################\n","loss: 0.0014\n","########### iter 0010640 ######################\n","loss: 0.0013\n","########### iter 0010660 ######################\n","loss: 0.0014\n","########### iter 0010680 ######################\n","loss: 0.0014\n","########### iter 0010700 ######################\n","loss: 0.0014\n","########### iter 0010720 ######################\n","loss: 0.0016\n","########### iter 0010740 ######################\n","loss: 0.0014\n","########### iter 0010760 ######################\n","loss: 0.0014\n","########### iter 0010780 ######################\n","loss: 0.0014\n","########### iter 0010800 ######################\n","loss: 0.0015\n","########### iter 0010820 ######################\n","loss: 0.0013\n","########### iter 0010840 ######################\n","loss: 0.0014\n","########### iter 0010860 ######################\n","loss: 0.0014\n","########### iter 0010880 ######################\n","loss: 0.0013\n","########### iter 0010900 ######################\n","loss: 0.0014\n","########### iter 0010920 ######################\n","loss: 0.0013\n","########### iter 0010940 ######################\n","loss: 0.0014\n","########### iter 0010960 ######################\n","loss: 0.0014\n","########### iter 0010980 ######################\n","loss: 0.0014\n","########### iter 0011000 ######################\n","loss: 0.0012\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0011000.weight\n","########### iter 0011020 ######################\n","loss: 0.0013\n","########### iter 0011040 ######################\n","loss: 0.0014\n","########### iter 0011060 ######################\n","loss: 0.0014\n","########### iter 0011080 ######################\n","loss: 0.0013\n","########### iter 0011100 ######################\n","loss: 0.0014\n","########### iter 0011120 ######################\n","loss: 0.0013\n","########### iter 0011140 ######################\n","loss: 0.0014\n","########### iter 0011160 ######################\n","loss: 0.0012\n","########### iter 0011180 ######################\n","loss: 0.0013\n","########### iter 0011200 ######################\n","loss: 0.0014\n","########### iter 0011220 ######################\n","loss: 0.0014\n","########### iter 0011240 ######################\n","loss: 0.0013\n","########### iter 0011260 ######################\n","loss: 0.0012\n","########### iter 0011280 ######################\n","loss: 0.0017\n","########### iter 0011300 ######################\n","loss: 0.0015\n","########### iter 0011320 ######################\n","loss: 0.0013\n","########### iter 0011340 ######################\n","loss: 0.0011\n","########### iter 0011360 ######################\n","loss: 0.0014\n","########### iter 0011380 ######################\n","loss: 0.0014\n","########### iter 0011400 ######################\n","loss: 0.0014\n","########### iter 0011420 ######################\n","loss: 0.0014\n","########### iter 0011440 ######################\n","loss: 0.0015\n","########### iter 0011460 ######################\n","loss: 0.0013\n","########### iter 0011480 ######################\n","loss: 0.0013\n","########### iter 0011500 ######################\n","loss: 0.0015\n","########### iter 0011520 ######################\n","loss: 0.0015\n","########### iter 0011540 ######################\n","loss: 0.0012\n","########### iter 0011560 ######################\n","loss: 0.0012\n","########### iter 0011580 ######################\n","loss: 0.0011\n","########### iter 0011600 ######################\n","loss: 0.0011\n","########### iter 0011620 ######################\n","loss: 0.0014\n","########### iter 0011640 ######################\n","loss: 0.0012\n","########### iter 0011660 ######################\n","loss: 0.0011\n","########### iter 0011680 ######################\n","loss: 0.0012\n","########### iter 0011700 ######################\n","loss: 0.0013\n","########### iter 0011720 ######################\n","loss: 0.0012\n","########### iter 0011740 ######################\n","loss: 0.0013\n","########### iter 0011760 ######################\n","loss: 0.0014\n","########### iter 0011780 ######################\n","loss: 0.0012\n","########### iter 0011800 ######################\n","loss: 0.0013\n","########### iter 0011820 ######################\n","loss: 0.0012\n","########### iter 0011840 ######################\n","loss: 0.0012\n","########### iter 0011860 ######################\n","loss: 0.0014\n","########### iter 0011880 ######################\n","loss: 0.0014\n","########### iter 0011900 ######################\n","loss: 0.0012\n","########### iter 0011920 ######################\n","loss: 0.0010\n","########### iter 0011940 ######################\n","loss: 0.0013\n","########### iter 0011960 ######################\n","loss: 0.0014\n","########### iter 0011980 ######################\n","loss: 0.0011\n","########### iter 0012000 ######################\n","loss: 0.0011\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0012000.weight\n","########### iter 0012020 ######################\n","loss: 0.0012\n","########### iter 0012040 ######################\n","loss: 0.0014\n","########### iter 0012060 ######################\n","loss: 0.0011\n","########### iter 0012080 ######################\n","loss: 0.0012\n","########### iter 0012100 ######################\n","loss: 0.0010\n","########### iter 0012120 ######################\n","loss: 0.0014\n","########### iter 0012140 ######################\n","loss: 0.0012\n","########### iter 0012160 ######################\n","loss: 0.0012\n","########### iter 0012180 ######################\n","loss: 0.0014\n","########### iter 0012200 ######################\n","loss: 0.0013\n","########### iter 0012220 ######################\n","loss: 0.0014\n","########### iter 0012240 ######################\n","loss: 0.0011\n","########### iter 0012260 ######################\n","loss: 0.0014\n","########### iter 0012280 ######################\n","loss: 0.0012\n","########### iter 0012300 ######################\n","loss: 0.0013\n","########### iter 0012320 ######################\n","loss: 0.0013\n","########### iter 0012340 ######################\n","loss: 0.0014\n","########### iter 0012360 ######################\n","loss: 0.0013\n","########### iter 0012380 ######################\n","loss: 0.0013\n","########### iter 0012400 ######################\n","loss: 0.0015\n","########### iter 0012420 ######################\n","loss: 0.0012\n","########### iter 0012440 ######################\n","loss: 0.0013\n","########### iter 0012460 ######################\n","loss: 0.0014\n","########### iter 0012480 ######################\n","loss: 0.0012\n","########### iter 0012500 ######################\n","loss: 0.0013\n","########### iter 0012520 ######################\n","loss: 0.0013\n","########### iter 0012540 ######################\n","loss: 0.0013\n","########### iter 0012560 ######################\n","loss: 0.0012\n","########### iter 0012580 ######################\n","loss: 0.0012\n","########### iter 0012600 ######################\n","loss: 0.0011\n","########### iter 0012620 ######################\n","loss: 0.0013\n","########### iter 0012640 ######################\n","loss: 0.0012\n","########### iter 0012660 ######################\n","loss: 0.0010\n","########### iter 0012680 ######################\n","loss: 0.0012\n","########### iter 0012700 ######################\n","loss: 0.0012\n","########### iter 0012720 ######################\n","loss: 0.0014\n","########### iter 0012740 ######################\n","loss: 0.0012\n","########### iter 0012760 ######################\n","loss: 0.0013\n","########### iter 0012780 ######################\n","loss: 0.0012\n","########### iter 0012800 ######################\n","loss: 0.0011\n","########### iter 0012820 ######################\n","loss: 0.0010\n","########### iter 0012840 ######################\n","loss: 0.0013\n","########### iter 0012860 ######################\n","loss: 0.0010\n","########### iter 0012880 ######################\n","loss: 0.0011\n","########### iter 0012900 ######################\n","loss: 0.0011\n","########### iter 0012920 ######################\n","loss: 0.0011\n","########### iter 0012940 ######################\n","loss: 0.0012\n","########### iter 0012960 ######################\n","loss: 0.0011\n","########### iter 0012980 ######################\n","loss: 0.0011\n","########### iter 0013000 ######################\n","loss: 0.0011\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0013000.weight\n","########### iter 0013020 ######################\n","loss: 0.0011\n","########### iter 0013040 ######################\n","loss: 0.0011\n","########### iter 0013060 ######################\n","loss: 0.0013\n","########### iter 0013080 ######################\n","loss: 0.0011\n","########### iter 0013100 ######################\n","loss: 0.0010\n","########### iter 0013120 ######################\n","loss: 0.0010\n","########### iter 0013140 ######################\n","loss: 0.0012\n","########### iter 0013160 ######################\n","loss: 0.0009\n","########### iter 0013180 ######################\n","loss: 0.0013\n","########### iter 0013200 ######################\n","loss: 0.0010\n","########### iter 0013220 ######################\n","loss: 0.0011\n","########### iter 0013240 ######################\n","loss: 0.0012\n","########### iter 0013260 ######################\n","loss: 0.0013\n","########### iter 0013280 ######################\n","loss: 0.0013\n","########### iter 0013300 ######################\n","loss: 0.0011\n","########### iter 0013320 ######################\n","loss: 0.0011\n","########### iter 0013340 ######################\n","loss: 0.0013\n","########### iter 0013360 ######################\n","loss: 0.0012\n","########### iter 0013380 ######################\n","loss: 0.0010\n","########### iter 0013400 ######################\n","loss: 0.0012\n","########### iter 0013420 ######################\n","loss: 0.0009\n","########### iter 0013440 ######################\n","loss: 0.0010\n","########### iter 0013460 ######################\n","loss: 0.0012\n","########### iter 0013480 ######################\n","loss: 0.0010\n","########### iter 0013500 ######################\n","loss: 0.0010\n","########### iter 0013520 ######################\n","loss: 0.0012\n","########### iter 0013540 ######################\n","loss: 0.0012\n","########### iter 0013560 ######################\n","loss: 0.0010\n","########### iter 0013580 ######################\n","loss: 0.0011\n","########### iter 0013600 ######################\n","loss: 0.0010\n","########### iter 0013620 ######################\n","loss: 0.0012\n","########### iter 0013640 ######################\n","loss: 0.0012\n","########### iter 0013660 ######################\n","loss: 0.0014\n","########### iter 0013680 ######################\n","loss: 0.0012\n","########### iter 0013700 ######################\n","loss: 0.0010\n","########### iter 0013720 ######################\n","loss: 0.0011\n","########### iter 0013740 ######################\n","loss: 0.0009\n","########### iter 0013760 ######################\n","loss: 0.0010\n","########### iter 0013780 ######################\n","loss: 0.0010\n","########### iter 0013800 ######################\n","loss: 0.0010\n","########### iter 0013820 ######################\n","loss: 0.0011\n","########### iter 0013840 ######################\n","loss: 0.0012\n","########### iter 0013860 ######################\n","loss: 0.0010\n","########### iter 0013880 ######################\n","loss: 0.0011\n","########### iter 0013900 ######################\n","loss: 0.0010\n","########### iter 0013920 ######################\n","loss: 0.0009\n","########### iter 0013940 ######################\n","loss: 0.0009\n","########### iter 0013960 ######################\n","loss: 0.0011\n","########### iter 0013980 ######################\n","loss: 0.0012\n","########### iter 0014000 ######################\n","loss: 0.0012\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0014000.weight\n","########### iter 0014020 ######################\n","loss: 0.0011\n","########### iter 0014040 ######################\n","loss: 0.0010\n","########### iter 0014060 ######################\n","loss: 0.0012\n","########### iter 0014080 ######################\n","loss: 0.0011\n","########### iter 0014100 ######################\n","loss: 0.0011\n","########### iter 0014120 ######################\n","loss: 0.0010\n","########### iter 0014140 ######################\n","loss: 0.0012\n","########### iter 0014160 ######################\n","loss: 0.0010\n","########### iter 0014180 ######################\n","loss: 0.0011\n","########### iter 0014200 ######################\n","loss: 0.0011\n","########### iter 0014220 ######################\n","loss: 0.0010\n","########### iter 0014240 ######################\n","loss: 0.0010\n","########### iter 0014260 ######################\n","loss: 0.0010\n","########### iter 0014280 ######################\n","loss: 0.0010\n","########### iter 0014300 ######################\n","loss: 0.0008\n","########### iter 0014320 ######################\n","loss: 0.0011\n","########### iter 0014340 ######################\n","loss: 0.0011\n","########### iter 0014360 ######################\n","loss: 0.0011\n","########### iter 0014380 ######################\n","loss: 0.0010\n","########### iter 0014400 ######################\n","loss: 0.0010\n","########### iter 0014420 ######################\n","loss: 0.0009\n","########### iter 0014440 ######################\n","loss: 0.0010\n","########### iter 0014460 ######################\n","loss: 0.0010\n","########### iter 0014480 ######################\n","loss: 0.0010\n","########### iter 0014500 ######################\n","loss: 0.0011\n","########### iter 0014520 ######################\n","loss: 0.0010\n","########### iter 0014540 ######################\n","loss: 0.0009\n","########### iter 0014560 ######################\n","loss: 0.0009\n","########### iter 0014580 ######################\n","loss: 0.0009\n","########### iter 0014600 ######################\n","loss: 0.0010\n","########### iter 0014620 ######################\n","loss: 0.0009\n","########### iter 0014640 ######################\n","loss: 0.0010\n","########### iter 0014660 ######################\n","loss: 0.0011\n","########### iter 0014680 ######################\n","loss: 0.0012\n","########### iter 0014700 ######################\n","loss: 0.0009\n","########### iter 0014720 ######################\n","loss: 0.0010\n","########### iter 0014740 ######################\n","loss: 0.0010\n","########### iter 0014760 ######################\n","loss: 0.0012\n","########### iter 0014780 ######################\n","loss: 0.0011\n","########### iter 0014800 ######################\n","loss: 0.0014\n","########### iter 0014820 ######################\n","loss: 0.0015\n","########### iter 0014840 ######################\n","loss: 0.0014\n","########### iter 0014860 ######################\n","loss: 0.0012\n","########### iter 0014880 ######################\n","loss: 0.0009\n","########### iter 0014900 ######################\n","loss: 0.0010\n","########### iter 0014920 ######################\n","loss: 0.0009\n","########### iter 0014940 ######################\n","loss: 0.0010\n","########### iter 0014960 ######################\n","loss: 0.0010\n","########### iter 0014980 ######################\n","loss: 0.0010\n","########### iter 0015000 ######################\n","loss: 0.0009\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0015000.weight\n","########### iter 0015020 ######################\n","loss: 0.0011\n","########### iter 0015040 ######################\n","loss: 0.0011\n","########### iter 0015060 ######################\n","loss: 0.0008\n","########### iter 0015080 ######################\n","loss: 0.0009\n","########### iter 0015100 ######################\n","loss: 0.0010\n","########### iter 0015120 ######################\n","loss: 0.0010\n","########### iter 0015140 ######################\n","loss: 0.0011\n","########### iter 0015160 ######################\n","loss: 0.0012\n","########### iter 0015180 ######################\n","loss: 0.0010\n","########### iter 0015200 ######################\n","loss: 0.0009\n","########### iter 0015220 ######################\n","loss: 0.0009\n","########### iter 0015240 ######################\n","loss: 0.0010\n","########### iter 0015260 ######################\n","loss: 0.0010\n","########### iter 0015280 ######################\n","loss: 0.0009\n","########### iter 0015300 ######################\n","loss: 0.0008\n","########### iter 0015320 ######################\n","loss: 0.0008\n","########### iter 0015340 ######################\n","loss: 0.0009\n","########### iter 0015360 ######################\n","loss: 0.0009\n","########### iter 0015380 ######################\n","loss: 0.0008\n","########### iter 0015400 ######################\n","loss: 0.0010\n","########### iter 0015420 ######################\n","loss: 0.0009\n","########### iter 0015440 ######################\n","loss: 0.0009\n","########### iter 0015460 ######################\n","loss: 0.0009\n","########### iter 0015480 ######################\n","loss: 0.0011\n","########### iter 0015500 ######################\n","loss: 0.0010\n","########### iter 0015520 ######################\n","loss: 0.0009\n","########### iter 0015540 ######################\n","loss: 0.0010\n","########### iter 0015560 ######################\n","loss: 0.0008\n","########### iter 0015580 ######################\n","loss: 0.0009\n","########### iter 0015600 ######################\n","loss: 0.0010\n","########### iter 0015620 ######################\n","loss: 0.0008\n","########### iter 0015640 ######################\n","loss: 0.0010\n","########### iter 0015660 ######################\n","loss: 0.0008\n","########### iter 0015680 ######################\n","loss: 0.0009\n","########### iter 0015700 ######################\n","loss: 0.0009\n","########### iter 0015720 ######################\n","loss: 0.0010\n","########### iter 0015740 ######################\n","loss: 0.0010\n","########### iter 0015760 ######################\n","loss: 0.0009\n","########### iter 0015780 ######################\n","loss: 0.0011\n","########### iter 0015800 ######################\n","loss: 0.0010\n","########### iter 0015820 ######################\n","loss: 0.0009\n","########### iter 0015840 ######################\n","loss: 0.0008\n","########### iter 0015860 ######################\n","loss: 0.0009\n","########### iter 0015880 ######################\n","loss: 0.0008\n","########### iter 0015900 ######################\n","loss: 0.0010\n","########### iter 0015920 ######################\n","loss: 0.0008\n","########### iter 0015940 ######################\n","loss: 0.0008\n","########### iter 0015960 ######################\n","loss: 0.0011\n","########### iter 0015980 ######################\n","loss: 0.0010\n","########### iter 0016000 ######################\n","loss: 0.0010\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0016000.weight\n","########### iter 0016020 ######################\n","loss: 0.0010\n","########### iter 0016040 ######################\n","loss: 0.0009\n","########### iter 0016060 ######################\n","loss: 0.0009\n","########### iter 0016080 ######################\n","loss: 0.0009\n","########### iter 0016100 ######################\n","loss: 0.0010\n","########### iter 0016120 ######################\n","loss: 0.0009\n","########### iter 0016140 ######################\n","loss: 0.0011\n","########### iter 0016160 ######################\n","loss: 0.0008\n","########### iter 0016180 ######################\n","loss: 0.0008\n","########### iter 0016200 ######################\n","loss: 0.0009\n","########### iter 0016220 ######################\n","loss: 0.0007\n","########### iter 0016240 ######################\n","loss: 0.0009\n","########### iter 0016260 ######################\n","loss: 0.0009\n","########### iter 0016280 ######################\n","loss: 0.0010\n","########### iter 0016300 ######################\n","loss: 0.0007\n","########### iter 0016320 ######################\n","loss: 0.0009\n","########### iter 0016340 ######################\n","loss: 0.0010\n","########### iter 0016360 ######################\n","loss: 0.0011\n","########### iter 0016380 ######################\n","loss: 0.0008\n","########### iter 0016400 ######################\n","loss: 0.0007\n","########### iter 0016420 ######################\n","loss: 0.0009\n","########### iter 0016440 ######################\n","loss: 0.0010\n","########### iter 0016460 ######################\n","loss: 0.0009\n","########### iter 0016480 ######################\n","loss: 0.0009\n","########### iter 0016500 ######################\n","loss: 0.0010\n","########### iter 0016520 ######################\n","loss: 0.0010\n","########### iter 0016540 ######################\n","loss: 0.0010\n","########### iter 0016560 ######################\n","loss: 0.0008\n","########### iter 0016580 ######################\n","loss: 0.0009\n","########### iter 0016600 ######################\n","loss: 0.0012\n","########### iter 0016620 ######################\n","loss: 0.0008\n","########### iter 0016640 ######################\n","loss: 0.0009\n","########### iter 0016660 ######################\n","loss: 0.0009\n","########### iter 0016680 ######################\n","loss: 0.0008\n","########### iter 0016700 ######################\n","loss: 0.0008\n","########### iter 0016720 ######################\n","loss: 0.0008\n","########### iter 0016740 ######################\n","loss: 0.0008\n","########### iter 0016760 ######################\n","loss: 0.0009\n","########### iter 0016780 ######################\n","loss: 0.0009\n","########### iter 0016800 ######################\n","loss: 0.0008\n","########### iter 0016820 ######################\n","loss: 0.0010\n","########### iter 0016840 ######################\n","loss: 0.0010\n","########### iter 0016860 ######################\n","loss: 0.0009\n","########### iter 0016880 ######################\n","loss: 0.0009\n","########### iter 0016900 ######################\n","loss: 0.0008\n","########### iter 0016920 ######################\n","loss: 0.0008\n","########### iter 0016940 ######################\n","loss: 0.0008\n","########### iter 0016960 ######################\n","loss: 0.0009\n","########### iter 0016980 ######################\n","loss: 0.0009\n","########### iter 0017000 ######################\n","loss: 0.0011\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0017000.weight\n","########### iter 0017020 ######################\n","loss: 0.0010\n","########### iter 0017040 ######################\n","loss: 0.0009\n","########### iter 0017060 ######################\n","loss: 0.0010\n","########### iter 0017080 ######################\n","loss: 0.0009\n","########### iter 0017100 ######################\n","loss: 0.0009\n","########### iter 0017120 ######################\n","loss: 0.0009\n","########### iter 0017140 ######################\n","loss: 0.0010\n","########### iter 0017160 ######################\n","loss: 0.0008\n","########### iter 0017180 ######################\n","loss: 0.0009\n","########### iter 0017200 ######################\n","loss: 0.0008\n","########### iter 0017220 ######################\n","loss: 0.0009\n","########### iter 0017240 ######################\n","loss: 0.0008\n","########### iter 0017260 ######################\n","loss: 0.0008\n","########### iter 0017280 ######################\n","loss: 0.0009\n","########### iter 0017300 ######################\n","loss: 0.0008\n","########### iter 0017320 ######################\n","loss: 0.0007\n","########### iter 0017340 ######################\n","loss: 0.0009\n","########### iter 0017360 ######################\n","loss: 0.0010\n","########### iter 0017380 ######################\n","loss: 0.0009\n","########### iter 0017400 ######################\n","loss: 0.0008\n","########### iter 0017420 ######################\n","loss: 0.0009\n","########### iter 0017440 ######################\n","loss: 0.0007\n","########### iter 0017460 ######################\n","loss: 0.0007\n","########### iter 0017480 ######################\n","loss: 0.0007\n","########### iter 0017500 ######################\n","loss: 0.0008\n","########### iter 0017520 ######################\n","loss: 0.0009\n","########### iter 0017540 ######################\n","loss: 0.0009\n","########### iter 0017560 ######################\n","loss: 0.0008\n","########### iter 0017580 ######################\n","loss: 0.0010\n","########### iter 0017600 ######################\n","loss: 0.0008\n","########### iter 0017620 ######################\n","loss: 0.0008\n","########### iter 0017640 ######################\n","loss: 0.0007\n","########### iter 0017660 ######################\n","loss: 0.0009\n","########### iter 0017680 ######################\n","loss: 0.0008\n","########### iter 0017700 ######################\n","loss: 0.0008\n","########### iter 0017720 ######################\n","loss: 0.0008\n","########### iter 0017740 ######################\n","loss: 0.0009\n","########### iter 0017760 ######################\n","loss: 0.0009\n","########### iter 0017780 ######################\n","loss: 0.0009\n","########### iter 0017800 ######################\n","loss: 0.0008\n","########### iter 0017820 ######################\n","loss: 0.0009\n","########### iter 0017840 ######################\n","loss: 0.0007\n","########### iter 0017860 ######################\n","loss: 0.0008\n","########### iter 0017880 ######################\n","loss: 0.0008\n","########### iter 0017900 ######################\n","loss: 0.0009\n","########### iter 0017920 ######################\n","loss: 0.0008\n","########### iter 0017940 ######################\n","loss: 0.0008\n","########### iter 0017960 ######################\n","loss: 0.0007\n","########### iter 0017980 ######################\n","loss: 0.0007\n","########### iter 0018000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0018000.weight\n","########### iter 0018020 ######################\n","loss: 0.0009\n","########### iter 0018040 ######################\n","loss: 0.0009\n","########### iter 0018060 ######################\n","loss: 0.0008\n","########### iter 0018080 ######################\n","loss: 0.0008\n","########### iter 0018100 ######################\n","loss: 0.0009\n","########### iter 0018120 ######################\n","loss: 0.0007\n","########### iter 0018140 ######################\n","loss: 0.0010\n","########### iter 0018160 ######################\n","loss: 0.0008\n","########### iter 0018180 ######################\n","loss: 0.0007\n","########### iter 0018200 ######################\n","loss: 0.0008\n","########### iter 0018220 ######################\n","loss: 0.0007\n","########### iter 0018240 ######################\n","loss: 0.0009\n","########### iter 0018260 ######################\n","loss: 0.0008\n","########### iter 0018280 ######################\n","loss: 0.0008\n","########### iter 0018300 ######################\n","loss: 0.0008\n","########### iter 0018320 ######################\n","loss: 0.0010\n","########### iter 0018340 ######################\n","loss: 0.0008\n","########### iter 0018360 ######################\n","loss: 0.0009\n","########### iter 0018380 ######################\n","loss: 0.0007\n","########### iter 0018400 ######################\n","loss: 0.0008\n","########### iter 0018420 ######################\n","loss: 0.0008\n","########### iter 0018440 ######################\n","loss: 0.0007\n","########### iter 0018460 ######################\n","loss: 0.0009\n","########### iter 0018480 ######################\n","loss: 0.0008\n","########### iter 0018500 ######################\n","loss: 0.0009\n","########### iter 0018520 ######################\n","loss: 0.0007\n","########### iter 0018540 ######################\n","loss: 0.0007\n","########### iter 0018560 ######################\n","loss: 0.0007\n","########### iter 0018580 ######################\n","loss: 0.0008\n","########### iter 0018600 ######################\n","loss: 0.0006\n","########### iter 0018620 ######################\n","loss: 0.0007\n","########### iter 0018640 ######################\n","loss: 0.0008\n","########### iter 0018660 ######################\n","loss: 0.0009\n","########### iter 0018680 ######################\n","loss: 0.0008\n","########### iter 0018700 ######################\n","loss: 0.0008\n","########### iter 0018720 ######################\n","loss: 0.0008\n","########### iter 0018740 ######################\n","loss: 0.0008\n","########### iter 0018760 ######################\n","loss: 0.0008\n","########### iter 0018780 ######################\n","loss: 0.0008\n","########### iter 0018800 ######################\n","loss: 0.0008\n","########### iter 0018820 ######################\n","loss: 0.0009\n","########### iter 0018840 ######################\n","loss: 0.0008\n","########### iter 0018860 ######################\n","loss: 0.0007\n","########### iter 0018880 ######################\n","loss: 0.0007\n","########### iter 0018900 ######################\n","loss: 0.0006\n","########### iter 0018920 ######################\n","loss: 0.0009\n","########### iter 0018940 ######################\n","loss: 0.0008\n","########### iter 0018960 ######################\n","loss: 0.0007\n","########### iter 0018980 ######################\n","loss: 0.0007\n","########### iter 0019000 ######################\n","loss: 0.0008\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0019000.weight\n","########### iter 0019020 ######################\n","loss: 0.0007\n","########### iter 0019040 ######################\n","loss: 0.0008\n","########### iter 0019060 ######################\n","loss: 0.0008\n","########### iter 0019080 ######################\n","loss: 0.0008\n","########### iter 0019100 ######################\n","loss: 0.0006\n","########### iter 0019120 ######################\n","loss: 0.0009\n","########### iter 0019140 ######################\n","loss: 0.0007\n","########### iter 0019160 ######################\n","loss: 0.0008\n","########### iter 0019180 ######################\n","loss: 0.0008\n","########### iter 0019200 ######################\n","loss: 0.0008\n","########### iter 0019220 ######################\n","loss: 0.0007\n","########### iter 0019240 ######################\n","loss: 0.0007\n","########### iter 0019260 ######################\n","loss: 0.0008\n","########### iter 0019280 ######################\n","loss: 0.0009\n","########### iter 0019300 ######################\n","loss: 0.0007\n","########### iter 0019320 ######################\n","loss: 0.0008\n","########### iter 0019340 ######################\n","loss: 0.0009\n","########### iter 0019360 ######################\n","loss: 0.0009\n","########### iter 0019380 ######################\n","loss: 0.0008\n","########### iter 0019400 ######################\n","loss: 0.0007\n","########### iter 0019420 ######################\n","loss: 0.0007\n","########### iter 0019440 ######################\n","loss: 0.0007\n","########### iter 0019460 ######################\n","loss: 0.0006\n","########### iter 0019480 ######################\n","loss: 0.0007\n","########### iter 0019500 ######################\n","loss: 0.0008\n","########### iter 0019520 ######################\n","loss: 0.0007\n","########### iter 0019540 ######################\n","loss: 0.0009\n","########### iter 0019560 ######################\n","loss: 0.0007\n","########### iter 0019580 ######################\n","loss: 0.0007\n","########### iter 0019600 ######################\n","loss: 0.0007\n","########### iter 0019620 ######################\n","loss: 0.0008\n","########### iter 0019640 ######################\n","loss: 0.0008\n","########### iter 0019660 ######################\n","loss: 0.0008\n","########### iter 0019680 ######################\n","loss: 0.0007\n","########### iter 0019700 ######################\n","loss: 0.0008\n","########### iter 0019720 ######################\n","loss: 0.0007\n","########### iter 0019740 ######################\n","loss: 0.0008\n","########### iter 0019760 ######################\n","loss: 0.0008\n","########### iter 0019780 ######################\n","loss: 0.0008\n","########### iter 0019800 ######################\n","loss: 0.0008\n","########### iter 0019820 ######################\n","loss: 0.0007\n","########### iter 0019840 ######################\n","loss: 0.0007\n","########### iter 0019860 ######################\n","loss: 0.0008\n","########### iter 0019880 ######################\n","loss: 0.0007\n","########### iter 0019900 ######################\n","loss: 0.0008\n","########### iter 0019920 ######################\n","loss: 0.0007\n","########### iter 0019940 ######################\n","loss: 0.0007\n","########### iter 0019960 ######################\n","loss: 0.0006\n","########### iter 0019980 ######################\n","loss: 0.0008\n","########### iter 0020000 ######################\n","loss: 0.0007\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0020000.weight\n","########### iter 0020020 ######################\n","loss: 0.0008\n","########### iter 0020040 ######################\n","loss: 0.0008\n","########### iter 0020060 ######################\n","loss: 0.0007\n","########### iter 0020080 ######################\n","loss: 0.0007\n","########### iter 0020100 ######################\n","loss: 0.0006\n","########### iter 0020120 ######################\n","loss: 0.0006\n","########### iter 0020140 ######################\n","loss: 0.0008\n","########### iter 0020160 ######################\n","loss: 0.0008\n","########### iter 0020180 ######################\n","loss: 0.0008\n","########### iter 0020200 ######################\n","loss: 0.0007\n","########### iter 0020220 ######################\n","loss: 0.0007\n","########### iter 0020240 ######################\n","loss: 0.0007\n","########### iter 0020260 ######################\n","loss: 0.0008\n","########### iter 0020280 ######################\n","loss: 0.0009\n","########### iter 0020300 ######################\n","loss: 0.0008\n","########### iter 0020320 ######################\n","loss: 0.0007\n","########### iter 0020340 ######################\n","loss: 0.0006\n","########### iter 0020360 ######################\n","loss: 0.0007\n","########### iter 0020380 ######################\n","loss: 0.0006\n","########### iter 0020400 ######################\n","loss: 0.0008\n","########### iter 0020420 ######################\n","loss: 0.0012\n","########### iter 0020440 ######################\n","loss: 0.0009\n","########### iter 0020460 ######################\n","loss: 0.0008\n","########### iter 0020480 ######################\n","loss: 0.0007\n","########### iter 0020500 ######################\n","loss: 0.0008\n","########### iter 0020520 ######################\n","loss: 0.0008\n","########### iter 0020540 ######################\n","loss: 0.0006\n","########### iter 0020560 ######################\n","loss: 0.0007\n","########### iter 0020580 ######################\n","loss: 0.0006\n","########### iter 0020600 ######################\n","loss: 0.0008\n","########### iter 0020620 ######################\n","loss: 0.0006\n","########### iter 0020640 ######################\n","loss: 0.0007\n","########### iter 0020660 ######################\n","loss: 0.0008\n","########### iter 0020680 ######################\n","loss: 0.0007\n","########### iter 0020700 ######################\n","loss: 0.0008\n","########### iter 0020720 ######################\n","loss: 0.0008\n","########### iter 0020740 ######################\n","loss: 0.0007\n","########### iter 0020760 ######################\n","loss: 0.0006\n","########### iter 0020780 ######################\n","loss: 0.0008\n","########### iter 0020800 ######################\n","loss: 0.0008\n","########### iter 0020820 ######################\n","loss: 0.0009\n","########### iter 0020840 ######################\n","loss: 0.0007\n","########### iter 0020860 ######################\n","loss: 0.0006\n","########### iter 0020880 ######################\n","loss: 0.0008\n","########### iter 0020900 ######################\n","loss: 0.0008\n","########### iter 0020920 ######################\n","loss: 0.0006\n","########### iter 0020940 ######################\n","loss: 0.0006\n","########### iter 0020960 ######################\n","loss: 0.0006\n","########### iter 0020980 ######################\n","loss: 0.0007\n","########### iter 0021000 ######################\n","loss: 0.0009\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0021000.weight\n","########### iter 0021020 ######################\n","loss: 0.0010\n","########### iter 0021040 ######################\n","loss: 0.0009\n","########### iter 0021060 ######################\n","loss: 0.0007\n","########### iter 0021080 ######################\n","loss: 0.0005\n","########### iter 0021100 ######################\n","loss: 0.0008\n","########### iter 0021120 ######################\n","loss: 0.0007\n","########### iter 0021140 ######################\n","loss: 0.0007\n","########### iter 0021160 ######################\n","loss: 0.0007\n","########### iter 0021180 ######################\n","loss: 0.0007\n","########### iter 0021200 ######################\n","loss: 0.0008\n","########### iter 0021220 ######################\n","loss: 0.0007\n","########### iter 0021240 ######################\n","loss: 0.0006\n","########### iter 0021260 ######################\n","loss: 0.0007\n","########### iter 0021280 ######################\n","loss: 0.0007\n","########### iter 0021300 ######################\n","loss: 0.0007\n","########### iter 0021320 ######################\n","loss: 0.0007\n","########### iter 0021340 ######################\n","loss: 0.0007\n","########### iter 0021360 ######################\n","loss: 0.0008\n","########### iter 0021380 ######################\n","loss: 0.0007\n","########### iter 0021400 ######################\n","loss: 0.0007\n","########### iter 0021420 ######################\n","loss: 0.0006\n","########### iter 0021440 ######################\n","loss: 0.0007\n","########### iter 0021460 ######################\n","loss: 0.0007\n","########### iter 0021480 ######################\n","loss: 0.0007\n","########### iter 0021500 ######################\n","loss: 0.0006\n","########### iter 0021520 ######################\n","loss: 0.0007\n","########### iter 0021540 ######################\n","loss: 0.0007\n","########### iter 0021560 ######################\n","loss: 0.0006\n","########### iter 0021580 ######################\n","loss: 0.0008\n","########### iter 0021600 ######################\n","loss: 0.0006\n","########### iter 0021620 ######################\n","loss: 0.0007\n","########### iter 0021640 ######################\n","loss: 0.0007\n","########### iter 0021660 ######################\n","loss: 0.0007\n","########### iter 0021680 ######################\n","loss: 0.0007\n","########### iter 0021700 ######################\n","loss: 0.0007\n","########### iter 0021720 ######################\n","loss: 0.0006\n","########### iter 0021740 ######################\n","loss: 0.0006\n","########### iter 0021760 ######################\n","loss: 0.0007\n","########### iter 0021780 ######################\n","loss: 0.0007\n","########### iter 0021800 ######################\n","loss: 0.0006\n","########### iter 0021820 ######################\n","loss: 0.0006\n","########### iter 0021840 ######################\n","loss: 0.0007\n","########### iter 0021860 ######################\n","loss: 0.0007\n","########### iter 0021880 ######################\n","loss: 0.0007\n","########### iter 0021900 ######################\n","loss: 0.0007\n","########### iter 0021920 ######################\n","loss: 0.0006\n","########### iter 0021940 ######################\n","loss: 0.0007\n","########### iter 0021960 ######################\n","loss: 0.0006\n","########### iter 0021980 ######################\n","loss: 0.0006\n","########### iter 0022000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0022000.weight\n","########### iter 0022020 ######################\n","loss: 0.0006\n","########### iter 0022040 ######################\n","loss: 0.0007\n","########### iter 0022060 ######################\n","loss: 0.0006\n","########### iter 0022080 ######################\n","loss: 0.0007\n","########### iter 0022100 ######################\n","loss: 0.0007\n","########### iter 0022120 ######################\n","loss: 0.0006\n","########### iter 0022140 ######################\n","loss: 0.0006\n","########### iter 0022160 ######################\n","loss: 0.0008\n","########### iter 0022180 ######################\n","loss: 0.0007\n","########### iter 0022200 ######################\n","loss: 0.0006\n","########### iter 0022220 ######################\n","loss: 0.0006\n","########### iter 0022240 ######################\n","loss: 0.0008\n","########### iter 0022260 ######################\n","loss: 0.0005\n","########### iter 0022280 ######################\n","loss: 0.0005\n","########### iter 0022300 ######################\n","loss: 0.0007\n","########### iter 0022320 ######################\n","loss: 0.0006\n","########### iter 0022340 ######################\n","loss: 0.0008\n","########### iter 0022360 ######################\n","loss: 0.0006\n","########### iter 0022380 ######################\n","loss: 0.0007\n","########### iter 0022400 ######################\n","loss: 0.0007\n","########### iter 0022420 ######################\n","loss: 0.0007\n","########### iter 0022440 ######################\n","loss: 0.0007\n","########### iter 0022460 ######################\n","loss: 0.0007\n","########### iter 0022480 ######################\n","loss: 0.0006\n","########### iter 0022500 ######################\n","loss: 0.0007\n","########### iter 0022520 ######################\n","loss: 0.0005\n","########### iter 0022540 ######################\n","loss: 0.0007\n","########### iter 0022560 ######################\n","loss: 0.0007\n","########### iter 0022580 ######################\n","loss: 0.0006\n","########### iter 0022600 ######################\n","loss: 0.0007\n","########### iter 0022620 ######################\n","loss: 0.0007\n","########### iter 0022640 ######################\n","loss: 0.0006\n","########### iter 0022660 ######################\n","loss: 0.0007\n","########### iter 0022680 ######################\n","loss: 0.0007\n","########### iter 0022700 ######################\n","loss: 0.0005\n","########### iter 0022720 ######################\n","loss: 0.0007\n","########### iter 0022740 ######################\n","loss: 0.0007\n","########### iter 0022760 ######################\n","loss: 0.0007\n","########### iter 0022780 ######################\n","loss: 0.0006\n","########### iter 0022800 ######################\n","loss: 0.0007\n","########### iter 0022820 ######################\n","loss: 0.0008\n","########### iter 0022840 ######################\n","loss: 0.0007\n","########### iter 0022860 ######################\n","loss: 0.0007\n","########### iter 0022880 ######################\n","loss: 0.0007\n","########### iter 0022900 ######################\n","loss: 0.0005\n","########### iter 0022920 ######################\n","loss: 0.0006\n","########### iter 0022940 ######################\n","loss: 0.0007\n","########### iter 0022960 ######################\n","loss: 0.0006\n","########### iter 0022980 ######################\n","loss: 0.0007\n","########### iter 0023000 ######################\n","loss: 0.0007\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0023000.weight\n","########### iter 0023020 ######################\n","loss: 0.0006\n","########### iter 0023040 ######################\n","loss: 0.0007\n","########### iter 0023060 ######################\n","loss: 0.0007\n","########### iter 0023080 ######################\n","loss: 0.0006\n","########### iter 0023100 ######################\n","loss: 0.0007\n","########### iter 0023120 ######################\n","loss: 0.0006\n","########### iter 0023140 ######################\n","loss: 0.0006\n","########### iter 0023160 ######################\n","loss: 0.0007\n","########### iter 0023180 ######################\n","loss: 0.0007\n","########### iter 0023200 ######################\n","loss: 0.0007\n","########### iter 0023220 ######################\n","loss: 0.0007\n","########### iter 0023240 ######################\n","loss: 0.0007\n","########### iter 0023260 ######################\n","loss: 0.0006\n","########### iter 0023280 ######################\n","loss: 0.0007\n","########### iter 0023300 ######################\n","loss: 0.0007\n","########### iter 0023320 ######################\n","loss: 0.0006\n","########### iter 0023340 ######################\n","loss: 0.0005\n","########### iter 0023360 ######################\n","loss: 0.0007\n","########### iter 0023380 ######################\n","loss: 0.0008\n","########### iter 0023400 ######################\n","loss: 0.0007\n","########### iter 0023420 ######################\n","loss: 0.0007\n","########### iter 0023440 ######################\n","loss: 0.0007\n","########### iter 0023460 ######################\n","loss: 0.0007\n","########### iter 0023480 ######################\n","loss: 0.0008\n","########### iter 0023500 ######################\n","loss: 0.0007\n","########### iter 0023520 ######################\n","loss: 0.0006\n","########### iter 0023540 ######################\n","loss: 0.0008\n","########### iter 0023560 ######################\n","loss: 0.0008\n","########### iter 0023580 ######################\n","loss: 0.0006\n","########### iter 0023600 ######################\n","loss: 0.0006\n","########### iter 0023620 ######################\n","loss: 0.0005\n","########### iter 0023640 ######################\n","loss: 0.0006\n","########### iter 0023660 ######################\n","loss: 0.0007\n","########### iter 0023680 ######################\n","loss: 0.0006\n","########### iter 0023700 ######################\n","loss: 0.0005\n","########### iter 0023720 ######################\n","loss: 0.0006\n","########### iter 0023740 ######################\n","loss: 0.0008\n","########### iter 0023760 ######################\n","loss: 0.0006\n","########### iter 0023780 ######################\n","loss: 0.0006\n","########### iter 0023800 ######################\n","loss: 0.0006\n","########### iter 0023820 ######################\n","loss: 0.0008\n","########### iter 0023840 ######################\n","loss: 0.0006\n","########### iter 0023860 ######################\n","loss: 0.0008\n","########### iter 0023880 ######################\n","loss: 0.0006\n","########### iter 0023900 ######################\n","loss: 0.0007\n","########### iter 0023920 ######################\n","loss: 0.0005\n","########### iter 0023940 ######################\n","loss: 0.0007\n","########### iter 0023960 ######################\n","loss: 0.0007\n","########### iter 0023980 ######################\n","loss: 0.0005\n","########### iter 0024000 ######################\n","loss: 0.0007\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0024000.weight\n","########### iter 0024020 ######################\n","loss: 0.0006\n","########### iter 0024040 ######################\n","loss: 0.0006\n","########### iter 0024060 ######################\n","loss: 0.0007\n","########### iter 0024080 ######################\n","loss: 0.0007\n","########### iter 0024100 ######################\n","loss: 0.0008\n","########### iter 0024120 ######################\n","loss: 0.0007\n","########### iter 0024140 ######################\n","loss: 0.0006\n","########### iter 0024160 ######################\n","loss: 0.0007\n","########### iter 0024180 ######################\n","loss: 0.0006\n","########### iter 0024200 ######################\n","loss: 0.0005\n","########### iter 0024220 ######################\n","loss: 0.0006\n","########### iter 0024240 ######################\n","loss: 0.0006\n","########### iter 0024260 ######################\n","loss: 0.0006\n","########### iter 0024280 ######################\n","loss: 0.0006\n","########### iter 0024300 ######################\n","loss: 0.0006\n","########### iter 0024320 ######################\n","loss: 0.0008\n","########### iter 0024340 ######################\n","loss: 0.0008\n","########### iter 0024360 ######################\n","loss: 0.0006\n","########### iter 0024380 ######################\n","loss: 0.0007\n","########### iter 0024400 ######################\n","loss: 0.0009\n","########### iter 0024420 ######################\n","loss: 0.0008\n","########### iter 0024440 ######################\n","loss: 0.0006\n","########### iter 0024460 ######################\n","loss: 0.0006\n","########### iter 0024480 ######################\n","loss: 0.0006\n","########### iter 0024500 ######################\n","loss: 0.0006\n","########### iter 0024520 ######################\n","loss: 0.0005\n","########### iter 0024540 ######################\n","loss: 0.0007\n","########### iter 0024560 ######################\n","loss: 0.0005\n","########### iter 0024580 ######################\n","loss: 0.0006\n","########### iter 0024600 ######################\n","loss: 0.0006\n","########### iter 0024620 ######################\n","loss: 0.0007\n","########### iter 0024640 ######################\n","loss: 0.0007\n","########### iter 0024660 ######################\n","loss: 0.0006\n","########### iter 0024680 ######################\n","loss: 0.0006\n","########### iter 0024700 ######################\n","loss: 0.0005\n","########### iter 0024720 ######################\n","loss: 0.0006\n","########### iter 0024740 ######################\n","loss: 0.0007\n","########### iter 0024760 ######################\n","loss: 0.0005\n","########### iter 0024780 ######################\n","loss: 0.0007\n","########### iter 0024800 ######################\n","loss: 0.0006\n","########### iter 0024820 ######################\n","loss: 0.0007\n","########### iter 0024840 ######################\n","loss: 0.0006\n","########### iter 0024860 ######################\n","loss: 0.0007\n","########### iter 0024880 ######################\n","loss: 0.0007\n","########### iter 0024900 ######################\n","loss: 0.0006\n","########### iter 0024920 ######################\n","loss: 0.0006\n","########### iter 0024940 ######################\n","loss: 0.0006\n","########### iter 0024960 ######################\n","loss: 0.0006\n","########### iter 0024980 ######################\n","loss: 0.0006\n","########### iter 0025000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0025000.weight\n","########### iter 0025020 ######################\n","loss: 0.0005\n","########### iter 0025040 ######################\n","loss: 0.0007\n","########### iter 0025060 ######################\n","loss: 0.0006\n","########### iter 0025080 ######################\n","loss: 0.0005\n","########### iter 0025100 ######################\n","loss: 0.0006\n","########### iter 0025120 ######################\n","loss: 0.0006\n","########### iter 0025140 ######################\n","loss: 0.0006\n","########### iter 0025160 ######################\n","loss: 0.0006\n","########### iter 0025180 ######################\n","loss: 0.0006\n","########### iter 0025200 ######################\n","loss: 0.0006\n","########### iter 0025220 ######################\n","loss: 0.0008\n","########### iter 0025240 ######################\n","loss: 0.0006\n","########### iter 0025260 ######################\n","loss: 0.0006\n","########### iter 0025280 ######################\n","loss: 0.0006\n","########### iter 0025300 ######################\n","loss: 0.0006\n","########### iter 0025320 ######################\n","loss: 0.0005\n","########### iter 0025340 ######################\n","loss: 0.0006\n","########### iter 0025360 ######################\n","loss: 0.0005\n","########### iter 0025380 ######################\n","loss: 0.0007\n","########### iter 0025400 ######################\n","loss: 0.0006\n","########### iter 0025420 ######################\n","loss: 0.0005\n","########### iter 0025440 ######################\n","loss: 0.0006\n","########### iter 0025460 ######################\n","loss: 0.0007\n","########### iter 0025480 ######################\n","loss: 0.0005\n","########### iter 0025500 ######################\n","loss: 0.0006\n","########### iter 0025520 ######################\n","loss: 0.0005\n","########### iter 0025540 ######################\n","loss: 0.0005\n","########### iter 0025560 ######################\n","loss: 0.0006\n","########### iter 0025580 ######################\n","loss: 0.0006\n","########### iter 0025600 ######################\n","loss: 0.0007\n","########### iter 0025620 ######################\n","loss: 0.0008\n","########### iter 0025640 ######################\n","loss: 0.0005\n","########### iter 0025660 ######################\n","loss: 0.0007\n","########### iter 0025680 ######################\n","loss: 0.0005\n","########### iter 0025700 ######################\n","loss: 0.0005\n","########### iter 0025720 ######################\n","loss: 0.0006\n","########### iter 0025740 ######################\n","loss: 0.0006\n","########### iter 0025760 ######################\n","loss: 0.0006\n","########### iter 0025780 ######################\n","loss: 0.0006\n","########### iter 0025800 ######################\n","loss: 0.0007\n","########### iter 0025820 ######################\n","loss: 0.0006\n","########### iter 0025840 ######################\n","loss: 0.0006\n","########### iter 0025860 ######################\n","loss: 0.0006\n","########### iter 0025880 ######################\n","loss: 0.0006\n","########### iter 0025900 ######################\n","loss: 0.0007\n","########### iter 0025920 ######################\n","loss: 0.0006\n","########### iter 0025940 ######################\n","loss: 0.0005\n","########### iter 0025960 ######################\n","loss: 0.0006\n","########### iter 0025980 ######################\n","loss: 0.0005\n","########### iter 0026000 ######################\n","loss: 0.0007\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0026000.weight\n","########### iter 0026020 ######################\n","loss: 0.0005\n","########### iter 0026040 ######################\n","loss: 0.0007\n","########### iter 0026060 ######################\n","loss: 0.0005\n","########### iter 0026080 ######################\n","loss: 0.0006\n","########### iter 0026100 ######################\n","loss: 0.0007\n","########### iter 0026120 ######################\n","loss: 0.0006\n","########### iter 0026140 ######################\n","loss: 0.0006\n","########### iter 0026160 ######################\n","loss: 0.0005\n","########### iter 0026180 ######################\n","loss: 0.0006\n","########### iter 0026200 ######################\n","loss: 0.0005\n","########### iter 0026220 ######################\n","loss: 0.0006\n","########### iter 0026240 ######################\n","loss: 0.0005\n","########### iter 0026260 ######################\n","loss: 0.0004\n","########### iter 0026280 ######################\n","loss: 0.0005\n","########### iter 0026300 ######################\n","loss: 0.0005\n","########### iter 0026320 ######################\n","loss: 0.0005\n","########### iter 0026340 ######################\n","loss: 0.0005\n","########### iter 0026360 ######################\n","loss: 0.0006\n","########### iter 0026380 ######################\n","loss: 0.0006\n","########### iter 0026400 ######################\n","loss: 0.0006\n","########### iter 0026420 ######################\n","loss: 0.0006\n","########### iter 0026440 ######################\n","loss: 0.0005\n","########### iter 0026460 ######################\n","loss: 0.0006\n","########### iter 0026480 ######################\n","loss: 0.0006\n","########### iter 0026500 ######################\n","loss: 0.0006\n","########### iter 0026520 ######################\n","loss: 0.0006\n","########### iter 0026540 ######################\n","loss: 0.0006\n","########### iter 0026560 ######################\n","loss: 0.0005\n","########### iter 0026580 ######################\n","loss: 0.0005\n","########### iter 0026600 ######################\n","loss: 0.0005\n","########### iter 0026620 ######################\n","loss: 0.0005\n","########### iter 0026640 ######################\n","loss: 0.0006\n","########### iter 0026660 ######################\n","loss: 0.0006\n","########### iter 0026680 ######################\n","loss: 0.0007\n","########### iter 0026700 ######################\n","loss: 0.0006\n","########### iter 0026720 ######################\n","loss: 0.0006\n","########### iter 0026740 ######################\n","loss: 0.0005\n","########### iter 0026760 ######################\n","loss: 0.0007\n","########### iter 0026780 ######################\n","loss: 0.0007\n","########### iter 0026800 ######################\n","loss: 0.0007\n","########### iter 0026820 ######################\n","loss: 0.0006\n","########### iter 0026840 ######################\n","loss: 0.0006\n","########### iter 0026860 ######################\n","loss: 0.0005\n","########### iter 0026880 ######################\n","loss: 0.0007\n","########### iter 0026900 ######################\n","loss: 0.0006\n","########### iter 0026920 ######################\n","loss: 0.0005\n","########### iter 0026940 ######################\n","loss: 0.0005\n","########### iter 0026960 ######################\n","loss: 0.0006\n","########### iter 0026980 ######################\n","loss: 0.0005\n","########### iter 0027000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0027000.weight\n","########### iter 0027020 ######################\n","loss: 0.0006\n","########### iter 0027040 ######################\n","loss: 0.0006\n","########### iter 0027060 ######################\n","loss: 0.0006\n","########### iter 0027080 ######################\n","loss: 0.0005\n","########### iter 0027100 ######################\n","loss: 0.0006\n","########### iter 0027120 ######################\n","loss: 0.0005\n","########### iter 0027140 ######################\n","loss: 0.0006\n","########### iter 0027160 ######################\n","loss: 0.0006\n","########### iter 0027180 ######################\n","loss: 0.0005\n","########### iter 0027200 ######################\n","loss: 0.0006\n","########### iter 0027220 ######################\n","loss: 0.0006\n","########### iter 0027240 ######################\n","loss: 0.0004\n","########### iter 0027260 ######################\n","loss: 0.0005\n","########### iter 0027280 ######################\n","loss: 0.0006\n","########### iter 0027300 ######################\n","loss: 0.0007\n","########### iter 0027320 ######################\n","loss: 0.0006\n","########### iter 0027340 ######################\n","loss: 0.0005\n","########### iter 0027360 ######################\n","loss: 0.0006\n","########### iter 0027380 ######################\n","loss: 0.0006\n","########### iter 0027400 ######################\n","loss: 0.0006\n","########### iter 0027420 ######################\n","loss: 0.0005\n","########### iter 0027440 ######################\n","loss: 0.0006\n","########### iter 0027460 ######################\n","loss: 0.0005\n","########### iter 0027480 ######################\n","loss: 0.0010\n","########### iter 0027500 ######################\n","loss: 0.0008\n","########### iter 0027520 ######################\n","loss: 0.0015\n","########### iter 0027540 ######################\n","loss: 0.0006\n","########### iter 0027560 ######################\n","loss: 0.0005\n","########### iter 0027580 ######################\n","loss: 0.0005\n","########### iter 0027600 ######################\n","loss: 0.0007\n","########### iter 0027620 ######################\n","loss: 0.0005\n","########### iter 0027640 ######################\n","loss: 0.0006\n","########### iter 0027660 ######################\n","loss: 0.0006\n","########### iter 0027680 ######################\n","loss: 0.0006\n","########### iter 0027700 ######################\n","loss: 0.0005\n","########### iter 0027720 ######################\n","loss: 0.0005\n","########### iter 0027740 ######################\n","loss: 0.0006\n","########### iter 0027760 ######################\n","loss: 0.0005\n","########### iter 0027780 ######################\n","loss: 0.0005\n","########### iter 0027800 ######################\n","loss: 0.0006\n","########### iter 0027820 ######################\n","loss: 0.0005\n","########### iter 0027840 ######################\n","loss: 0.0005\n","########### iter 0027860 ######################\n","loss: 0.0006\n","########### iter 0027880 ######################\n","loss: 0.0006\n","########### iter 0027900 ######################\n","loss: 0.0006\n","########### iter 0027920 ######################\n","loss: 0.0006\n","########### iter 0027940 ######################\n","loss: 0.0005\n","########### iter 0027960 ######################\n","loss: 0.0005\n","########### iter 0027980 ######################\n","loss: 0.0005\n","########### iter 0028000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0028000.weight\n","########### iter 0028020 ######################\n","loss: 0.0005\n","########### iter 0028040 ######################\n","loss: 0.0005\n","########### iter 0028060 ######################\n","loss: 0.0005\n","########### iter 0028080 ######################\n","loss: 0.0005\n","########### iter 0028100 ######################\n","loss: 0.0006\n","########### iter 0028120 ######################\n","loss: 0.0005\n","########### iter 0028140 ######################\n","loss: 0.0005\n","########### iter 0028160 ######################\n","loss: 0.0006\n","########### iter 0028180 ######################\n","loss: 0.0005\n","########### iter 0028200 ######################\n","loss: 0.0005\n","########### iter 0028220 ######################\n","loss: 0.0005\n","########### iter 0028240 ######################\n","loss: 0.0005\n","########### iter 0028260 ######################\n","loss: 0.0006\n","########### iter 0028280 ######################\n","loss: 0.0005\n","########### iter 0028300 ######################\n","loss: 0.0006\n","########### iter 0028320 ######################\n","loss: 0.0005\n","########### iter 0028340 ######################\n","loss: 0.0006\n","########### iter 0028360 ######################\n","loss: 0.0006\n","########### iter 0028380 ######################\n","loss: 0.0005\n","########### iter 0028400 ######################\n","loss: 0.0006\n","########### iter 0028420 ######################\n","loss: 0.0005\n","########### iter 0028440 ######################\n","loss: 0.0006\n","########### iter 0028460 ######################\n","loss: 0.0005\n","########### iter 0028480 ######################\n","loss: 0.0006\n","########### iter 0028500 ######################\n","loss: 0.0005\n","########### iter 0028520 ######################\n","loss: 0.0007\n","########### iter 0028540 ######################\n","loss: 0.0009\n","########### iter 0028560 ######################\n","loss: 0.0007\n","########### iter 0028580 ######################\n","loss: 0.0006\n","########### iter 0028600 ######################\n","loss: 0.0007\n","########### iter 0028620 ######################\n","loss: 0.0005\n","########### iter 0028640 ######################\n","loss: 0.0008\n","########### iter 0028660 ######################\n","loss: 0.0007\n","########### iter 0028680 ######################\n","loss: 0.0006\n","########### iter 0028700 ######################\n","loss: 0.0007\n","########### iter 0028720 ######################\n","loss: 0.0005\n","########### iter 0028740 ######################\n","loss: 0.0024\n","########### iter 0028760 ######################\n","loss: 0.0014\n","########### iter 0028780 ######################\n","loss: 0.0023\n","########### iter 0028800 ######################\n","loss: 0.0008\n","########### iter 0028820 ######################\n","loss: 0.0013\n","########### iter 0028840 ######################\n","loss: 0.0012\n","########### iter 0028860 ######################\n","loss: 0.0006\n","########### iter 0028880 ######################\n","loss: 0.0007\n","########### iter 0028900 ######################\n","loss: 0.0006\n","########### iter 0028920 ######################\n","loss: 0.0007\n","########### iter 0028940 ######################\n","loss: 0.0006\n","########### iter 0028960 ######################\n","loss: 0.0006\n","########### iter 0028980 ######################\n","loss: 0.0006\n","########### iter 0029000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0029000.weight\n","########### iter 0029020 ######################\n","loss: 0.0006\n","########### iter 0029040 ######################\n","loss: 0.0005\n","########### iter 0029060 ######################\n","loss: 0.0005\n","########### iter 0029080 ######################\n","loss: 0.0004\n","########### iter 0029100 ######################\n","loss: 0.0006\n","########### iter 0029120 ######################\n","loss: 0.0006\n","########### iter 0029140 ######################\n","loss: 0.0005\n","########### iter 0029160 ######################\n","loss: 0.0005\n","########### iter 0029180 ######################\n","loss: 0.0005\n","########### iter 0029200 ######################\n","loss: 0.0005\n","########### iter 0029220 ######################\n","loss: 0.0006\n","########### iter 0029240 ######################\n","loss: 0.0005\n","########### iter 0029260 ######################\n","loss: 0.0006\n","########### iter 0029280 ######################\n","loss: 0.0004\n","########### iter 0029300 ######################\n","loss: 0.0006\n","########### iter 0029320 ######################\n","loss: 0.0005\n","########### iter 0029340 ######################\n","loss: 0.0006\n","########### iter 0029360 ######################\n","loss: 0.0004\n","########### iter 0029380 ######################\n","loss: 0.0005\n","########### iter 0029400 ######################\n","loss: 0.0004\n","########### iter 0029420 ######################\n","loss: 0.0005\n","########### iter 0029440 ######################\n","loss: 0.0004\n","########### iter 0029460 ######################\n","loss: 0.0005\n","########### iter 0029480 ######################\n","loss: 0.0005\n","########### iter 0029500 ######################\n","loss: 0.0005\n","########### iter 0029520 ######################\n","loss: 0.0006\n","########### iter 0029540 ######################\n","loss: 0.0005\n","########### iter 0029560 ######################\n","loss: 0.0006\n","########### iter 0029580 ######################\n","loss: 0.0005\n","########### iter 0029600 ######################\n","loss: 0.0005\n","########### iter 0029620 ######################\n","loss: 0.0005\n","########### iter 0029640 ######################\n","loss: 0.0005\n","########### iter 0029660 ######################\n","loss: 0.0005\n","########### iter 0029680 ######################\n","loss: 0.0004\n","########### iter 0029700 ######################\n","loss: 0.0005\n","########### iter 0029720 ######################\n","loss: 0.0005\n","########### iter 0029740 ######################\n","loss: 0.0005\n","########### iter 0029760 ######################\n","loss: 0.0005\n","########### iter 0029780 ######################\n","loss: 0.0006\n","########### iter 0029800 ######################\n","loss: 0.0004\n","########### iter 0029820 ######################\n","loss: 0.0005\n","########### iter 0029840 ######################\n","loss: 0.0005\n","########### iter 0029860 ######################\n","loss: 0.0004\n","########### iter 0029880 ######################\n","loss: 0.0004\n","########### iter 0029900 ######################\n","loss: 0.0005\n","########### iter 0029920 ######################\n","loss: 0.0005\n","########### iter 0029940 ######################\n","loss: 0.0006\n","########### iter 0029960 ######################\n","loss: 0.0006\n","########### iter 0029980 ######################\n","loss: 0.0006\n","########### iter 0030000 ######################\n","loss: 0.0006\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0030000.weight\n","########### iter 0030020 ######################\n","loss: 0.0005\n","########### iter 0030040 ######################\n","loss: 0.0006\n","########### iter 0030060 ######################\n","loss: 0.0004\n","########### iter 0030080 ######################\n","loss: 0.0005\n","########### iter 0030100 ######################\n","loss: 0.0007\n","########### iter 0030120 ######################\n","loss: 0.0005\n","########### iter 0030140 ######################\n","loss: 0.0005\n","########### iter 0030160 ######################\n","loss: 0.0005\n","########### iter 0030180 ######################\n","loss: 0.0006\n","########### iter 0030200 ######################\n","loss: 0.0006\n","########### iter 0030220 ######################\n","loss: 0.0005\n","########### iter 0030240 ######################\n","loss: 0.0006\n","########### iter 0030260 ######################\n","loss: 0.0007\n","########### iter 0030280 ######################\n","loss: 0.0005\n","########### iter 0030300 ######################\n","loss: 0.0004\n","########### iter 0030320 ######################\n","loss: 0.0005\n","########### iter 0030340 ######################\n","loss: 0.0005\n","########### iter 0030360 ######################\n","loss: 0.0005\n","########### iter 0030380 ######################\n","loss: 0.0004\n","########### iter 0030400 ######################\n","loss: 0.0006\n","########### iter 0030420 ######################\n","loss: 0.0005\n","########### iter 0030440 ######################\n","loss: 0.0005\n","########### iter 0030460 ######################\n","loss: 0.0006\n","########### iter 0030480 ######################\n","loss: 0.0004\n","########### iter 0030500 ######################\n","loss: 0.0005\n","########### iter 0030520 ######################\n","loss: 0.0005\n","########### iter 0030540 ######################\n","loss: 0.0005\n","########### iter 0030560 ######################\n","loss: 0.0004\n","########### iter 0030580 ######################\n","loss: 0.0004\n","########### iter 0030600 ######################\n","loss: 0.0006\n","########### iter 0030620 ######################\n","loss: 0.0005\n","########### iter 0030640 ######################\n","loss: 0.0005\n","########### iter 0030660 ######################\n","loss: 0.0005\n","########### iter 0030680 ######################\n","loss: 0.0004\n","########### iter 0030700 ######################\n","loss: 0.0005\n","########### iter 0030720 ######################\n","loss: 0.0005\n","########### iter 0030740 ######################\n","loss: 0.0005\n","########### iter 0030760 ######################\n","loss: 0.0005\n","########### iter 0030780 ######################\n","loss: 0.0006\n","########### iter 0030800 ######################\n","loss: 0.0005\n","########### iter 0030820 ######################\n","loss: 0.0005\n","########### iter 0030840 ######################\n","loss: 0.0006\n","########### iter 0030860 ######################\n","loss: 0.0005\n","########### iter 0030880 ######################\n","loss: 0.0006\n","########### iter 0030900 ######################\n","loss: 0.0005\n","########### iter 0030920 ######################\n","loss: 0.0005\n","########### iter 0030940 ######################\n","loss: 0.0005\n","########### iter 0030960 ######################\n","loss: 0.0005\n","########### iter 0030980 ######################\n","loss: 0.0005\n","########### iter 0031000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0031000.weight\n","########### iter 0031020 ######################\n","loss: 0.0006\n","########### iter 0031040 ######################\n","loss: 0.0005\n","########### iter 0031060 ######################\n","loss: 0.0006\n","########### iter 0031080 ######################\n","loss: 0.0005\n","########### iter 0031100 ######################\n","loss: 0.0006\n","########### iter 0031120 ######################\n","loss: 0.0006\n","########### iter 0031140 ######################\n","loss: 0.0005\n","########### iter 0031160 ######################\n","loss: 0.0005\n","########### iter 0031180 ######################\n","loss: 0.0005\n","########### iter 0031200 ######################\n","loss: 0.0006\n","########### iter 0031220 ######################\n","loss: 0.0005\n","########### iter 0031240 ######################\n","loss: 0.0005\n","########### iter 0031260 ######################\n","loss: 0.0005\n","########### iter 0031280 ######################\n","loss: 0.0005\n","########### iter 0031300 ######################\n","loss: 0.0006\n","########### iter 0031320 ######################\n","loss: 0.0005\n","########### iter 0031340 ######################\n","loss: 0.0006\n","########### iter 0031360 ######################\n","loss: 0.0005\n","########### iter 0031380 ######################\n","loss: 0.0004\n","########### iter 0031400 ######################\n","loss: 0.0005\n","########### iter 0031420 ######################\n","loss: 0.0005\n","########### iter 0031440 ######################\n","loss: 0.0006\n","########### iter 0031460 ######################\n","loss: 0.0005\n","########### iter 0031480 ######################\n","loss: 0.0005\n","########### iter 0031500 ######################\n","loss: 0.0005\n","########### iter 0031520 ######################\n","loss: 0.0006\n","########### iter 0031540 ######################\n","loss: 0.0005\n","########### iter 0031560 ######################\n","loss: 0.0005\n","########### iter 0031580 ######################\n","loss: 0.0005\n","########### iter 0031600 ######################\n","loss: 0.0006\n","########### iter 0031620 ######################\n","loss: 0.0005\n","########### iter 0031640 ######################\n","loss: 0.0004\n","########### iter 0031660 ######################\n","loss: 0.0005\n","########### iter 0031680 ######################\n","loss: 0.0005\n","########### iter 0031700 ######################\n","loss: 0.0005\n","########### iter 0031720 ######################\n","loss: 0.0005\n","########### iter 0031740 ######################\n","loss: 0.0006\n","########### iter 0031760 ######################\n","loss: 0.0006\n","########### iter 0031780 ######################\n","loss: 0.0005\n","########### iter 0031800 ######################\n","loss: 0.0004\n","########### iter 0031820 ######################\n","loss: 0.0006\n","########### iter 0031840 ######################\n","loss: 0.0005\n","########### iter 0031860 ######################\n","loss: 0.0006\n","########### iter 0031880 ######################\n","loss: 0.0005\n","########### iter 0031900 ######################\n","loss: 0.0005\n","########### iter 0031920 ######################\n","loss: 0.0004\n","########### iter 0031940 ######################\n","loss: 0.0005\n","########### iter 0031960 ######################\n","loss: 0.0005\n","########### iter 0031980 ######################\n","loss: 0.0004\n","########### iter 0032000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0032000.weight\n","########### iter 0032020 ######################\n","loss: 0.0005\n","########### iter 0032040 ######################\n","loss: 0.0005\n","########### iter 0032060 ######################\n","loss: 0.0005\n","########### iter 0032080 ######################\n","loss: 0.0005\n","########### iter 0032100 ######################\n","loss: 0.0005\n","########### iter 0032120 ######################\n","loss: 0.0005\n","########### iter 0032140 ######################\n","loss: 0.0004\n","########### iter 0032160 ######################\n","loss: 0.0006\n","########### iter 0032180 ######################\n","loss: 0.0004\n","########### iter 0032200 ######################\n","loss: 0.0003\n","########### iter 0032220 ######################\n","loss: 0.0004\n","########### iter 0032240 ######################\n","loss: 0.0005\n","########### iter 0032260 ######################\n","loss: 0.0006\n","########### iter 0032280 ######################\n","loss: 0.0005\n","########### iter 0032300 ######################\n","loss: 0.0005\n","########### iter 0032320 ######################\n","loss: 0.0006\n","########### iter 0032340 ######################\n","loss: 0.0004\n","########### iter 0032360 ######################\n","loss: 0.0006\n","########### iter 0032380 ######################\n","loss: 0.0005\n","########### iter 0032400 ######################\n","loss: 0.0005\n","########### iter 0032420 ######################\n","loss: 0.0005\n","########### iter 0032440 ######################\n","loss: 0.0005\n","########### iter 0032460 ######################\n","loss: 0.0005\n","########### iter 0032480 ######################\n","loss: 0.0005\n","########### iter 0032500 ######################\n","loss: 0.0005\n","########### iter 0032520 ######################\n","loss: 0.0005\n","########### iter 0032540 ######################\n","loss: 0.0005\n","########### iter 0032560 ######################\n","loss: 0.0005\n","########### iter 0032580 ######################\n","loss: 0.0005\n","########### iter 0032600 ######################\n","loss: 0.0005\n","########### iter 0032620 ######################\n","loss: 0.0004\n","########### iter 0032640 ######################\n","loss: 0.0005\n","########### iter 0032660 ######################\n","loss: 0.0005\n","########### iter 0032680 ######################\n","loss: 0.0005\n","########### iter 0032700 ######################\n","loss: 0.0005\n","########### iter 0032720 ######################\n","loss: 0.0005\n","########### iter 0032740 ######################\n","loss: 0.0005\n","########### iter 0032760 ######################\n","loss: 0.0005\n","########### iter 0032780 ######################\n","loss: 0.0006\n","########### iter 0032800 ######################\n","loss: 0.0006\n","########### iter 0032820 ######################\n","loss: 0.0006\n","########### iter 0032840 ######################\n","loss: 0.0006\n","########### iter 0032860 ######################\n","loss: 0.0005\n","########### iter 0032880 ######################\n","loss: 0.0004\n","########### iter 0032900 ######################\n","loss: 0.0005\n","########### iter 0032920 ######################\n","loss: 0.0006\n","########### iter 0032940 ######################\n","loss: 0.0006\n","########### iter 0032960 ######################\n","loss: 0.0005\n","########### iter 0032980 ######################\n","loss: 0.0006\n","########### iter 0033000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0033000.weight\n","########### iter 0033020 ######################\n","loss: 0.0005\n","########### iter 0033040 ######################\n","loss: 0.0005\n","########### iter 0033060 ######################\n","loss: 0.0005\n","########### iter 0033080 ######################\n","loss: 0.0004\n","########### iter 0033100 ######################\n","loss: 0.0005\n","########### iter 0033120 ######################\n","loss: 0.0005\n","########### iter 0033140 ######################\n","loss: 0.0005\n","########### iter 0033160 ######################\n","loss: 0.0005\n","########### iter 0033180 ######################\n","loss: 0.0005\n","########### iter 0033200 ######################\n","loss: 0.0005\n","########### iter 0033220 ######################\n","loss: 0.0006\n","########### iter 0033240 ######################\n","loss: 0.0005\n","########### iter 0033260 ######################\n","loss: 0.0005\n","########### iter 0033280 ######################\n","loss: 0.0005\n","########### iter 0033300 ######################\n","loss: 0.0004\n","########### iter 0033320 ######################\n","loss: 0.0005\n","########### iter 0033340 ######################\n","loss: 0.0004\n","########### iter 0033360 ######################\n","loss: 0.0005\n","########### iter 0033380 ######################\n","loss: 0.0005\n","########### iter 0033400 ######################\n","loss: 0.0005\n","########### iter 0033420 ######################\n","loss: 0.0005\n","########### iter 0033440 ######################\n","loss: 0.0005\n","########### iter 0033460 ######################\n","loss: 0.0005\n","########### iter 0033480 ######################\n","loss: 0.0004\n","########### iter 0033500 ######################\n","loss: 0.0005\n","########### iter 0033520 ######################\n","loss: 0.0005\n","########### iter 0033540 ######################\n","loss: 0.0005\n","########### iter 0033560 ######################\n","loss: 0.0006\n","########### iter 0033580 ######################\n","loss: 0.0005\n","########### iter 0033600 ######################\n","loss: 0.0005\n","########### iter 0033620 ######################\n","loss: 0.0004\n","########### iter 0033640 ######################\n","loss: 0.0004\n","########### iter 0033660 ######################\n","loss: 0.0005\n","########### iter 0033680 ######################\n","loss: 0.0004\n","########### iter 0033700 ######################\n","loss: 0.0005\n","########### iter 0033720 ######################\n","loss: 0.0004\n","########### iter 0033740 ######################\n","loss: 0.0005\n","########### iter 0033760 ######################\n","loss: 0.0005\n","########### iter 0033780 ######################\n","loss: 0.0005\n","########### iter 0033800 ######################\n","loss: 0.0006\n","########### iter 0033820 ######################\n","loss: 0.0007\n","########### iter 0033840 ######################\n","loss: 0.0005\n","########### iter 0033860 ######################\n","loss: 0.0005\n","########### iter 0033880 ######################\n","loss: 0.0004\n","########### iter 0033900 ######################\n","loss: 0.0005\n","########### iter 0033920 ######################\n","loss: 0.0005\n","########### iter 0033940 ######################\n","loss: 0.0005\n","########### iter 0033960 ######################\n","loss: 0.0004\n","########### iter 0033980 ######################\n","loss: 0.0006\n","########### iter 0034000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0034000.weight\n","########### iter 0034020 ######################\n","loss: 0.0004\n","########### iter 0034040 ######################\n","loss: 0.0006\n","########### iter 0034060 ######################\n","loss: 0.0005\n","########### iter 0034080 ######################\n","loss: 0.0004\n","########### iter 0034100 ######################\n","loss: 0.0005\n","########### iter 0034120 ######################\n","loss: 0.0004\n","########### iter 0034140 ######################\n","loss: 0.0004\n","########### iter 0034160 ######################\n","loss: 0.0004\n","########### iter 0034180 ######################\n","loss: 0.0005\n","########### iter 0034200 ######################\n","loss: 0.0005\n","########### iter 0034220 ######################\n","loss: 0.0005\n","########### iter 0034240 ######################\n","loss: 0.0004\n","########### iter 0034260 ######################\n","loss: 0.0006\n","########### iter 0034280 ######################\n","loss: 0.0005\n","########### iter 0034300 ######################\n","loss: 0.0005\n","########### iter 0034320 ######################\n","loss: 0.0005\n","########### iter 0034340 ######################\n","loss: 0.0005\n","########### iter 0034360 ######################\n","loss: 0.0004\n","########### iter 0034380 ######################\n","loss: 0.0006\n","########### iter 0034400 ######################\n","loss: 0.0005\n","########### iter 0034420 ######################\n","loss: 0.0005\n","########### iter 0034440 ######################\n","loss: 0.0004\n","########### iter 0034460 ######################\n","loss: 0.0004\n","########### iter 0034480 ######################\n","loss: 0.0005\n","########### iter 0034500 ######################\n","loss: 0.0005\n","########### iter 0034520 ######################\n","loss: 0.0004\n","########### iter 0034540 ######################\n","loss: 0.0004\n","########### iter 0034560 ######################\n","loss: 0.0005\n","########### iter 0034580 ######################\n","loss: 0.0005\n","########### iter 0034600 ######################\n","loss: 0.0004\n","########### iter 0034620 ######################\n","loss: 0.0005\n","########### iter 0034640 ######################\n","loss: 0.0005\n","########### iter 0034660 ######################\n","loss: 0.0004\n","########### iter 0034680 ######################\n","loss: 0.0005\n","########### iter 0034700 ######################\n","loss: 0.0005\n","########### iter 0034720 ######################\n","loss: 0.0006\n","########### iter 0034740 ######################\n","loss: 0.0005\n","########### iter 0034760 ######################\n","loss: 0.0005\n","########### iter 0034780 ######################\n","loss: 0.0004\n","########### iter 0034800 ######################\n","loss: 0.0004\n","########### iter 0034820 ######################\n","loss: 0.0006\n","########### iter 0034840 ######################\n","loss: 0.0004\n","########### iter 0034860 ######################\n","loss: 0.0004\n","########### iter 0034880 ######################\n","loss: 0.0005\n","########### iter 0034900 ######################\n","loss: 0.0005\n","########### iter 0034920 ######################\n","loss: 0.0005\n","########### iter 0034940 ######################\n","loss: 0.0005\n","########### iter 0034960 ######################\n","loss: 0.0006\n","########### iter 0034980 ######################\n","loss: 0.0005\n","########### iter 0035000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0035000.weight\n","########### iter 0035020 ######################\n","loss: 0.0004\n","########### iter 0035040 ######################\n","loss: 0.0005\n","########### iter 0035060 ######################\n","loss: 0.0005\n","########### iter 0035080 ######################\n","loss: 0.0005\n","########### iter 0035100 ######################\n","loss: 0.0004\n","########### iter 0035120 ######################\n","loss: 0.0005\n","########### iter 0035140 ######################\n","loss: 0.0004\n","########### iter 0035160 ######################\n","loss: 0.0005\n","########### iter 0035180 ######################\n","loss: 0.0005\n","########### iter 0035200 ######################\n","loss: 0.0005\n","########### iter 0035220 ######################\n","loss: 0.0005\n","########### iter 0035240 ######################\n","loss: 0.0004\n","########### iter 0035260 ######################\n","loss: 0.0005\n","########### iter 0035280 ######################\n","loss: 0.0004\n","########### iter 0035300 ######################\n","loss: 0.0005\n","########### iter 0035320 ######################\n","loss: 0.0005\n","########### iter 0035340 ######################\n","loss: 0.0004\n","########### iter 0035360 ######################\n","loss: 0.0005\n","########### iter 0035380 ######################\n","loss: 0.0004\n","########### iter 0035400 ######################\n","loss: 0.0004\n","########### iter 0035420 ######################\n","loss: 0.0004\n","########### iter 0035440 ######################\n","loss: 0.0005\n","########### iter 0035460 ######################\n","loss: 0.0005\n","########### iter 0035480 ######################\n","loss: 0.0005\n","########### iter 0035500 ######################\n","loss: 0.0004\n","########### iter 0035520 ######################\n","loss: 0.0004\n","########### iter 0035540 ######################\n","loss: 0.0004\n","########### iter 0035560 ######################\n","loss: 0.0005\n","########### iter 0035580 ######################\n","loss: 0.0004\n","########### iter 0035600 ######################\n","loss: 0.0004\n","########### iter 0035620 ######################\n","loss: 0.0004\n","########### iter 0035640 ######################\n","loss: 0.0005\n","########### iter 0035660 ######################\n","loss: 0.0005\n","########### iter 0035680 ######################\n","loss: 0.0004\n","########### iter 0035700 ######################\n","loss: 0.0004\n","########### iter 0035720 ######################\n","loss: 0.0005\n","########### iter 0035740 ######################\n","loss: 0.0004\n","########### iter 0035760 ######################\n","loss: 0.0005\n","########### iter 0035780 ######################\n","loss: 0.0004\n","########### iter 0035800 ######################\n","loss: 0.0005\n","########### iter 0035820 ######################\n","loss: 0.0006\n","########### iter 0035840 ######################\n","loss: 0.0004\n","########### iter 0035860 ######################\n","loss: 0.0005\n","########### iter 0035880 ######################\n","loss: 0.0006\n","########### iter 0035900 ######################\n","loss: 0.0005\n","########### iter 0035920 ######################\n","loss: 0.0005\n","########### iter 0035940 ######################\n","loss: 0.0005\n","########### iter 0035960 ######################\n","loss: 0.0004\n","########### iter 0035980 ######################\n","loss: 0.0004\n","########### iter 0036000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0036000.weight\n","########### iter 0036020 ######################\n","loss: 0.0005\n","########### iter 0036040 ######################\n","loss: 0.0005\n","########### iter 0036060 ######################\n","loss: 0.0004\n","########### iter 0036080 ######################\n","loss: 0.0005\n","########### iter 0036100 ######################\n","loss: 0.0005\n","########### iter 0036120 ######################\n","loss: 0.0004\n","########### iter 0036140 ######################\n","loss: 0.0004\n","########### iter 0036160 ######################\n","loss: 0.0004\n","########### iter 0036180 ######################\n","loss: 0.0005\n","########### iter 0036200 ######################\n","loss: 0.0004\n","########### iter 0036220 ######################\n","loss: 0.0004\n","########### iter 0036240 ######################\n","loss: 0.0004\n","########### iter 0036260 ######################\n","loss: 0.0005\n","########### iter 0036280 ######################\n","loss: 0.0005\n","########### iter 0036300 ######################\n","loss: 0.0005\n","########### iter 0036320 ######################\n","loss: 0.0005\n","########### iter 0036340 ######################\n","loss: 0.0004\n","########### iter 0036360 ######################\n","loss: 0.0004\n","########### iter 0036380 ######################\n","loss: 0.0004\n","########### iter 0036400 ######################\n","loss: 0.0005\n","########### iter 0036420 ######################\n","loss: 0.0004\n","########### iter 0036440 ######################\n","loss: 0.0005\n","########### iter 0036460 ######################\n","loss: 0.0004\n","########### iter 0036480 ######################\n","loss: 0.0004\n","########### iter 0036500 ######################\n","loss: 0.0005\n","########### iter 0036520 ######################\n","loss: 0.0004\n","########### iter 0036540 ######################\n","loss: 0.0004\n","########### iter 0036560 ######################\n","loss: 0.0004\n","########### iter 0036580 ######################\n","loss: 0.0004\n","########### iter 0036600 ######################\n","loss: 0.0004\n","########### iter 0036620 ######################\n","loss: 0.0005\n","########### iter 0036640 ######################\n","loss: 0.0005\n","########### iter 0036660 ######################\n","loss: 0.0004\n","########### iter 0036680 ######################\n","loss: 0.0003\n","########### iter 0036700 ######################\n","loss: 0.0004\n","########### iter 0036720 ######################\n","loss: 0.0005\n","########### iter 0036740 ######################\n","loss: 0.0004\n","########### iter 0036760 ######################\n","loss: 0.0005\n","########### iter 0036780 ######################\n","loss: 0.0004\n","########### iter 0036800 ######################\n","loss: 0.0004\n","########### iter 0036820 ######################\n","loss: 0.0004\n","########### iter 0036840 ######################\n","loss: 0.0006\n","########### iter 0036860 ######################\n","loss: 0.0005\n","########### iter 0036880 ######################\n","loss: 0.0005\n","########### iter 0036900 ######################\n","loss: 0.0004\n","########### iter 0036920 ######################\n","loss: 0.0005\n","########### iter 0036940 ######################\n","loss: 0.0004\n","########### iter 0036960 ######################\n","loss: 0.0005\n","########### iter 0036980 ######################\n","loss: 0.0004\n","########### iter 0037000 ######################\n","loss: 0.0005\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0037000.weight\n","########### iter 0037020 ######################\n","loss: 0.0005\n","########### iter 0037040 ######################\n","loss: 0.0006\n","########### iter 0037060 ######################\n","loss: 0.0007\n","########### iter 0037080 ######################\n","loss: 0.0005\n","########### iter 0037100 ######################\n","loss: 0.0005\n","########### iter 0037120 ######################\n","loss: 0.0005\n","########### iter 0037140 ######################\n","loss: 0.0004\n","########### iter 0037160 ######################\n","loss: 0.0005\n","########### iter 0037180 ######################\n","loss: 0.0004\n","########### iter 0037200 ######################\n","loss: 0.0004\n","########### iter 0037220 ######################\n","loss: 0.0005\n","########### iter 0037240 ######################\n","loss: 0.0004\n","########### iter 0037260 ######################\n","loss: 0.0005\n","########### iter 0037280 ######################\n","loss: 0.0005\n","########### iter 0037300 ######################\n","loss: 0.0005\n","########### iter 0037320 ######################\n","loss: 0.0005\n","########### iter 0037340 ######################\n","loss: 0.0005\n","########### iter 0037360 ######################\n","loss: 0.0005\n","########### iter 0037380 ######################\n","loss: 0.0004\n","########### iter 0037400 ######################\n","loss: 0.0005\n","########### iter 0037420 ######################\n","loss: 0.0005\n","########### iter 0037440 ######################\n","loss: 0.0004\n","########### iter 0037460 ######################\n","loss: 0.0005\n","########### iter 0037480 ######################\n","loss: 0.0004\n","########### iter 0037500 ######################\n","loss: 0.0004\n","########### iter 0037520 ######################\n","loss: 0.0005\n","########### iter 0037540 ######################\n","loss: 0.0004\n","########### iter 0037560 ######################\n","loss: 0.0004\n","########### iter 0037580 ######################\n","loss: 0.0004\n","########### iter 0037600 ######################\n","loss: 0.0004\n","########### iter 0037620 ######################\n","loss: 0.0004\n","########### iter 0037640 ######################\n","loss: 0.0005\n","########### iter 0037660 ######################\n","loss: 0.0005\n","########### iter 0037680 ######################\n","loss: 0.0004\n","########### iter 0037700 ######################\n","loss: 0.0004\n","########### iter 0037720 ######################\n","loss: 0.0004\n","########### iter 0037740 ######################\n","loss: 0.0005\n","########### iter 0037760 ######################\n","loss: 0.0005\n","########### iter 0037780 ######################\n","loss: 0.0005\n","########### iter 0037800 ######################\n","loss: 0.0004\n","########### iter 0037820 ######################\n","loss: 0.0004\n","########### iter 0037840 ######################\n","loss: 0.0005\n","########### iter 0037860 ######################\n","loss: 0.0004\n","########### iter 0037880 ######################\n","loss: 0.0004\n","########### iter 0037900 ######################\n","loss: 0.0005\n","########### iter 0037920 ######################\n","loss: 0.0004\n","########### iter 0037940 ######################\n","loss: 0.0005\n","########### iter 0037960 ######################\n","loss: 0.0005\n","########### iter 0037980 ######################\n","loss: 0.0005\n","########### iter 0038000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0038000.weight\n","########### iter 0038020 ######################\n","loss: 0.0004\n","########### iter 0038040 ######################\n","loss: 0.0004\n","########### iter 0038060 ######################\n","loss: 0.0004\n","########### iter 0038080 ######################\n","loss: 0.0004\n","########### iter 0038100 ######################\n","loss: 0.0005\n","########### iter 0038120 ######################\n","loss: 0.0004\n","########### iter 0038140 ######################\n","loss: 0.0005\n","########### iter 0038160 ######################\n","loss: 0.0004\n","########### iter 0038180 ######################\n","loss: 0.0005\n","########### iter 0038200 ######################\n","loss: 0.0004\n","########### iter 0038220 ######################\n","loss: 0.0005\n","########### iter 0038240 ######################\n","loss: 0.0004\n","########### iter 0038260 ######################\n","loss: 0.0005\n","########### iter 0038280 ######################\n","loss: 0.0005\n","########### iter 0038300 ######################\n","loss: 0.0005\n","########### iter 0038320 ######################\n","loss: 0.0006\n","########### iter 0038340 ######################\n","loss: 0.0006\n","########### iter 0038360 ######################\n","loss: 0.0005\n","########### iter 0038380 ######################\n","loss: 0.0004\n","########### iter 0038400 ######################\n","loss: 0.0004\n","########### iter 0038420 ######################\n","loss: 0.0005\n","########### iter 0038440 ######################\n","loss: 0.0004\n","########### iter 0038460 ######################\n","loss: 0.0005\n","########### iter 0038480 ######################\n","loss: 0.0004\n","########### iter 0038500 ######################\n","loss: 0.0004\n","########### iter 0038520 ######################\n","loss: 0.0004\n","########### iter 0038540 ######################\n","loss: 0.0004\n","########### iter 0038560 ######################\n","loss: 0.0004\n","########### iter 0038580 ######################\n","loss: 0.0004\n","########### iter 0038600 ######################\n","loss: 0.0004\n","########### iter 0038620 ######################\n","loss: 0.0004\n","########### iter 0038640 ######################\n","loss: 0.0005\n","########### iter 0038660 ######################\n","loss: 0.0005\n","########### iter 0038680 ######################\n","loss: 0.0004\n","########### iter 0038700 ######################\n","loss: 0.0005\n","########### iter 0038720 ######################\n","loss: 0.0005\n","########### iter 0038740 ######################\n","loss: 0.0005\n","########### iter 0038760 ######################\n","loss: 0.0005\n","########### iter 0038780 ######################\n","loss: 0.0005\n","########### iter 0038800 ######################\n","loss: 0.0004\n","########### iter 0038820 ######################\n","loss: 0.0005\n","########### iter 0038840 ######################\n","loss: 0.0006\n","########### iter 0038860 ######################\n","loss: 0.0008\n","########### iter 0038880 ######################\n","loss: 0.0004\n","########### iter 0038900 ######################\n","loss: 0.0004\n","########### iter 0038920 ######################\n","loss: 0.0004\n","########### iter 0038940 ######################\n","loss: 0.0004\n","########### iter 0038960 ######################\n","loss: 0.0005\n","########### iter 0038980 ######################\n","loss: 0.0005\n","########### iter 0039000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0039000.weight\n","########### iter 0039020 ######################\n","loss: 0.0004\n","########### iter 0039040 ######################\n","loss: 0.0004\n","########### iter 0039060 ######################\n","loss: 0.0005\n","########### iter 0039080 ######################\n","loss: 0.0004\n","########### iter 0039100 ######################\n","loss: 0.0004\n","########### iter 0039120 ######################\n","loss: 0.0004\n","########### iter 0039140 ######################\n","loss: 0.0004\n","########### iter 0039160 ######################\n","loss: 0.0005\n","########### iter 0039180 ######################\n","loss: 0.0005\n","########### iter 0039200 ######################\n","loss: 0.0004\n","########### iter 0039220 ######################\n","loss: 0.0005\n","########### iter 0039240 ######################\n","loss: 0.0005\n","########### iter 0039260 ######################\n","loss: 0.0004\n","########### iter 0039280 ######################\n","loss: 0.0004\n","########### iter 0039300 ######################\n","loss: 0.0005\n","########### iter 0039320 ######################\n","loss: 0.0004\n","########### iter 0039340 ######################\n","loss: 0.0004\n","########### iter 0039360 ######################\n","loss: 0.0004\n","########### iter 0039380 ######################\n","loss: 0.0004\n","########### iter 0039400 ######################\n","loss: 0.0005\n","########### iter 0039420 ######################\n","loss: 0.0005\n","########### iter 0039440 ######################\n","loss: 0.0005\n","########### iter 0039460 ######################\n","loss: 0.0005\n","########### iter 0039480 ######################\n","loss: 0.0005\n","########### iter 0039500 ######################\n","loss: 0.0004\n","########### iter 0039520 ######################\n","loss: 0.0004\n","########### iter 0039540 ######################\n","loss: 0.0004\n","########### iter 0039560 ######################\n","loss: 0.0005\n","########### iter 0039580 ######################\n","loss: 0.0005\n","########### iter 0039600 ######################\n","loss: 0.0004\n","########### iter 0039620 ######################\n","loss: 0.0005\n","########### iter 0039640 ######################\n","loss: 0.0006\n","########### iter 0039660 ######################\n","loss: 0.0004\n","########### iter 0039680 ######################\n","loss: 0.0004\n","########### iter 0039700 ######################\n","loss: 0.0004\n","########### iter 0039720 ######################\n","loss: 0.0004\n","########### iter 0039740 ######################\n","loss: 0.0004\n","########### iter 0039760 ######################\n","loss: 0.0004\n","########### iter 0039780 ######################\n","loss: 0.0005\n","########### iter 0039800 ######################\n","loss: 0.0004\n","########### iter 0039820 ######################\n","loss: 0.0003\n","########### iter 0039840 ######################\n","loss: 0.0004\n","########### iter 0039860 ######################\n","loss: 0.0004\n","########### iter 0039880 ######################\n","loss: 0.0004\n","########### iter 0039900 ######################\n","loss: 0.0004\n","########### iter 0039920 ######################\n","loss: 0.0004\n","########### iter 0039940 ######################\n","loss: 0.0004\n","########### iter 0039960 ######################\n","loss: 0.0003\n","########### iter 0039980 ######################\n","loss: 0.0004\n","########### iter 0040000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0040000.weight\n","########### iter 0040020 ######################\n","loss: 0.0004\n","########### iter 0040040 ######################\n","loss: 0.0005\n","########### iter 0040060 ######################\n","loss: 0.0006\n","########### iter 0040080 ######################\n","loss: 0.0004\n","########### iter 0040100 ######################\n","loss: 0.0004\n","########### iter 0040120 ######################\n","loss: 0.0004\n","########### iter 0040140 ######################\n","loss: 0.0004\n","########### iter 0040160 ######################\n","loss: 0.0004\n","########### iter 0040180 ######################\n","loss: 0.0004\n","########### iter 0040200 ######################\n","loss: 0.0004\n","########### iter 0040220 ######################\n","loss: 0.0004\n","########### iter 0040240 ######################\n","loss: 0.0005\n","########### iter 0040260 ######################\n","loss: 0.0004\n","########### iter 0040280 ######################\n","loss: 0.0004\n","########### iter 0040300 ######################\n","loss: 0.0005\n","########### iter 0040320 ######################\n","loss: 0.0004\n","########### iter 0040340 ######################\n","loss: 0.0004\n","########### iter 0040360 ######################\n","loss: 0.0004\n","########### iter 0040380 ######################\n","loss: 0.0005\n","########### iter 0040400 ######################\n","loss: 0.0005\n","########### iter 0040420 ######################\n","loss: 0.0005\n","########### iter 0040440 ######################\n","loss: 0.0005\n","########### iter 0040460 ######################\n","loss: 0.0005\n","########### iter 0040480 ######################\n","loss: 0.0005\n","########### iter 0040500 ######################\n","loss: 0.0004\n","########### iter 0040520 ######################\n","loss: 0.0004\n","########### iter 0040540 ######################\n","loss: 0.0004\n","########### iter 0040560 ######################\n","loss: 0.0004\n","########### iter 0040580 ######################\n","loss: 0.0004\n","########### iter 0040600 ######################\n","loss: 0.0004\n","########### iter 0040620 ######################\n","loss: 0.0004\n","########### iter 0040640 ######################\n","loss: 0.0004\n","########### iter 0040660 ######################\n","loss: 0.0004\n","########### iter 0040680 ######################\n","loss: 0.0004\n","########### iter 0040700 ######################\n","loss: 0.0004\n","########### iter 0040720 ######################\n","loss: 0.0005\n","########### iter 0040740 ######################\n","loss: 0.0005\n","########### iter 0040760 ######################\n","loss: 0.0005\n","########### iter 0040780 ######################\n","loss: 0.0005\n","########### iter 0040800 ######################\n","loss: 0.0004\n","########### iter 0040820 ######################\n","loss: 0.0005\n","########### iter 0040840 ######################\n","loss: 0.0004\n","########### iter 0040860 ######################\n","loss: 0.0005\n","########### iter 0040880 ######################\n","loss: 0.0005\n","########### iter 0040900 ######################\n","loss: 0.0004\n","########### iter 0040920 ######################\n","loss: 0.0004\n","########### iter 0040940 ######################\n","loss: 0.0004\n","########### iter 0040960 ######################\n","loss: 0.0004\n","########### iter 0040980 ######################\n","loss: 0.0005\n","########### iter 0041000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0041000.weight\n","########### iter 0041020 ######################\n","loss: 0.0004\n","########### iter 0041040 ######################\n","loss: 0.0005\n","########### iter 0041060 ######################\n","loss: 0.0004\n","########### iter 0041080 ######################\n","loss: 0.0004\n","########### iter 0041100 ######################\n","loss: 0.0004\n","########### iter 0041120 ######################\n","loss: 0.0005\n","########### iter 0041140 ######################\n","loss: 0.0004\n","########### iter 0041160 ######################\n","loss: 0.0005\n","########### iter 0041180 ######################\n","loss: 0.0004\n","########### iter 0041200 ######################\n","loss: 0.0004\n","########### iter 0041220 ######################\n","loss: 0.0005\n","########### iter 0041240 ######################\n","loss: 0.0004\n","########### iter 0041260 ######################\n","loss: 0.0004\n","########### iter 0041280 ######################\n","loss: 0.0004\n","########### iter 0041300 ######################\n","loss: 0.0005\n","########### iter 0041320 ######################\n","loss: 0.0005\n","########### iter 0041340 ######################\n","loss: 0.0005\n","########### iter 0041360 ######################\n","loss: 0.0005\n","########### iter 0041380 ######################\n","loss: 0.0004\n","########### iter 0041400 ######################\n","loss: 0.0005\n","########### iter 0041420 ######################\n","loss: 0.0004\n","########### iter 0041440 ######################\n","loss: 0.0004\n","########### iter 0041460 ######################\n","loss: 0.0004\n","########### iter 0041480 ######################\n","loss: 0.0004\n","########### iter 0041500 ######################\n","loss: 0.0004\n","########### iter 0041520 ######################\n","loss: 0.0004\n","########### iter 0041540 ######################\n","loss: 0.0006\n","########### iter 0041560 ######################\n","loss: 0.0004\n","########### iter 0041580 ######################\n","loss: 0.0004\n","########### iter 0041600 ######################\n","loss: 0.0004\n","########### iter 0041620 ######################\n","loss: 0.0005\n","########### iter 0041640 ######################\n","loss: 0.0004\n","########### iter 0041660 ######################\n","loss: 0.0004\n","########### iter 0041680 ######################\n","loss: 0.0005\n","########### iter 0041700 ######################\n","loss: 0.0003\n","########### iter 0041720 ######################\n","loss: 0.0004\n","########### iter 0041740 ######################\n","loss: 0.0004\n","########### iter 0041760 ######################\n","loss: 0.0004\n","########### iter 0041780 ######################\n","loss: 0.0004\n","########### iter 0041800 ######################\n","loss: 0.0004\n","########### iter 0041820 ######################\n","loss: 0.0004\n","########### iter 0041840 ######################\n","loss: 0.0004\n","########### iter 0041860 ######################\n","loss: 0.0006\n","########### iter 0041880 ######################\n","loss: 0.0003\n","########### iter 0041900 ######################\n","loss: 0.0005\n","########### iter 0041920 ######################\n","loss: 0.0004\n","########### iter 0041940 ######################\n","loss: 0.0004\n","########### iter 0041960 ######################\n","loss: 0.0003\n","########### iter 0041980 ######################\n","loss: 0.0004\n","########### iter 0042000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0042000.weight\n","########### iter 0042020 ######################\n","loss: 0.0004\n","########### iter 0042040 ######################\n","loss: 0.0004\n","########### iter 0042060 ######################\n","loss: 0.0004\n","########### iter 0042080 ######################\n","loss: 0.0005\n","########### iter 0042100 ######################\n","loss: 0.0004\n","########### iter 0042120 ######################\n","loss: 0.0005\n","########### iter 0042140 ######################\n","loss: 0.0005\n","########### iter 0042160 ######################\n","loss: 0.0004\n","########### iter 0042180 ######################\n","loss: 0.0004\n","########### iter 0042200 ######################\n","loss: 0.0004\n","########### iter 0042220 ######################\n","loss: 0.0004\n","########### iter 0042240 ######################\n","loss: 0.0004\n","########### iter 0042260 ######################\n","loss: 0.0004\n","########### iter 0042280 ######################\n","loss: 0.0004\n","########### iter 0042300 ######################\n","loss: 0.0004\n","########### iter 0042320 ######################\n","loss: 0.0004\n","########### iter 0042340 ######################\n","loss: 0.0004\n","########### iter 0042360 ######################\n","loss: 0.0005\n","########### iter 0042380 ######################\n","loss: 0.0004\n","########### iter 0042400 ######################\n","loss: 0.0004\n","########### iter 0042420 ######################\n","loss: 0.0004\n","########### iter 0042440 ######################\n","loss: 0.0004\n","########### iter 0042460 ######################\n","loss: 0.0004\n","########### iter 0042480 ######################\n","loss: 0.0004\n","########### iter 0042500 ######################\n","loss: 0.0005\n","########### iter 0042520 ######################\n","loss: 0.0004\n","########### iter 0042540 ######################\n","loss: 0.0005\n","########### iter 0042560 ######################\n","loss: 0.0005\n","########### iter 0042580 ######################\n","loss: 0.0005\n","########### iter 0042600 ######################\n","loss: 0.0004\n","########### iter 0042620 ######################\n","loss: 0.0003\n","########### iter 0042640 ######################\n","loss: 0.0004\n","########### iter 0042660 ######################\n","loss: 0.0004\n","########### iter 0042680 ######################\n","loss: 0.0004\n","########### iter 0042700 ######################\n","loss: 0.0004\n","########### iter 0042720 ######################\n","loss: 0.0004\n","########### iter 0042740 ######################\n","loss: 0.0004\n","########### iter 0042760 ######################\n","loss: 0.0004\n","########### iter 0042780 ######################\n","loss: 0.0004\n","########### iter 0042800 ######################\n","loss: 0.0004\n","########### iter 0042820 ######################\n","loss: 0.0004\n","########### iter 0042840 ######################\n","loss: 0.0004\n","########### iter 0042860 ######################\n","loss: 0.0003\n","########### iter 0042880 ######################\n","loss: 0.0004\n","########### iter 0042900 ######################\n","loss: 0.0004\n","########### iter 0042920 ######################\n","loss: 0.0005\n","########### iter 0042940 ######################\n","loss: 0.0004\n","########### iter 0042960 ######################\n","loss: 0.0004\n","########### iter 0042980 ######################\n","loss: 0.0005\n","########### iter 0043000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0043000.weight\n","########### iter 0043020 ######################\n","loss: 0.0005\n","########### iter 0043040 ######################\n","loss: 0.0004\n","########### iter 0043060 ######################\n","loss: 0.0005\n","########### iter 0043080 ######################\n","loss: 0.0004\n","########### iter 0043100 ######################\n","loss: 0.0004\n","########### iter 0043120 ######################\n","loss: 0.0004\n","########### iter 0043140 ######################\n","loss: 0.0004\n","########### iter 0043160 ######################\n","loss: 0.0004\n","########### iter 0043180 ######################\n","loss: 0.0005\n","########### iter 0043200 ######################\n","loss: 0.0004\n","########### iter 0043220 ######################\n","loss: 0.0004\n","########### iter 0043240 ######################\n","loss: 0.0004\n","########### iter 0043260 ######################\n","loss: 0.0004\n","########### iter 0043280 ######################\n","loss: 0.0004\n","########### iter 0043300 ######################\n","loss: 0.0004\n","########### iter 0043320 ######################\n","loss: 0.0004\n","########### iter 0043340 ######################\n","loss: 0.0004\n","########### iter 0043360 ######################\n","loss: 0.0006\n","########### iter 0043380 ######################\n","loss: 0.0005\n","########### iter 0043400 ######################\n","loss: 0.0004\n","########### iter 0043420 ######################\n","loss: 0.0004\n","########### iter 0043440 ######################\n","loss: 0.0004\n","########### iter 0043460 ######################\n","loss: 0.0005\n","########### iter 0043480 ######################\n","loss: 0.0005\n","########### iter 0043500 ######################\n","loss: 0.0005\n","########### iter 0043520 ######################\n","loss: 0.0004\n","########### iter 0043540 ######################\n","loss: 0.0004\n","########### iter 0043560 ######################\n","loss: 0.0005\n","########### iter 0043580 ######################\n","loss: 0.0012\n","########### iter 0043600 ######################\n","loss: 0.0013\n","########### iter 0043620 ######################\n","loss: 0.0011\n","########### iter 0043640 ######################\n","loss: 0.0014\n","########### iter 0043660 ######################\n","loss: 0.0008\n","########### iter 0043680 ######################\n","loss: 0.0005\n","########### iter 0043700 ######################\n","loss: 0.0005\n","########### iter 0043720 ######################\n","loss: 0.0007\n","########### iter 0043740 ######################\n","loss: 0.0005\n","########### iter 0043760 ######################\n","loss: 0.0005\n","########### iter 0043780 ######################\n","loss: 0.0005\n","########### iter 0043800 ######################\n","loss: 0.0004\n","########### iter 0043820 ######################\n","loss: 0.0004\n","########### iter 0043840 ######################\n","loss: 0.0004\n","########### iter 0043860 ######################\n","loss: 0.0004\n","########### iter 0043880 ######################\n","loss: 0.0004\n","########### iter 0043900 ######################\n","loss: 0.0005\n","########### iter 0043920 ######################\n","loss: 0.0004\n","########### iter 0043940 ######################\n","loss: 0.0004\n","########### iter 0043960 ######################\n","loss: 0.0004\n","########### iter 0043980 ######################\n","loss: 0.0004\n","########### iter 0044000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0044000.weight\n","########### iter 0044020 ######################\n","loss: 0.0004\n","########### iter 0044040 ######################\n","loss: 0.0004\n","########### iter 0044060 ######################\n","loss: 0.0004\n","########### iter 0044080 ######################\n","loss: 0.0005\n","########### iter 0044100 ######################\n","loss: 0.0004\n","########### iter 0044120 ######################\n","loss: 0.0004\n","########### iter 0044140 ######################\n","loss: 0.0004\n","########### iter 0044160 ######################\n","loss: 0.0005\n","########### iter 0044180 ######################\n","loss: 0.0004\n","########### iter 0044200 ######################\n","loss: 0.0004\n","########### iter 0044220 ######################\n","loss: 0.0004\n","########### iter 0044240 ######################\n","loss: 0.0003\n","########### iter 0044260 ######################\n","loss: 0.0004\n","########### iter 0044280 ######################\n","loss: 0.0003\n","########### iter 0044300 ######################\n","loss: 0.0004\n","########### iter 0044320 ######################\n","loss: 0.0003\n","########### iter 0044340 ######################\n","loss: 0.0004\n","########### iter 0044360 ######################\n","loss: 0.0004\n","########### iter 0044380 ######################\n","loss: 0.0004\n","########### iter 0044400 ######################\n","loss: 0.0004\n","########### iter 0044420 ######################\n","loss: 0.0005\n","########### iter 0044440 ######################\n","loss: 0.0003\n","########### iter 0044460 ######################\n","loss: 0.0003\n","########### iter 0044480 ######################\n","loss: 0.0004\n","########### iter 0044500 ######################\n","loss: 0.0004\n","########### iter 0044520 ######################\n","loss: 0.0004\n","########### iter 0044540 ######################\n","loss: 0.0005\n","########### iter 0044560 ######################\n","loss: 0.0004\n","########### iter 0044580 ######################\n","loss: 0.0004\n","########### iter 0044600 ######################\n","loss: 0.0004\n","########### iter 0044620 ######################\n","loss: 0.0004\n","########### iter 0044640 ######################\n","loss: 0.0004\n","########### iter 0044660 ######################\n","loss: 0.0003\n","########### iter 0044680 ######################\n","loss: 0.0003\n","########### iter 0044700 ######################\n","loss: 0.0004\n","########### iter 0044720 ######################\n","loss: 0.0004\n","########### iter 0044740 ######################\n","loss: 0.0004\n","########### iter 0044760 ######################\n","loss: 0.0003\n","########### iter 0044780 ######################\n","loss: 0.0004\n","########### iter 0044800 ######################\n","loss: 0.0003\n","########### iter 0044820 ######################\n","loss: 0.0003\n","########### iter 0044840 ######################\n","loss: 0.0004\n","########### iter 0044860 ######################\n","loss: 0.0004\n","########### iter 0044880 ######################\n","loss: 0.0004\n","########### iter 0044900 ######################\n","loss: 0.0004\n","########### iter 0044920 ######################\n","loss: 0.0003\n","########### iter 0044940 ######################\n","loss: 0.0004\n","########### iter 0044960 ######################\n","loss: 0.0004\n","########### iter 0044980 ######################\n","loss: 0.0003\n","########### iter 0045000 ######################\n","loss: 0.0003\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0045000.weight\n","########### iter 0045020 ######################\n","loss: 0.0004\n","########### iter 0045040 ######################\n","loss: 0.0004\n","########### iter 0045060 ######################\n","loss: 0.0003\n","########### iter 0045080 ######################\n","loss: 0.0003\n","########### iter 0045100 ######################\n","loss: 0.0004\n","########### iter 0045120 ######################\n","loss: 0.0004\n","########### iter 0045140 ######################\n","loss: 0.0004\n","########### iter 0045160 ######################\n","loss: 0.0004\n","########### iter 0045180 ######################\n","loss: 0.0004\n","########### iter 0045200 ######################\n","loss: 0.0004\n","########### iter 0045220 ######################\n","loss: 0.0004\n","########### iter 0045240 ######################\n","loss: 0.0004\n","########### iter 0045260 ######################\n","loss: 0.0004\n","########### iter 0045280 ######################\n","loss: 0.0005\n","########### iter 0045300 ######################\n","loss: 0.0004\n","########### iter 0045320 ######################\n","loss: 0.0004\n","########### iter 0045340 ######################\n","loss: 0.0004\n","########### iter 0045360 ######################\n","loss: 0.0004\n","########### iter 0045380 ######################\n","loss: 0.0004\n","########### iter 0045400 ######################\n","loss: 0.0004\n","########### iter 0045420 ######################\n","loss: 0.0004\n","########### iter 0045440 ######################\n","loss: 0.0003\n","########### iter 0045460 ######################\n","loss: 0.0003\n","########### iter 0045480 ######################\n","loss: 0.0003\n","########### iter 0045500 ######################\n","loss: 0.0004\n","########### iter 0045520 ######################\n","loss: 0.0003\n","########### iter 0045540 ######################\n","loss: 0.0003\n","########### iter 0045560 ######################\n","loss: 0.0004\n","########### iter 0045580 ######################\n","loss: 0.0004\n","########### iter 0045600 ######################\n","loss: 0.0004\n","########### iter 0045620 ######################\n","loss: 0.0003\n","########### iter 0045640 ######################\n","loss: 0.0003\n","########### iter 0045660 ######################\n","loss: 0.0005\n","########### iter 0045680 ######################\n","loss: 0.0004\n","########### iter 0045700 ######################\n","loss: 0.0004\n","########### iter 0045720 ######################\n","loss: 0.0004\n","########### iter 0045740 ######################\n","loss: 0.0004\n","########### iter 0045760 ######################\n","loss: 0.0004\n","########### iter 0045780 ######################\n","loss: 0.0005\n","########### iter 0045800 ######################\n","loss: 0.0003\n","########### iter 0045820 ######################\n","loss: 0.0003\n","########### iter 0045840 ######################\n","loss: 0.0004\n","########### iter 0045860 ######################\n","loss: 0.0003\n","########### iter 0045880 ######################\n","loss: 0.0004\n","########### iter 0045900 ######################\n","loss: 0.0004\n","########### iter 0045920 ######################\n","loss: 0.0003\n","########### iter 0045940 ######################\n","loss: 0.0004\n","########### iter 0045960 ######################\n","loss: 0.0004\n","########### iter 0045980 ######################\n","loss: 0.0003\n","########### iter 0046000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0046000.weight\n","########### iter 0046020 ######################\n","loss: 0.0003\n","########### iter 0046040 ######################\n","loss: 0.0004\n","########### iter 0046060 ######################\n","loss: 0.0004\n","########### iter 0046080 ######################\n","loss: 0.0004\n","########### iter 0046100 ######################\n","loss: 0.0003\n","########### iter 0046120 ######################\n","loss: 0.0004\n","########### iter 0046140 ######################\n","loss: 0.0004\n","########### iter 0046160 ######################\n","loss: 0.0003\n","########### iter 0046180 ######################\n","loss: 0.0003\n","########### iter 0046200 ######################\n","loss: 0.0004\n","########### iter 0046220 ######################\n","loss: 0.0003\n","########### iter 0046240 ######################\n","loss: 0.0004\n","########### iter 0046260 ######################\n","loss: 0.0005\n","########### iter 0046280 ######################\n","loss: 0.0005\n","########### iter 0046300 ######################\n","loss: 0.0005\n","########### iter 0046320 ######################\n","loss: 0.0004\n","########### iter 0046340 ######################\n","loss: 0.0004\n","########### iter 0046360 ######################\n","loss: 0.0005\n","########### iter 0046380 ######################\n","loss: 0.0005\n","########### iter 0046400 ######################\n","loss: 0.0004\n","########### iter 0046420 ######################\n","loss: 0.0004\n","########### iter 0046440 ######################\n","loss: 0.0003\n","########### iter 0046460 ######################\n","loss: 0.0004\n","########### iter 0046480 ######################\n","loss: 0.0004\n","########### iter 0046500 ######################\n","loss: 0.0005\n","########### iter 0046520 ######################\n","loss: 0.0004\n","########### iter 0046540 ######################\n","loss: 0.0004\n","########### iter 0046560 ######################\n","loss: 0.0004\n","########### iter 0046580 ######################\n","loss: 0.0004\n","########### iter 0046600 ######################\n","loss: 0.0005\n","########### iter 0046620 ######################\n","loss: 0.0004\n","########### iter 0046640 ######################\n","loss: 0.0004\n","########### iter 0046660 ######################\n","loss: 0.0003\n","########### iter 0046680 ######################\n","loss: 0.0004\n","########### iter 0046700 ######################\n","loss: 0.0004\n","########### iter 0046720 ######################\n","loss: 0.0004\n","########### iter 0046740 ######################\n","loss: 0.0004\n","########### iter 0046760 ######################\n","loss: 0.0004\n","########### iter 0046780 ######################\n","loss: 0.0005\n","########### iter 0046800 ######################\n","loss: 0.0004\n","########### iter 0046820 ######################\n","loss: 0.0004\n","########### iter 0046840 ######################\n","loss: 0.0005\n","########### iter 0046860 ######################\n","loss: 0.0004\n","########### iter 0046880 ######################\n","loss: 0.0004\n","########### iter 0046900 ######################\n","loss: 0.0004\n","########### iter 0046920 ######################\n","loss: 0.0004\n","########### iter 0046940 ######################\n","loss: 0.0005\n","########### iter 0046960 ######################\n","loss: 0.0004\n","########### iter 0046980 ######################\n","loss: 0.0004\n","########### iter 0047000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0047000.weight\n","########### iter 0047020 ######################\n","loss: 0.0004\n","########### iter 0047040 ######################\n","loss: 0.0004\n","########### iter 0047060 ######################\n","loss: 0.0005\n","########### iter 0047080 ######################\n","loss: 0.0005\n","########### iter 0047100 ######################\n","loss: 0.0003\n","########### iter 0047120 ######################\n","loss: 0.0005\n","########### iter 0047140 ######################\n","loss: 0.0004\n","########### iter 0047160 ######################\n","loss: 0.0003\n","########### iter 0047180 ######################\n","loss: 0.0004\n","########### iter 0047200 ######################\n","loss: 0.0004\n","########### iter 0047220 ######################\n","loss: 0.0004\n","########### iter 0047240 ######################\n","loss: 0.0004\n","########### iter 0047260 ######################\n","loss: 0.0003\n","########### iter 0047280 ######################\n","loss: 0.0003\n","########### iter 0047300 ######################\n","loss: 0.0005\n","########### iter 0047320 ######################\n","loss: 0.0004\n","########### iter 0047340 ######################\n","loss: 0.0004\n","########### iter 0047360 ######################\n","loss: 0.0004\n","########### iter 0047380 ######################\n","loss: 0.0004\n","########### iter 0047400 ######################\n","loss: 0.0004\n","########### iter 0047420 ######################\n","loss: 0.0004\n","########### iter 0047440 ######################\n","loss: 0.0004\n","########### iter 0047460 ######################\n","loss: 0.0004\n","########### iter 0047480 ######################\n","loss: 0.0004\n","########### iter 0047500 ######################\n","loss: 0.0004\n","########### iter 0047520 ######################\n","loss: 0.0004\n","########### iter 0047540 ######################\n","loss: 0.0003\n","########### iter 0047560 ######################\n","loss: 0.0004\n","########### iter 0047580 ######################\n","loss: 0.0004\n","########### iter 0047600 ######################\n","loss: 0.0004\n","########### iter 0047620 ######################\n","loss: 0.0003\n","########### iter 0047640 ######################\n","loss: 0.0004\n","########### iter 0047660 ######################\n","loss: 0.0003\n","########### iter 0047680 ######################\n","loss: 0.0003\n","########### iter 0047700 ######################\n","loss: 0.0004\n","########### iter 0047720 ######################\n","loss: 0.0004\n","########### iter 0047740 ######################\n","loss: 0.0004\n","########### iter 0047760 ######################\n","loss: 0.0004\n","########### iter 0047780 ######################\n","loss: 0.0004\n","########### iter 0047800 ######################\n","loss: 0.0004\n","########### iter 0047820 ######################\n","loss: 0.0004\n","########### iter 0047840 ######################\n","loss: 0.0004\n","########### iter 0047860 ######################\n","loss: 0.0003\n","########### iter 0047880 ######################\n","loss: 0.0004\n","########### iter 0047900 ######################\n","loss: 0.0004\n","########### iter 0047920 ######################\n","loss: 0.0004\n","########### iter 0047940 ######################\n","loss: 0.0004\n","########### iter 0047960 ######################\n","loss: 0.0004\n","########### iter 0047980 ######################\n","loss: 0.0004\n","########### iter 0048000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0048000.weight\n","########### iter 0048020 ######################\n","loss: 0.0004\n","########### iter 0048040 ######################\n","loss: 0.0003\n","########### iter 0048060 ######################\n","loss: 0.0004\n","########### iter 0048080 ######################\n","loss: 0.0003\n","########### iter 0048100 ######################\n","loss: 0.0004\n","########### iter 0048120 ######################\n","loss: 0.0003\n","########### iter 0048140 ######################\n","loss: 0.0004\n","########### iter 0048160 ######################\n","loss: 0.0004\n","########### iter 0048180 ######################\n","loss: 0.0004\n","########### iter 0048200 ######################\n","loss: 0.0004\n","########### iter 0048220 ######################\n","loss: 0.0003\n","########### iter 0048240 ######################\n","loss: 0.0003\n","########### iter 0048260 ######################\n","loss: 0.0004\n","########### iter 0048280 ######################\n","loss: 0.0003\n","########### iter 0048300 ######################\n","loss: 0.0003\n","########### iter 0048320 ######################\n","loss: 0.0003\n","########### iter 0048340 ######################\n","loss: 0.0004\n","########### iter 0048360 ######################\n","loss: 0.0004\n","########### iter 0048380 ######################\n","loss: 0.0004\n","########### iter 0048400 ######################\n","loss: 0.0003\n","########### iter 0048420 ######################\n","loss: 0.0004\n","########### iter 0048440 ######################\n","loss: 0.0004\n","########### iter 0048460 ######################\n","loss: 0.0003\n","########### iter 0048480 ######################\n","loss: 0.0004\n","########### iter 0048500 ######################\n","loss: 0.0004\n","########### iter 0048520 ######################\n","loss: 0.0004\n","########### iter 0048540 ######################\n","loss: 0.0004\n","########### iter 0048560 ######################\n","loss: 0.0004\n","########### iter 0048580 ######################\n","loss: 0.0004\n","########### iter 0048600 ######################\n","loss: 0.0004\n","########### iter 0048620 ######################\n","loss: 0.0004\n","########### iter 0048640 ######################\n","loss: 0.0004\n","########### iter 0048660 ######################\n","loss: 0.0004\n","########### iter 0048680 ######################\n","loss: 0.0005\n","########### iter 0048700 ######################\n","loss: 0.0004\n","########### iter 0048720 ######################\n","loss: 0.0004\n","########### iter 0048740 ######################\n","loss: 0.0004\n","########### iter 0048760 ######################\n","loss: 0.0004\n","########### iter 0048780 ######################\n","loss: 0.0004\n","########### iter 0048800 ######################\n","loss: 0.0005\n","########### iter 0048820 ######################\n","loss: 0.0005\n","########### iter 0048840 ######################\n","loss: 0.0005\n","########### iter 0048860 ######################\n","loss: 0.0005\n","########### iter 0048880 ######################\n","loss: 0.0004\n","########### iter 0048900 ######################\n","loss: 0.0004\n","########### iter 0048920 ######################\n","loss: 0.0004\n","########### iter 0048940 ######################\n","loss: 0.0004\n","########### iter 0048960 ######################\n","loss: 0.0005\n","########### iter 0048980 ######################\n","loss: 0.0004\n","########### iter 0049000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0049000.weight\n","########### iter 0049020 ######################\n","loss: 0.0004\n","########### iter 0049040 ######################\n","loss: 0.0004\n","########### iter 0049060 ######################\n","loss: 0.0004\n","########### iter 0049080 ######################\n","loss: 0.0004\n","########### iter 0049100 ######################\n","loss: 0.0004\n","########### iter 0049120 ######################\n","loss: 0.0004\n","########### iter 0049140 ######################\n","loss: 0.0005\n","########### iter 0049160 ######################\n","loss: 0.0004\n","########### iter 0049180 ######################\n","loss: 0.0004\n","########### iter 0049200 ######################\n","loss: 0.0004\n","########### iter 0049220 ######################\n","loss: 0.0004\n","########### iter 0049240 ######################\n","loss: 0.0004\n","########### iter 0049260 ######################\n","loss: 0.0004\n","########### iter 0049280 ######################\n","loss: 0.0004\n","########### iter 0049300 ######################\n","loss: 0.0004\n","########### iter 0049320 ######################\n","loss: 0.0004\n","########### iter 0049340 ######################\n","loss: 0.0004\n","########### iter 0049360 ######################\n","loss: 0.0005\n","########### iter 0049380 ######################\n","loss: 0.0004\n","########### iter 0049400 ######################\n","loss: 0.0003\n","########### iter 0049420 ######################\n","loss: 0.0005\n","########### iter 0049440 ######################\n","loss: 0.0003\n","########### iter 0049460 ######################\n","loss: 0.0004\n","########### iter 0049480 ######################\n","loss: 0.0004\n","########### iter 0049500 ######################\n","loss: 0.0003\n","########### iter 0049520 ######################\n","loss: 0.0004\n","########### iter 0049540 ######################\n","loss: 0.0004\n","########### iter 0049560 ######################\n","loss: 0.0004\n","########### iter 0049580 ######################\n","loss: 0.0004\n","########### iter 0049600 ######################\n","loss: 0.0003\n","########### iter 0049620 ######################\n","loss: 0.0004\n","########### iter 0049640 ######################\n","loss: 0.0005\n","########### iter 0049660 ######################\n","loss: 0.0004\n","########### iter 0049680 ######################\n","loss: 0.0003\n","########### iter 0049700 ######################\n","loss: 0.0004\n","########### iter 0049720 ######################\n","loss: 0.0005\n","########### iter 0049740 ######################\n","loss: 0.0003\n","########### iter 0049760 ######################\n","loss: 0.0004\n","########### iter 0049780 ######################\n","loss: 0.0004\n","########### iter 0049800 ######################\n","loss: 0.0003\n","########### iter 0049820 ######################\n","loss: 0.0006\n","########### iter 0049840 ######################\n","loss: 0.0003\n","########### iter 0049860 ######################\n","loss: 0.0004\n","########### iter 0049880 ######################\n","loss: 0.0004\n","########### iter 0049900 ######################\n","loss: 0.0004\n","########### iter 0049920 ######################\n","loss: 0.0004\n","########### iter 0049940 ######################\n","loss: 0.0004\n","########### iter 0049960 ######################\n","loss: 0.0003\n","########### iter 0049980 ######################\n","loss: 0.0004\n","########### iter 0050000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0050000.weight\n","########### iter 0050020 ######################\n","loss: 0.0004\n","########### iter 0050040 ######################\n","loss: 0.0004\n","########### iter 0050060 ######################\n","loss: 0.0004\n","########### iter 0050080 ######################\n","loss: 0.0004\n","########### iter 0050100 ######################\n","loss: 0.0004\n","########### iter 0050120 ######################\n","loss: 0.0004\n","########### iter 0050140 ######################\n","loss: 0.0004\n","########### iter 0050160 ######################\n","loss: 0.0004\n","########### iter 0050180 ######################\n","loss: 0.0004\n","########### iter 0050200 ######################\n","loss: 0.0004\n","########### iter 0050220 ######################\n","loss: 0.0004\n","########### iter 0050240 ######################\n","loss: 0.0003\n","########### iter 0050260 ######################\n","loss: 0.0004\n","########### iter 0050280 ######################\n","loss: 0.0004\n","########### iter 0050300 ######################\n","loss: 0.0003\n","########### iter 0050320 ######################\n","loss: 0.0004\n","########### iter 0050340 ######################\n","loss: 0.0005\n","########### iter 0050360 ######################\n","loss: 0.0004\n","########### iter 0050380 ######################\n","loss: 0.0004\n","########### iter 0050400 ######################\n","loss: 0.0004\n","########### iter 0050420 ######################\n","loss: 0.0005\n","########### iter 0050440 ######################\n","loss: 0.0004\n","########### iter 0050460 ######################\n","loss: 0.0004\n","########### iter 0050480 ######################\n","loss: 0.0004\n","########### iter 0050500 ######################\n","loss: 0.0004\n","########### iter 0050520 ######################\n","loss: 0.0004\n","########### iter 0050540 ######################\n","loss: 0.0004\n","########### iter 0050560 ######################\n","loss: 0.0005\n","########### iter 0050580 ######################\n","loss: 0.0004\n","########### iter 0050600 ######################\n","loss: 0.0005\n","########### iter 0050620 ######################\n","loss: 0.0004\n","########### iter 0050640 ######################\n","loss: 0.0003\n","########### iter 0050660 ######################\n","loss: 0.0004\n","########### iter 0050680 ######################\n","loss: 0.0003\n","########### iter 0050700 ######################\n","loss: 0.0004\n","########### iter 0050720 ######################\n","loss: 0.0003\n","########### iter 0050740 ######################\n","loss: 0.0005\n","########### iter 0050760 ######################\n","loss: 0.0003\n","########### iter 0050780 ######################\n","loss: 0.0004\n","########### iter 0050800 ######################\n","loss: 0.0003\n","########### iter 0050820 ######################\n","loss: 0.0004\n","########### iter 0050840 ######################\n","loss: 0.0004\n","########### iter 0050860 ######################\n","loss: 0.0004\n","########### iter 0050880 ######################\n","loss: 0.0004\n","########### iter 0050900 ######################\n","loss: 0.0004\n","########### iter 0050920 ######################\n","loss: 0.0004\n","########### iter 0050940 ######################\n","loss: 0.0005\n","########### iter 0050960 ######################\n","loss: 0.0005\n","########### iter 0050980 ######################\n","loss: 0.0004\n","########### iter 0051000 ######################\n","loss: 0.0004\n","Saved model weights to /content/drive/MyDrive/mai645_project_outputs/weights_euler/0051000.weight\n","########### iter 0051020 ######################\n","loss: 0.0004\n","object address  : 0x7d24489e1c00\n","object refcount : 2\n","object type     : 0x9d5ea0\n","object type name: KeyboardInterrupt\n","object repr     : KeyboardInterrupt()\n","lost sys.stderr\n"]}]},{"cell_type":"markdown","source":["# Euler Synthesis"],"metadata":{"id":"UK40wHJyy4Mp"}},{"cell_type":"code","source":["\n","# Define paths for synthesis - adjust as necessary\n","GDRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/mai645_project_outputs\" # Ensure this is defined\n","EULER_WEIGHTS_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"weights_euler\")\n","SYNTHESIS_OUTPUT_BVH_DIR = os.path.join(GDRIVE_OUTPUT_DIR, \"synthesis_output_bvh_euler\")\n","SYNTHESIS_SEED_DATA_DIR = \"/content/project645/train_data_euler/salsa/\" # Or any other folder with suitable .npy seeds\n","STANDARD_BVH_REF_PATH = \"/content/project645/train_data_bvh/standard.bvh\" # Path to your standard.bvh\n","\n","# IMPORTANT: Specify the actual weight file you want to use for synthesis!\n","# For example, list files in EULER_WEIGHTS_DIR and pick one.\n","# !ls -lt \"{EULER_WEIGHTS_DIR}\" # Uncomment and run this in a Colab cell to see your weight files\n","# Replace 'YOUR_TRAINED_MODEL.weight' with the actual filename.\n","TRAINED_MODEL_WEIGHT_FILE = \"0051000.weight\" #\n","PATH_TO_WEIGHT_FILE = os.path.join(EULER_WEIGHTS_DIR, TRAINED_MODEL_WEIGHT_FILE)\n","\n","os.makedirs(SYNTHESIS_OUTPUT_BVH_DIR, exist_ok=True)\n","\n","# Check if the necessary files and folders exist\n","if not os.path.exists(PATH_TO_WEIGHT_FILE):\n","    print(f\"ERROR: Trained model weight file not found at {PATH_TO_WEIGHT_FILE}\")\n","    print(f\"Please ensure the file '{TRAINED_MODEL_WEIGHT_FILE}' exists in '{EULER_WEIGHTS_DIR}'.\")\n","elif not os.path.exists(STANDARD_BVH_REF_PATH):\n","    print(f\"ERROR: Standard BVH reference file not found at {STANDARD_BVH_REF_PATH}\")\n","elif not os.path.exists(SYNTHESIS_SEED_DATA_DIR) or not os.listdir(SYNTHESIS_SEED_DATA_DIR):\n","    print(f\"ERROR: Seed data directory not found or is empty: {SYNTHESIS_SEED_DATA_DIR}\")\n","else:\n","    print(f\"Using trained model: {PATH_TO_WEIGHT_FILE}\")\n","    print(f\"Using seed data from: {SYNTHESIS_SEED_DATA_DIR}\")\n","    print(f\"Saving synthesized BVH files to: {SYNTHESIS_OUTPUT_BVH_DIR}\")\n","\n","    # Define model parameters (should match the trained model)\n","    euler_frame_channels = 132 # Or args.in_frame_size from your training\n","    hidden_size = 1024       # Or args.hidden_size from your training\n","\n","    # Synthesis parameters\n","    batch_size_synthesis = 10  # How many sequences to generate\n","    initial_seq_len_synthesis = 200 # Number of frames from seed .npy to use\n","    generate_frames_synthesis = 400 # Number of frames to synthesize\n","\n","    get_ipython().system(f\"\"\"python synthesize_euler_motion.py \\\n","        --read_weight_path \"{PATH_TO_WEIGHT_FILE}\" \\\n","        --dances_folder \"{SYNTHESIS_SEED_DATA_DIR}\" \\\n","        --write_bvh_motion_folder \"{SYNTHESIS_OUTPUT_BVH_DIR}\" \\\n","        --standard_bvh_reference \"{STANDARD_BVH_REF_PATH}\" \\\n","        --batch_size {batch_size_synthesis} \\\n","        --initial_seq_len {initial_seq_len_synthesis} \\\n","        --generate_frames_number {generate_frames_synthesis} \\\n","        --in_frame_size {euler_frame_channels} \\\n","        --hidden_size {hidden_size} \\\n","        --out_frame_size {euler_frame_channels}\"\"\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FO7-4BM4y6eG","executionInfo":{"status":"ok","timestamp":1747901110043,"user_tz":-180,"elapsed":26779,"user":{"displayName":"Chrysis Andreou","userId":"08304976464433857852"}},"outputId":"bf92a98d-6d5c-4f17-a742-0cbd50b8509d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using trained model: /content/drive/MyDrive/mai645_project_outputs/weights_euler/0051000.weight\n","Using seed data from: /content/project645/train_data_euler/salsa/\n","Saving synthesized BVH files to: /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler\n","Using device: cuda\n","Loading motion files for synthesis seed...\n","load 01.npy\n","frame number: 2243\n","load 02.npy\n","frame number: 2102\n","load 03.npy\n","frame number: 1831\n","load 04.npy\n","frame number: 1872\n","load 05.npy\n","frame number: 1679\n","load 06.npy\n","frame number: 1773\n","load 07.npy\n","frame number: 2072\n","load 08.npy\n","frame number: 3422\n","load 09.npy\n","frame number: 2576\n","load 10.npy\n","frame number: 1198\n","load 11.npy\n","frame number: 2109\n","load 12.npy\n","frame number: 1691\n","load 13.npy\n","frame number: 2272\n","load 14.npy\n","frame number: 1950\n","load 15.npy\n","frame number: 2141\n","load 16.npy\n","frame number: 2243\n","load 17.npy\n","frame number: 2102\n","load 18.npy\n","frame number: 1831\n","load 19.npy\n","frame number: 1872\n","load 20.npy\n","frame number: 1679\n","load 21.npy\n","frame number: 1773\n","load 22.npy\n","frame number: 2072\n","load 23.npy\n","frame number: 3422\n","load 24.npy\n","frame number: 2576\n","load 25.npy\n","frame number: 1198\n","load 26.npy\n","frame number: 2109\n","load 27.npy\n","frame number: 1691\n","load 28.npy\n","frame number: 2272\n","load 29.npy\n","frame number: 1950\n","load 30.npy\n","frame number: 2141\n","Batch 0: Using dance 17 (length 1831 frames), seed starting raw frame 240\n","Batch 1: Using dance 0 (length 2243 frames), seed starting raw frame 343\n","Batch 2: Using dance 20 (length 1773 frames), seed starting raw frame 372\n","Batch 3: Using dance 22 (length 3422 frames), seed starting raw frame 627\n","Batch 4: Using dance 7 (length 3422 frames), seed starting raw frame 842\n","Batch 5: Using dance 25 (length 2109 frames), seed starting raw frame 318\n","Batch 6: Using dance 0 (length 2243 frames), seed starting raw frame 341\n","Batch 7: Using dance 11 (length 1691 frames), seed starting raw frame 132\n","Batch 8: Using dance 0 (length 2243 frames), seed starting raw frame 336\n","Batch 9: Using dance 20 (length 1773 frames), seed starting raw frame 27\n","Batch 0: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt00.bvh\n","Batch 0: Quantitative Eval (first 20 frames) - Hip MSE: 0.0004, Rot Ang Dist: 0.0067\n","Batch 1: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt01.bvh\n","Batch 1: Quantitative Eval (first 20 frames) - Hip MSE: 0.0002, Rot Ang Dist: 0.0001\n","Batch 2: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt02.bvh\n","Batch 2: Quantitative Eval (first 20 frames) - Hip MSE: 0.0002, Rot Ang Dist: 0.0027\n","Batch 3: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt03.bvh\n","Batch 3: Quantitative Eval (first 20 frames) - Hip MSE: 0.0001, Rot Ang Dist: 0.0050\n","Batch 4: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt04.bvh\n","Batch 4: Quantitative Eval (first 20 frames) - Hip MSE: 0.0000, Rot Ang Dist: 0.0021\n","Batch 5: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt05.bvh\n","Batch 5: Quantitative Eval (first 20 frames) - Hip MSE: 0.0000, Rot Ang Dist: 0.0016\n","Batch 6: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt06.bvh\n","Batch 6: Quantitative Eval (first 20 frames) - Hip MSE: 0.0002, Rot Ang Dist: 0.0001\n","Batch 7: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt07.bvh\n","Batch 7: Quantitative Eval (first 20 frames) - Hip MSE: 0.0001, Rot Ang Dist: 0.0013\n","Batch 8: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt08.bvh\n","Batch 8: Quantitative Eval (first 20 frames) - Hip MSE: 0.0002, Rot Ang Dist: 0.0002\n","Batch 9: Saved ground truth BVH to /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler/gt09.bvh\n","Batch 9: Quantitative Eval (first 20 frames) - Hip MSE: 0.0000, Rot Ang Dist: 0.0003\n","Euler angle motion synthesis complete. BVH files saved to: /content/drive/MyDrive/mai645_project_outputs/synthesis_output_bvh_euler\n"]}]}]}